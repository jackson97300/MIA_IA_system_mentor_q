#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Analyse des derniÃ¨res lignes collectÃ©es - VÃ©rification des anomalies persistantes
"""

import json
from pathlib import Path
from collections import defaultdict, Counter
import statistics

def analyze_latest_data():
    file_path = "chart_3_20250904.jsonl"
    
    if not Path(file_path).exists():
        print(f"âŒ Fichier non trouvÃ©: {file_path}")
        return
    
    print("ğŸ” ANALYSE DES DERNIÃˆRES LIGNES COLLECTÃ‰ES - SYSTÃˆME MIA")
    print("=" * 70)
    
    # Compter le nombre total de lignes
    total_lines = sum(1 for _ in open(file_path, 'r', encoding='utf-8'))
    print(f"ğŸ“Š Total lignes dans le fichier: {total_lines:,}")
    
    # Analyser les 1000 derniÃ¨res lignes
    start_line = max(0, total_lines - 1000)
    print(f"ğŸ” Analyse des lignes {start_line:,} Ã  {total_lines:,} (1000 derniÃ¨res)")
    
    data_types = defaultdict(list)
    coherence_issues = []
    vix_data = []
    quote_issues = []
    vva_issues = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i < start_line:
                continue
                
            try:
                data = json.loads(line.strip())
                data_type = data.get('type', 'NO_TYPE')
                data_types[data_type].append(data)
                
                # VÃ©rifications spÃ©cifiques
                if data_type == 'vix':
                    vix_data.append(data)
                
                if data_type == 'quote' and 'bid' in data and 'ask' in data:
                    if data['bid'] >= data['ask']:
                        quote_issues.append({
                            'line': i + 1,
                            'bid': data['bid'],
                            'ask': data['ask'],
                            'timestamp': data.get('t', 'N/A')
                        })
                
                if data_type == 'vva' and 'vah' in data and 'val' in data:
                    if data['vah'] < data['val']:
                        vva_issues.append({
                            'line': i + 1,
                            'vah': data['vah'],
                            'val': data['val'],
                            'timestamp': data.get('t', 'N/A')
                        })
                        
            except Exception as e:
                coherence_issues.append(f"Ligne {i+1}: Erreur parsing - {e}")
    
    # RÃ©sumÃ© des donnÃ©es rÃ©centes
    print(f"\nğŸ“‹ RÃ‰PARTITION DES DERNIÃˆRES DONNÃ‰ES:")
    total_recent = sum(len(data) for data in data_types.values())
    
    for data_type, data_list in sorted(data_types.items(), key=lambda x: len(x[1]), reverse=True):
        percentage = (len(data_list) / total_recent) * 100 if total_recent > 0 else 0
        print(f"   ğŸ“ˆ {data_type}: {len(data_list):,} ({percentage:.1f}%)")
    
    # Analyse VIX rÃ©cente
    print(f"\nğŸŒŠ ANALYSE VIX RÃ‰CENTE:")
    if vix_data:
        print(f"   âœ… VIX trouvÃ©: {len(vix_data)} enregistrements")
        for vix in vix_data:
            if 'last' in vix:
                print(f"      ğŸ“Š Valeur: {vix['last']}, Timestamp: {vix.get('t', 'N/A')}")
    else:
        print("   âŒ Aucun VIX dans les derniÃ¨res donnÃ©es")
    
    # Analyse des anomalies persistantes
    print(f"\nâš ï¸  ANALYSE DES ANOMALIES PERSISTANTES:")
    
    # Quotes bid >= ask
    if quote_issues:
        print(f"   ğŸ“ˆ Quotes bid >= ask: {len(quote_issues)} problÃ¨mes dÃ©tectÃ©s")
        for issue in quote_issues[:3]:  # Afficher les 3 premiers
            print(f"      âŒ Ligne {issue['line']}: bid={issue['bid']} >= ask={issue['ask']}")
        if len(quote_issues) > 3:
            print(f"      ... et {len(quote_issues) - 3} autres")
    else:
        print("   âœ… Aucun problÃ¨me de spread dÃ©tectÃ© dans les derniÃ¨res donnÃ©es")
    
    # VVA VAH < VAL
    if vva_issues:
        print(f"   ğŸ“‰ VVA VAH < VAL: {len(vva_issues)} problÃ¨mes dÃ©tectÃ©s")
        for issue in vva_issues:
            print(f"      âŒ Ligne {issue['line']}: VAH={issue['vah']} < VAL={issue['val']}")
    else:
        print("   âœ… Aucun problÃ¨me VVA dÃ©tectÃ© dans les derniÃ¨res donnÃ©es")
    
    # Autres erreurs
    if coherence_issues:
        print(f"   ğŸ”§ Erreurs de parsing: {len(coherence_issues)} dÃ©tectÃ©es")
        for issue in coherence_issues[:3]:
            print(f"      âŒ {issue}")
    
    # Ã‰valuation de la tendance
    print(f"\nğŸ¯ Ã‰VALUATION DE LA TENDANCE:")
    
    if len(quote_issues) == 0 and len(vva_issues) == 0:
        print("   ğŸ‰ EXCELLENT! Aucune anomalie dans les derniÃ¨res donnÃ©es")
        print("   ğŸ“ˆ Les corrections semblent avoir rÃ©solu les problÃ¨mes")
    elif len(quote_issues) < 3 and len(vva_issues) < 2:
        print("   âœ… BONNE amÃ©lioration! RÃ©duction significative des anomalies")
        print("   ğŸ“‰ Les problÃ¨mes persistent mais sont moins frÃ©quents")
    else:
        print("   âš ï¸  ATTENTION! Anomalies toujours prÃ©sentes")
        print("   ğŸ”§ Des corrections supplÃ©mentaires sont nÃ©cessaires")
    
    # Recommandations
    print(f"\nğŸš€ RECOMMANDATIONS:")
    if len(quote_issues) == 0 and len(vva_issues) == 0:
        print("   ğŸ¯ Maintenir la qualitÃ© actuelle")
        print("   ğŸ“Š Monitoring continu pour dÃ©tecter toute rÃ©gression")
    else:
        print("   ğŸ”§ Continuer les corrections des anomalies persistantes")
        print("   ğŸ“ˆ Analyser les patterns des anomalies restantes")
    
    print(f"\n" + "=" * 70)

if __name__ == "__main__":
    analyze_latest_data()







