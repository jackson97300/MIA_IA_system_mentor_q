"""
MIA_IA_SYSTEM - Technical Audit Complete
AUDIT TECHNIQUE COMPLET DU SYSTÈME
Validation : Patterns + Imports + Syntax + Vectorisation
"""

import ast
import sys
import time
import importlib
import traceback
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any, Set
from collections import defaultdict, deque

class TechnicalAuditor:
    """Auditeur technique complet du système"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.issues = defaultdict(list)
        self.stats = defaultdict(int)
        
    def run_complete_audit(self) -> Dict[str, Any]:
        """Audit technique complet"""
        print("🔍 TECHNICAL AUDIT COMPLET")
        print("=" * 60)
        
        results = {}
        
        # 1. Audit Patterns
        print("\n1️⃣ AUDIT PATTERNS...")
        results['patterns'] = self.audit_patterns()
        
        # 2. Audit Imports  
        print("\n2️⃣ AUDIT IMPORTS...")
        results['imports'] = self.audit_imports()
        
        # 3. Audit Syntax
        print("\n3️⃣ AUDIT SYNTAX...")
        results['syntax'] = self.audit_syntax()
        
        # 4. Audit Vectorisation
        print("\n4️⃣ AUDIT VECTORISATION...")
        results['vectorization'] = self.audit_vectorization()
        
        # 5. Summary
        print("\n📊 AUDIT SUMMARY...")
        self.print_audit_summary(results)
        
        return results
    
    def audit_patterns(self) -> Dict[str, Any]:
        """Audit structure et logique patterns"""
        patterns_file = self.project_root / "core" / "patterns_detector.py"
        
        if not patterns_file.exists():
            return {"status": "ERROR", "message": "patterns_detector.py not found"}
        
        try:
            with open(patterns_file, 'r', encoding='utf-8') as f:
                source = f.read()
            
            tree = ast.parse(source)
            
            # Analyse structure
            classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
            functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
            enums = []
            dataclasses = []
            
            for cls in classes:
                # Check if Enum
                if any(isinstance(base, ast.Name) and base.id == 'Enum' for base in cls.bases):
                    enums.append(cls.name)
                # Check if dataclass
                if any(isinstance(dec, ast.Name) and dec.id == 'dataclass' 
                      for dec in cls.decorator_list):
                    dataclasses.append(cls.name)
            
            # Validation patterns requis
            required_patterns = [
                'detect_gamma_pin',
                'detect_headfake', 
                'detect_microstructure_anomaly'
            ]
            
            found_patterns = [f.name for f in functions if f.name in required_patterns]
            missing_patterns = set(required_patterns) - set(found_patterns)
            
            # Check performance indicators
            performance_issues = []
            for func in functions:
                if 'for' in ast.dump(func):  # Has loops
                    if not any('numpy' in ast.dump(node) or 'np.' in ast.dump(node) 
                             for node in ast.walk(func)):
                        performance_issues.append(f"{func.name}: No NumPy vectorization in loop")
            
            result = {
                "status": "OK" if not missing_patterns and not performance_issues else "WARNING",
                "classes_count": len(classes),
                "functions_count": len(functions),
                "enums": enums,
                "dataclasses": dataclasses,
                "patterns_found": found_patterns,
                "missing_patterns": list(missing_patterns),
                "performance_issues": performance_issues
            }
            
            print(f"✅ Patterns: {len(found_patterns)}/3 found")
            print(f"✅ Classes: {len(classes)} | Functions: {len(functions)}")
            print(f"✅ Enums: {len(enums)} | Dataclasses: {len(dataclasses)}")
            
            if performance_issues:
                print(f"⚠️ Performance issues: {len(performance_issues)}")
                for issue in performance_issues:
                    print(f"   • {issue}")
            
            return result
            
        except Exception as e:
            return {"status": "ERROR", "message": str(e)}
    
    def audit_imports(self) -> Dict[str, Any]:
        """Audit structure imports et circularité"""
        python_files = list(self.project_root.rglob("*.py"))
        python_files = [f for f in python_files if (
            "__pycache__" not in str(f) and
            not f.name.startswith(('audit_', 'fix_', 'quick_', 'emergency_', 'complete_', 'vectorization_', 'precise_', 'windows_', 'ultimate_', 'final_')) and
            f.suffix == '.py'
        )]
        
        import_graph = defaultdict(set)
        import_errors = []
        circular_imports = []
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    source = f.read()
                
                tree = ast.parse(source)
                file_module = str(py_file.relative_to(self.project_root)).replace('\\', '.').replace('/', '.').replace('.py', '')
                
                # Extract imports
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            import_graph[file_module].add(alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            import_graph[file_module].add(node.module)
                
            except Exception as e:
                import_errors.append(f"{py_file}: {str(e)}")
        
        # Check circular imports
        def has_circular_dependency(graph, start, target, visited=None):
            if visited is None:
                visited = set()
            
            if start == target and visited:
                return True
            
            if start in visited:
                return False
            
            visited.add(start)
            
            for neighbor in graph.get(start, []):
                if neighbor.startswith(('core', 'features', 'strategies')):  # Local modules only
                    if has_circular_dependency(graph, neighbor, target, visited.copy()):
                        return True
            
            return False
        
        # Test imports
        import_test_results = []
        for py_file in python_files:
            file_module = str(py_file.relative_to(self.project_root)).replace('\\', '.').replace('/', '.').replace('.py', '')
            
            if file_module.startswith(('core', 'features', 'strategies', 'config')):
                try:
                    # Clear module cache
                    if file_module in sys.modules:
                        del sys.modules[file_module]
                    
                    importlib.import_module(file_module)
                    import_test_results.append((file_module, True, "OK"))
                    
                except Exception as e:
                    import_test_results.append((file_module, False, str(e)))
                    import_errors.append(f"{file_module}: {str(e)}")
        
        # Summary
        total_files = len(python_files)
        successful_imports = sum(1 for _, success, _ in import_test_results if success)
        
        result = {
            "status": "OK" if not import_errors and not circular_imports else "ERROR",
            "total_files": total_files,
            "successful_imports": successful_imports,
            "import_errors": import_errors,
            "circular_imports": circular_imports,
            "import_graph_size": len(import_graph)
        }
        
        print(f"✅ Files: {total_files} | Imports OK: {successful_imports}/{len(import_test_results)}")
        print(f"✅ Import graph: {len(import_graph)} modules")
        
        if import_errors:
            print(f"❌ Import errors: {len(import_errors)}")
            for error in import_errors[:3]:  # Show first 3
                print(f"   • {error}")
        
        return result
    
    def audit_syntax(self) -> Dict[str, Any]:
        """Audit syntax et style Python"""
        python_files = list(self.project_root.rglob("*.py"))
        python_files = [f for f in python_files if (
            "__pycache__" not in str(f) and
            not f.name.startswith(('audit_', 'fix_', 'quick_', 'emergency_', 'complete_', 'vectorization_', 'precise_', 'windows_', 'ultimate_', 'final_')) and
            f.suffix == '.py'
        )]
        
        syntax_errors = []
        style_issues = []
        total_lines = 0
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    source = f.read()
                    lines = source.split('\n')
                    total_lines += len(lines)
                
                # Test syntax
                try:
                    ast.parse(source)
                except SyntaxError as e:
                    syntax_errors.append(f"{py_file}:{e.lineno} - {e.msg}")
                    continue
                
                # Style checks
                for i, line in enumerate(lines, 1):
                    # Line length
                    if len(line) > 120:
                        style_issues.append(f"{py_file}:{i} - Line too long ({len(line)} chars)")
                    
                    # Import style
                    if line.strip().startswith('from') and '*' in line:
                        style_issues.append(f"{py_file}:{i} - Wildcard import")
                    
                    # Magic numbers
                    if any(char.isdigit() for char in line) and '=' in line:
                        if any(num in line for num in ['100', '200', '500', '1000']) and 'ES_TICK' not in line:
                            style_issues.append(f"{py_file}:{i} - Possible magic number")
                
            except Exception as e:
                syntax_errors.append(f"{py_file}: {str(e)}")
        
        result = {
            "status": "OK" if not syntax_errors else "ERROR",
            "total_files": len(python_files),
            "total_lines": total_lines,
            "syntax_errors": syntax_errors,
            "style_issues": style_issues[:10],  # Limit output
            "avg_lines_per_file": total_lines / len(python_files) if python_files else 0
        }
        
        print(f"✅ Files: {len(python_files)} | Lines: {total_lines}")
        print(f"✅ Avg lines/file: {result['avg_lines_per_file']:.1f}")
        
        if syntax_errors:
            print(f"❌ Syntax errors: {len(syntax_errors)}")
            for error in syntax_errors[:3]:
                print(f"   • {error}")
        
        if style_issues:
            print(f"⚠️ Style issues: {len(style_issues)}")
            for issue in style_issues[:3]:
                print(f"   • {issue}")
        
        return result
    
    def audit_vectorization(self) -> Dict[str, Any]:
        """Audit performance et vectorisation NumPy"""
        
        # Files to check for vectorization
        performance_files = [
            "core/battle_navale.py",
            "core/patterns_detector.py", 
            "features/feature_calculator.py"
        ]
        
        vectorization_issues = []
        performance_metrics = {}
        
        for file_path in performance_files:
            full_path = self.project_root / file_path
            
            if not full_path.exists():
                continue
                
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    source = f.read()
                
                tree = ast.parse(source)
                
                # Check for vectorization patterns
                has_numpy = 'import numpy' in source or 'import np' in source
                has_pandas = 'import pandas' in source or 'import pd' in source
                
                # Count loops
                loops = [node for node in ast.walk(tree) if isinstance(node, (ast.For, ast.While))]
                
                # Check list comprehensions vs vectorization
                list_comps = [node for node in ast.walk(tree) if isinstance(node, ast.ListComp)]
                
                # Performance analysis
                if loops and not has_numpy:
                    vectorization_issues.append(f"{file_path}: {len(loops)} loops without NumPy")
                
                if len(list_comps) > 5 and has_pandas:
                    vectorization_issues.append(f"{file_path}: {len(list_comps)} list comprehensions, consider vectorization")
                
                # Manual performance patterns to check
                performance_patterns = {
                    'np.array': source.count('np.array'),
                    'np.mean': source.count('np.mean'),
                    'np.std': source.count('np.std'),
                    'pd.DataFrame': source.count('pd.DataFrame'),
                    'vectorized_ops': source.count('*') + source.count('+') + source.count('-')  # Basic math ops
                }
                
                performance_metrics[file_path] = {
                    'has_numpy': has_numpy,
                    'has_pandas': has_pandas,
                    'loop_count': len(loops),
                    'list_comp_count': len(list_comps),
                    'patterns': performance_patterns
                }
                
            except Exception as e:
                vectorization_issues.append(f"{file_path}: Error analyzing - {str(e)}")
        
        # Test actual performance
        try:
            # Import patterns detector for performance test
            sys.path.insert(0, str(self.project_root))
            from core.patterns_detector import create_patterns_detector
            from core.base_types import MarketData, OrderFlowData
            
            detector = create_patterns_detector()
            
            # Performance test
            start_time = time.perf_counter()
            
            for i in range(100):
                market_data = MarketData(
                    timestamp=pd.Timestamp.now(),
                    symbol="ES",
                    open=4500.0,
                    high=4505.0,
                    low=4498.0,
                    close=4502.0,
                    volume=1500
                )
                
                detector.detect_all_patterns(market_data)
            
            total_time = (time.perf_counter() - start_time) * 1000
            avg_time = total_time / 100
            
            performance_test = {
                "total_time_ms": total_time,
                "avg_time_ms": avg_time,
                "performance_grade": "EXCELLENT" if avg_time < 1.0 else "GOOD" if avg_time < 2.0 else "NEEDS_OPTIMIZATION"
            }
            
        except Exception as e:
            performance_test = {"error": str(e)}
        
        result = {
            "status": "OK" if len(vectorization_issues) < 3 else "WARNING",
            "vectorization_issues": vectorization_issues,
            "performance_metrics": performance_metrics,
            "performance_test": performance_test
        }
        
        print(f"✅ Files analyzed: {len(performance_metrics)}")
        
        if 'avg_time_ms' in performance_test:
            print(f"✅ Performance test: {performance_test['avg_time_ms']:.3f}ms avg")
            print(f"✅ Grade: {performance_test['performance_grade']}")
        
        if vectorization_issues:
            print(f"⚠️ Vectorization issues: {len(vectorization_issues)}")
            for issue in vectorization_issues[:3]:
                print(f"   • {issue}")
        
        return result
    
    def print_audit_summary(self, results: Dict[str, Any]):
        """Print résumé audit complet"""
        print("\n" + "=" * 60)
        print("📊 TECHNICAL AUDIT SUMMARY")
        print("=" * 60)
        
        total_score = 0
        max_score = 4
        
        # Patterns
        patterns_status = results['patterns']['status']
        patterns_score = 1 if patterns_status == 'OK' else 0.5 if patterns_status == 'WARNING' else 0
        total_score += patterns_score
        
        print(f"1️⃣ PATTERNS: {'✅' if patterns_score == 1 else '⚠️' if patterns_score == 0.5 else '❌'} {patterns_status}")
        print(f"   • Classes: {results['patterns']['classes_count']}")
        print(f"   • Functions: {results['patterns']['functions_count']}")
        print(f"   • Patterns found: {len(results['patterns']['patterns_found'])}/3")
        
        # Imports
        imports_status = results['imports']['status']
        imports_score = 1 if imports_status == 'OK' else 0
        total_score += imports_score
        
        print(f"2️⃣ IMPORTS: {'✅' if imports_score == 1 else '❌'} {imports_status}")
        print(f"   • Files: {results['imports']['total_files']}")
        print(f"   • Successful imports: {results['imports']['successful_imports']}")
        print(f"   • Errors: {len(results['imports']['import_errors'])}")
        
        # Syntax
        syntax_status = results['syntax']['status']
        syntax_score = 1 if syntax_status == 'OK' else 0
        total_score += syntax_score
        
        print(f"3️⃣ SYNTAX: {'✅' if syntax_score == 1 else '❌'} {syntax_status}")
        print(f"   • Total lines: {results['syntax']['total_lines']}")
        print(f"   • Avg lines/file: {results['syntax']['avg_lines_per_file']:.1f}")
        print(f"   • Style issues: {len(results['syntax']['style_issues'])}")
        
        # Vectorization
        vectorization_status = results['vectorization']['status']
        vectorization_score = 1 if vectorization_status == 'OK' else 0.5 if vectorization_status == 'WARNING' else 0
        total_score += vectorization_score
        
        print(f"4️⃣ VECTORIZATION: {'✅' if vectorization_score == 1 else '⚠️' if vectorization_score == 0.5 else '❌'} {vectorization_status}")
        
        if 'performance_test' in results['vectorization'] and 'avg_time_ms' in results['vectorization']['performance_test']:
            perf = results['vectorization']['performance_test']
            print(f"   • Performance: {perf['avg_time_ms']:.3f}ms avg ({perf['performance_grade']})")
        
        print(f"   • Issues: {len(results['vectorization']['vectorization_issues'])}")
        
        # Overall score
        overall_percentage = (total_score / max_score) * 100
        
        print(f"\n🎯 OVERALL SCORE: {total_score:.1f}/{max_score} ({overall_percentage:.1f}%)")
        
        if overall_percentage >= 90:
            print("🏆 EXCELLENT - Production ready!")
        elif overall_percentage >= 75:
            print("👍 GOOD - Minor optimizations needed")
        elif overall_percentage >= 60:
            print("⚠️ FAIR - Some issues to fix")
        else:
            print("❌ NEEDS WORK - Critical issues")
        
        return overall_percentage

def run_technical_audit():
    """Run audit technique complet"""
    auditor = TechnicalAuditor()
    results = auditor.run_complete_audit()
    
    return results

if __name__ == "__main__":
    results = run_technical_audit()
    
    # Exit code based on overall quality
    if 'patterns' in results and 'imports' in results:
        patterns_ok = results['patterns']['status'] in ['OK', 'WARNING']
        imports_ok = results['imports']['status'] == 'OK'
        syntax_ok = results['syntax']['status'] == 'OK'
        
        if patterns_ok and imports_ok and syntax_ok:
            print("\n✅ AUDIT PASSED - Ready for Phase 3!")
            exit(0)
        else:
            print("\n❌ AUDIT FAILED - Fix issues before Phase 3!")
            exit(1)
    else:
        exit(1)