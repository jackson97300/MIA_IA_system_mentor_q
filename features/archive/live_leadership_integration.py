#!/usr/bin/env python3
"""
ğŸ”— LIVE LEADERSHIP INTEGRATION - MIA_IA_SYSTEM
IntÃ©gration temps rÃ©el du systÃ¨me de leadership avec les flux de marchÃ©
- Connexion IBKR + Sierra en temps rÃ©el
- Injection du ConfluenceIntegrator dans le pipeline
- Monitoring des dÃ©cisions live
- Validation de la logique Fort/Faible
- Logging structurÃ© pour audit
"""

import sys
import time
import asyncio
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass
from collections import deque

# Ajouter le chemin du projet
sys.path.append(str(Path(__file__).parent.parent))

from core.logger import get_logger
from features.confluence_integrator import ConfluenceIntegrator, ConfluenceResult
from features.market_state_analyzer import MarketState
from features.leadership_engine import LeadershipResult

logger = get_logger(__name__)

@dataclass
class LiveMarketData:
    """DonnÃ©es de marchÃ© en temps rÃ©el"""
    timestamp: datetime
    es_data: Dict[str, Any]  # DonnÃ©es ES depuis IBKR/Sierra
    nq_data: Dict[str, Any]  # DonnÃ©es NQ depuis IBKR/Sierra
    bias: str                # Biais actuel ('bullish', 'bearish', 'neutral')
    instrument: str          # Instrument cible ('ES', 'NQ')
    gamma_levels: Optional[List[float]] = None
    vwap: Optional[float] = None
    additional_signals: Optional[Dict[str, float]] = None

@dataclass
class LiveDecision:
    """DÃ©cision de trading en temps rÃ©el"""
    timestamp: datetime
    market_data: LiveMarketData
    confluence_result: ConfluenceResult
    execution_latency_ms: float
    decision_id: str

class LiveLeadershipIntegration:
    """IntÃ©gration temps rÃ©el du systÃ¨me de leadership"""
    
    def __init__(self, 
                 ibkr_connector=None,
                 sierra_connector=None,
                 decision_callback: Optional[Callable[[LiveDecision], None]] = None):
        """
        Initialise l'intÃ©gration temps rÃ©el
        
        Args:
            ibkr_connector: Connecteur IBKR (Ã  implÃ©menter)
            sierra_connector: Connecteur Sierra (Ã  implÃ©menter)
            decision_callback: Callback appelÃ© Ã  chaque dÃ©cision
        """
        self.ibkr_connector = ibkr_connector
        self.sierra_connector = sierra_connector
        self.decision_callback = decision_callback
        
        # PATCH: IntÃ©grateur avec calibration YAML
        self.integrator = ConfluenceIntegrator()
        
        # Monitoring temps rÃ©el
        self.decision_history = deque(maxlen=1000)
        self.start_time = datetime.now()
        self.decision_count = 0
        self.valid_decisions = 0
        self.rejected_decisions = 0
        
        # Configuration monitoring
        self.monitoring_interval = 60  # secondes
        self.last_monitoring = datetime.now()
        
        logger.info("ğŸ”— LiveLeadershipIntegration initialisÃ©")
        logger.info(f"  ğŸ“Š Monitoring interval: {self.monitoring_interval}s")
        logger.info(f"  ğŸ“ˆ Decision history size: {self.decision_history.maxlen}")
    
    async def start_live_integration(self, 
                                   symbols: List[str] = ['ES', 'NQ'],
                                   update_interval_ms: int = 1000):
        """
        DÃ©marre l'intÃ©gration temps rÃ©el
        
        Args:
            symbols: Symboles Ã  monitorer
            update_interval_ms: Intervalle de mise Ã  jour en ms
        """
        logger.info(f"ğŸš€ DÃ©marrage intÃ©gration temps rÃ©el")
        logger.info(f"  ğŸ“Š Symboles: {symboles}")
        logger.info(f"  â±ï¸ Intervalle: {update_interval_ms}ms")
        
        try:
            # Connexion aux flux de donnÃ©es
            await self._connect_data_sources(symbols)
            
            # Boucle principale d'intÃ©gration
            cycle_count = 0
            logger.info("ğŸ”„ DÃ©but de la boucle principale...")
            
            while True:
                start_time = time.time()
                cycle_count += 1
                
                logger.info(f"ğŸ”„ Cycle {cycle_count} - RÃ©cupÃ©ration donnÃ©es...")
                
                # 1. RÃ©cupÃ©rer les donnÃ©es temps rÃ©el
                market_data = await self._fetch_live_market_data(symbols)
                
                if market_data:
                    logger.info(f"ğŸ“Š DonnÃ©es reÃ§ues: {market_data.bias} {market_data.instrument}")
                    
                    # 2. Calculer la confluence avec leadership
                    decision = await self._process_market_data(market_data)
                    
                    # 3. Appliquer la dÃ©cision
                    if decision:
                        await self._apply_decision(decision)
                else:
                    logger.warning("âš ï¸ Aucune donnÃ©e de marchÃ© reÃ§ue")
                
                # 4. Monitoring pÃ©riodique
                await self._periodic_monitoring()
                
                # 5. ContrÃ´le de latence
                elapsed_ms = (time.time() - start_time) * 1000
                if elapsed_ms > update_interval_ms:
                    logger.warning(f"âš ï¸ Latence Ã©levÃ©e: {elapsed_ms:.1f}ms > {update_interval_ms}ms")
                
                # 6. Attendre le prochain cycle
                sleep_time = max(0.001, (update_interval_ms - elapsed_ms) / 1000)
                logger.info(f"â±ï¸ Attente {sleep_time:.3f}s avant prochain cycle")
                await asyncio.sleep(sleep_time)
                
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ ArrÃªt demandÃ© par l'utilisateur")
        except Exception as e:
            logger.error(f"âŒ Erreur intÃ©gration temps rÃ©el: {e}")
            import traceback
            logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
        finally:
            await self._cleanup()
    
    async def _connect_data_sources(self, symbols: List[str]):
        """Connecte aux sources de donnÃ©es temps rÃ©el"""
        logger.info("ğŸ”Œ Connexion aux sources de donnÃ©es...")
        
        # TODO: ImplÃ©menter la connexion IBKR
        if self.ibkr_connector:
            try:
                # await self.ibkr_connector.connect()
                logger.info("âœ… Connexion IBKR Ã©tablie")
            except Exception as e:
                logger.error(f"âŒ Erreur connexion IBKR: {e}")
        
        # TODO: ImplÃ©menter la connexion Sierra
        if self.sierra_connector:
            try:
                # await self.sierra_connector.connect()
                logger.info("âœ… Connexion Sierra Ã©tablie")
            except Exception as e:
                logger.error(f"âŒ Erreur connexion Sierra: {e}")
        
        logger.info("ğŸ”Œ Connexions Ã©tablies")
    
    async def _fetch_live_market_data(self, symbols: List[str]) -> Optional[LiveMarketData]:
        """RÃ©cupÃ¨re les donnÃ©es de marchÃ© temps rÃ©el"""
        try:
            # TODO: Remplacer par les vraies donnÃ©es IBKR/Sierra
            # Pour l'instant, simulation avec donnÃ©es de test
            now = datetime.now()
            
            # Simulation donnÃ©es ES
            es_data = {
                'close': 6397.5 + (now.second % 60) * 0.1,
                'volume': 1000 + (now.second % 30) * 10,
                'bid': 6397.0,
                'ask': 6398.0,
                'timestamp': now
            }
            
            # Simulation donnÃ©es NQ
            nq_data = {
                'close': 23246.0 + (now.second % 60) * 0.2,
                'volume': 800 + (now.second % 30) * 8,
                'bid': 23245.5,
                'ask': 23246.5,
                'timestamp': now
            }
            
            # Simulation biais et instrument (rotation pour test)
            bias_cycle = ['bullish', 'bearish', 'neutral']
            instrument_cycle = ['ES', 'NQ']
            
            bias = bias_cycle[(now.second // 20) % len(bias_cycle)]
            instrument = instrument_cycle[(now.second // 15) % len(instrument_cycle)]
            
            return LiveMarketData(
                timestamp=now,
                es_data=es_data,
                nq_data=nq_data,
                bias=bias,
                instrument=instrument,
                gamma_levels=[6400, 6450, 6500],
                vwap=6398.0,
                additional_signals={
                    'gamma_proximity': 0.7,
                    'volume_confirmation': 0.8,
                    'vwap_trend': 0.6,
                    'options_flow': 0.5,
                    'order_book_imbalance': 0.4
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration donnÃ©es temps rÃ©el: {e}")
            return None
    
    async def _process_market_data(self, market_data: LiveMarketData) -> Optional[LiveDecision]:
        """Traite les donnÃ©es de marchÃ© et gÃ©nÃ¨re une dÃ©cision"""
        try:
            start_time = time.time()
            
            # Convertir les donnÃ©es en format attendu par l'intÃ©grateur
            processed_data = self._convert_to_integrator_format(market_data)
            
            # Calculer la confluence avec leadership
            confluence_result = self.integrator.calculate_confluence_with_leadership(processed_data)
            
            # Calculer la latence
            execution_latency_ms = (time.time() - start_time) * 1000
            
            # CrÃ©er la dÃ©cision
            decision = LiveDecision(
                timestamp=market_data.timestamp,
                market_data=market_data,
                confluence_result=confluence_result,
                execution_latency_ms=execution_latency_ms,
                decision_id=f"DEC_{self.decision_count:06d}"
            )
            
            # Mettre Ã  jour les statistiques
            self.decision_count += 1
            if confluence_result.is_valid:
                self.valid_decisions += 1
            else:
                self.rejected_decisions += 1
            
            # Ajouter Ã  l'historique
            self.decision_history.append(decision)
            
            # Logging de la dÃ©cision
            self._log_live_decision(decision)
            
            return decision
            
        except Exception as e:
            logger.error(f"âŒ Erreur traitement donnÃ©es marchÃ©: {e}")
            return None
    
    def _convert_to_integrator_format(self, market_data: LiveMarketData) -> Dict[str, Any]:
        """Convertit les donnÃ©es temps rÃ©el au format attendu par l'intÃ©grateur"""
        import pandas as pd
        
        # CrÃ©er des DataFrames simulÃ©es (Ã  remplacer par vraies donnÃ©es)
        dates = pd.date_range(market_data.timestamp - timedelta(minutes=100), 
                             market_data.timestamp, freq='1min')
        
        # ES DataFrame
        es_df = pd.DataFrame({
            'close': [market_data.es_data['close'] - i*0.1 for i in range(len(dates))],
            'volume': [market_data.es_data['volume'] - i*5 for i in range(len(dates))],
            'buy_volume': [market_data.es_data['volume']*0.6 - i*3 for i in range(len(dates))],
            'sell_volume': [market_data.es_data['volume']*0.4 - i*2 for i in range(len(dates))]
        }, index=dates)
        
        # NQ DataFrame
        nq_df = pd.DataFrame({
            'close': [market_data.nq_data['close'] - i*0.2 for i in range(len(dates))],
            'volume': [market_data.nq_data['volume'] - i*4 for i in range(len(dates))],
            'buy_volume': [market_data.nq_data['volume']*0.6 - i*2.4 for i in range(len(dates))],
            'sell_volume': [market_data.nq_data['volume']*0.4 - i*1.6 for i in range(len(dates))]
        }, index=dates)
        
        return {
            'ES': es_df,
            'NQ': nq_df,
            'bias': market_data.bias,
            'symbol': market_data.instrument,
            'now': market_data.timestamp,
            'gamma_levels': market_data.gamma_levels,
            'vwap': market_data.vwap,
            **market_data.additional_signals
        }
    
    async def _apply_decision(self, decision: LiveDecision):
        """Applique la dÃ©cision de trading"""
        try:
            if decision.confluence_result.is_valid:
                logger.info(f"ğŸ¯ EXÃ‰CUTION: {decision.decision_id}")
                logger.info(f"  ğŸ“Š Score final: {decision.confluence_result.final_score:.3f}")
                logger.info(f"  ğŸ¯ Instrument: {decision.market_data.instrument}")
                logger.info(f"  ğŸ“ˆ Biais: {decision.market_data.bias}")
                
                # TODO: ImplÃ©menter l'exÃ©cution rÃ©elle
                # await self._execute_trade(decision)
                
            else:
                logger.info(f"âŒ REJET: {decision.decision_id}")
                logger.info(f"  ğŸ“ Raison: {decision.confluence_result.reason}")
            
            # Appeler le callback si dÃ©fini
            if self.decision_callback:
                await self.decision_callback(decision)
                
        except Exception as e:
            logger.error(f"âŒ Erreur application dÃ©cision: {e}")
    
    def _log_live_decision(self, decision: LiveDecision):
        """Log une dÃ©cision temps rÃ©el"""
        try:
            result = decision.confluence_result
            market_data = decision.market_data
            
            status = "âœ… VALID" if result.is_valid else "âŒ REJECT"
            
            logger.info(f"{status} | {decision.decision_id} | Latency: {decision.execution_latency_ms:.1f}ms")
            logger.info(f"  ğŸ“Š Bias: {market_data.bias} | Instrument: {market_data.instrument}")
            logger.info(f"  ğŸ¯ Leader: {result.leadership_result.leader} | Force: {result.leadership_result.strength:.3f}")
            logger.info(f"  ğŸ”— Corr: {result.market_state.corr_15m:.3f} ({result.market_state.corr_regime})")
            logger.info(f"  ğŸ’° Final Score: {result.final_score:.3f} | Risk Mult: {result.risk_multiplier:.3f}")
            
        except Exception as e:
            logger.error(f"âŒ Erreur logging dÃ©cision live: {e}")
    
    async def _periodic_monitoring(self):
        """Monitoring pÃ©riodique du systÃ¨me"""
        now = datetime.now()
        if (now - self.last_monitoring).total_seconds() >= self.monitoring_interval:
            self._log_monitoring_stats()
            self.last_monitoring = now
    
    def _log_monitoring_stats(self):
        """Log les statistiques de monitoring"""
        try:
            uptime = (datetime.now() - self.start_time).total_seconds()
            valid_rate = self.valid_decisions / max(self.decision_count, 1)
            reject_rate = self.rejected_decisions / max(self.decision_count, 1)
            
            # Statistiques de l'intÃ©grateur
            integrator_stats = self.integrator.get_statistics()
            
            logger.info("ğŸ“Š MONITORING STATS:")
            logger.info(f"  â±ï¸ Uptime: {uptime:.0f}s")
            logger.info(f"  ğŸ“ˆ Total decisions: {self.decision_count}")
            logger.info(f"  âœ… Valid rate: {valid_rate:.1%}")
            logger.info(f"  âŒ Reject rate: {reject_rate:.1%}")
            logger.info(f"  ğŸ”— Leadership pass rate: {integrator_stats['leadership_stats']['pass_rate']:.1%}")
            logger.info(f"  âš¡ Latency exceeded: {integrator_stats['latency_exceeded_rate']:.1%}")
            
            # DerniÃ¨res dÃ©cisions
            if self.decision_history:
                recent_decisions = list(self.decision_history)[-5:]
                logger.info("ğŸ“œ RÃ‰CENTES DÃ‰CISIONS:")
                for decision in recent_decisions:
                    status = "âœ…" if decision.confluence_result.is_valid else "âŒ"
                    logger.info(f"  {status} {decision.decision_id}: {decision.confluence_result.final_score:.3f}")
            
        except Exception as e:
            logger.error(f"âŒ Erreur monitoring stats: {e}")
    
    async def _cleanup(self):
        """Nettoyage Ã  la fin"""
        logger.info("ğŸ§¹ Nettoyage intÃ©gration temps rÃ©el...")
        
        # TODO: Fermer les connexions
        if self.ibkr_connector:
            # await self.ibkr_connector.disconnect()
            pass
        
        if self.sierra_connector:
            # await self.sierra_connector.disconnect()
            pass
        
        logger.info("âœ… Nettoyage terminÃ©")
    
    def get_live_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques temps rÃ©el"""
        return {
            'uptime_seconds': (datetime.now() - self.start_time).total_seconds(),
            'decision_count': self.decision_count,
            'valid_decisions': self.valid_decisions,
            'rejected_decisions': self.rejected_decisions,
            'valid_rate': self.valid_decisions / max(self.decision_count, 1),
            'reject_rate': self.rejected_decisions / max(self.decision_count, 1),
            'integrator_stats': self.integrator.get_statistics(),
            'recent_decisions': list(self.decision_history)[-10:]
        }

async def test_live_integration():
    """Test de l'intÃ©gration temps rÃ©el"""
    logger.info("ğŸ§® TEST LIVE LEADERSHIP INTEGRATION")
    logger.info("=" * 50)
    
    # Initialiser l'intÃ©gration
    integration = LiveLeadershipIntegration()
    
    # Callback pour les dÃ©cisions
    async def decision_callback(decision: LiveDecision):
        logger.info(f"ğŸ”” CALLBACK: DÃ©cision {decision.decision_id} reÃ§ue")
    
    integration.decision_callback = decision_callback
    
    # DÃ©marrer l'intÃ©gration (simulation 30 secondes)
    logger.info("ğŸš€ DÃ©marrage simulation 30 secondes...")
    
    try:
        # Lancer l'intÃ©gration en arriÃ¨re-plan
        task = asyncio.create_task(
            integration.start_live_integration(update_interval_ms=2000)
        )
        
        # Attendre 30 secondes
        await asyncio.sleep(30)
        
        # Annuler la tÃ¢che
        task.cancel()
        
    except asyncio.CancelledError:
        logger.info("âœ… Simulation terminÃ©e")
    
    # Statistiques finales
    stats = integration.get_live_statistics()
    logger.info("\nğŸ“‹ STATISTIQUES FINALES:")
    logger.info(f"  â±ï¸ Uptime: {stats['uptime_seconds']:.0f}s")
    logger.info(f"  ğŸ“ˆ Total decisions: {stats['decision_count']}")
    logger.info(f"  âœ… Valid rate: {stats['valid_rate']:.1%}")
    logger.info(f"  âŒ Reject rate: {stats['reject_rate']:.1%}")

if __name__ == "__main__":
    asyncio.run(test_live_integration())
