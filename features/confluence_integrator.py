#!/usr/bin/env python3
"""
ğŸ¯ CONFLUENCE INTEGRATOR - MIA_IA_SYSTEM
========================================

Module d'intÃ©gration confluence extrait du fichier monstre
- Calcul de confluence avec leadership
- IntÃ©gration des scores multiples
- Validation des signaux
- Gestion des seuils adaptatifs
"""

import sys
# import random  # SupprimÃ© - plus de valeurs alÃ©atoires
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

# Ajouter le chemin du projet
sys.path.append(str(Path(__file__).parent.parent))

from core.logger import get_logger

# ğŸ†• Imports MenthorQ
from features.menthorq_dealers_bias import create_menthorq_dealers_bias_analyzer
from features.menthorq_integration import get_menthorq_confluence

# ğŸ†• Import configuration centralisÃ©e
try:
    from config.menthorq_rules_loader import get_menthorq_rules, is_hard_rule_enabled, get_leadership_threshold
    MENTHORQ_RULES_AVAILABLE = True
except ImportError:
    MENTHORQ_RULES_AVAILABLE = False

# ğŸ†• Import filtre de leadership amÃ©liorÃ©
try:
    from features.leadership_zmom import LeadershipZMom
    ENHANCED_LEADERSHIP_FILTER_AVAILABLE = True
except ImportError:
    ENHANCED_LEADERSHIP_FILTER_AVAILABLE = False

# ğŸ†• Imports Advanced Features
try:
    from features.advanced import AdvancedFeaturesSuite, create_advanced_features_suite
    ADVANCED_FEATURES_AVAILABLE = True
except ImportError:
    ADVANCED_FEATURES_AVAILABLE = False

logger = get_logger(__name__)

@dataclass
class ConfluenceResult:
    """RÃ©sultat de calcul de confluence"""
    base_score: float
    leadership_gate: float
    risk_multiplier: float
    final_score: float
    is_valid: bool
    decision: str
    leader: Optional[str]
    confidence: float
    alignment: str
    # ğŸ†• MenthorQ Dealer's Bias
    menthorq_bias_score: float = 0.0
    menthorq_bias_direction: str = "NEUTRAL"
    menthorq_bias_strength: str = "UNKNOWN"
    menthorq_confluence_score: float = 0.0
    # ğŸ†• Advanced Features
    advanced_features_score: float = 0.0
    advanced_features_data: Dict[str, Any] = None

class ConfluenceIntegrator:
    """IntÃ©grateur de confluence avec leadership"""
    
    def __init__(self, config=None):
        self.config = config or {}
        self.last_confluence_score = 0.0
        self.confluence_history = []
        
        # ğŸ†• Synchronisation ES/NQ
        self.es_nq_sync_buffer = {
            'ES': [],
            'NQ': []
        }
        self.sync_tolerance_seconds = self.config.get('sync_tolerance_seconds', 5.0)
        self.max_buffer_size = self.config.get('max_sync_buffer_size', 100)
        
        # ğŸ†• MenthorQ Dealer's Bias Analyzer
        try:
            self.menthorq_bias_analyzer = create_menthorq_dealers_bias_analyzer()
            if self.menthorq_bias_analyzer:
                logger.info("âœ… MenthorQDealersBiasAnalyzer intÃ©grÃ© dans ConfluenceIntegrator")
            else:
                logger.warning("âš ï¸ MenthorQDealersBiasAnalyzer non disponible")
                self.menthorq_bias_analyzer = None
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation MenthorQDealersBiasAnalyzer: {e}")
            self.menthorq_bias_analyzer = None
        
        # ğŸ†• Advanced Features Suite
        if ADVANCED_FEATURES_AVAILABLE:
            try:
                self.advanced_features = create_advanced_features_suite(self.config)
                logger.info("âœ… Advanced Features Suite intÃ©grÃ© dans ConfluenceIntegrator (+7% win rate)")
            except Exception as e:
                logger.warning(f"âš ï¸ Erreur init Advanced Features: {e}")
                self.advanced_features = None
        else:
            self.advanced_features = None
        
        logger.info("ğŸ¯ Confluence Integrator initialisÃ© avec synchronisation ES/NQ + MenthorQ + Advanced Features")
    
    def calculate_confluence_with_leadership(self, market_data: Dict[str, Any]) -> ConfluenceResult:
        """Calcule la confluence avec intÃ©gration leadership"""
        try:
            # ğŸ†• Synchronisation ES/NQ
            synchronized_data = self._synchronize_es_nq_data(market_data)
            
            # Extraction des donnÃ©es synchronisÃ©es
            es_data = synchronized_data.get('ES', {})
            nq_data = synchronized_data.get('NQ', {})
            bias = market_data.get('bias', 'neutral')
            session = market_data.get('session', 'unknown')
            
            # Calcul du score de base avec donnÃ©es synchronisÃ©es
            base_score = self._calculate_base_confluence_score(es_data, nq_data, bias)
            
            # Calcul du leadership gate
            leadership_gate = self._calculate_leadership_gate(es_data, nq_data)
            
            # Calcul du multiplicateur de risque
            risk_multiplier = self._calculate_risk_multiplier(session, bias)
            
            # ğŸ†• Calcul du Dealer's Bias MenthorQ
            menthorq_bias_score, menthorq_bias_direction, menthorq_bias_strength, menthorq_confluence_score = self._calculate_menthorq_bias(es_data)
            
            # ğŸ†• Calcul des Advanced Features
            advanced_features_score, advanced_features_data = self._calculate_advanced_features(es_data)
            
            # Score final avec intÃ©gration leadership + MenthorQ + Advanced Features
            menthorq_multiplier = self._calculate_menthorq_multiplier(menthorq_bias_score, menthorq_bias_strength)
            advanced_multiplier = self._calculate_advanced_multiplier(advanced_features_score)
            final_score = base_score * leadership_gate * risk_multiplier * menthorq_multiplier * advanced_multiplier
            
            # Validation du signal
            is_valid = self._validate_confluence_signal(final_score, leadership_gate)
            
            # DÃ©cision
            decision = self._make_decision(final_score, is_valid)
            
            # DÃ©termination du leader
            leader = self._determine_leader(es_data, nq_data, leadership_gate)
            
            # Alignement
            alignment = self._determine_alignment(final_score, leadership_gate)
            
            # Confiance
            confidence = min(1.0, final_score * 1.5)
            
            # CrÃ©er le rÃ©sultat
            result = ConfluenceResult(
                base_score=base_score,
                leadership_gate=leadership_gate,
                risk_multiplier=risk_multiplier,
                final_score=final_score,
                is_valid=is_valid,
                decision=decision,
                leader=leader,
                confidence=confidence,
                alignment=alignment,
                # ğŸ†• MenthorQ Dealer's Bias
                menthorq_bias_score=menthorq_bias_score,
                menthorq_bias_direction=menthorq_bias_direction,
                menthorq_bias_strength=menthorq_bias_strength,
                menthorq_confluence_score=menthorq_confluence_score,
                # ğŸ†• Advanced Features
                advanced_features_score=advanced_features_score,
                advanced_features_data=advanced_features_data
            )
            
            # Sauvegarder l'historique
            self.confluence_history.append({
                'timestamp': datetime.now(),
                'result': result,
                'market_data': market_data
            })
            
            # Limiter l'historique
            if len(self.confluence_history) > 100:
                self.confluence_history = self.confluence_history[-100:]
            
            logger.info(f"ğŸ¯ Confluence calculÃ©e: {final_score:.3f} (base: {base_score:.3f}, gate: {leadership_gate:.3f})")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul confluence: {e}")
            return self._create_fallback_result()
    
    def _calculate_base_confluence_score(self, es_data: Dict, nq_data: Dict, bias: str) -> float:
        """Calcule le score de confluence de base"""
        try:
            # Scores individuels
            es_score = self._calculate_instrument_score(es_data, 'ES')
            nq_score = self._calculate_instrument_score(nq_data, 'NQ')
            
            # Score de corrÃ©lation
            correlation_score = self._calculate_correlation_score(es_data, nq_data)
            
            # Score de biais
            bias_score = self._calculate_bias_score(bias)
            
            # Score composite
            base_score = (
                es_score * 0.3 +
                nq_score * 0.3 +
                correlation_score * 0.25 +
                bias_score * 0.15
            )
            
            return max(0.0, min(1.0, base_score))
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul score base: {e}")
            return 0.5
    
    def _is_valid_data(self, data: Any) -> bool:
        """VÃ©rifie si les donnÃ©es sont valides (Ã©vite l'erreur DataFrame ambiguous)"""
        try:
            if data is None:
                return False
            
            # Gestion des DataFrames pandas
            if hasattr(data, 'iloc'):
                return len(data) > 0
            
            # Gestion des dictionnaires
            if isinstance(data, dict):
                return len(data) > 0
            
            # Gestion des listes
            if isinstance(data, list):
                return len(data) > 0
            
            return bool(data)
            
        except Exception:
            return False
    
    def _calculate_instrument_score(self, data: Dict, symbol: str) -> float:
        """Calcule le score pour un instrument"""
        try:
            # DonnÃ©es simulÃ©es si pas de donnÃ©es rÃ©elles
            if not self._is_valid_data(data):
                return 0.6  # Score neutre dÃ©terministe
            
            # ğŸ”§ CORRECTION: Gestion des DataFrames pandas
            import pandas as pd
            if isinstance(data, pd.DataFrame):
                # Extraire les derniÃ¨res donnÃ©es du DataFrame
                if len(data) > 0:
                    latest = data.iloc[-1]
                    volume = latest.get('volume', 1000)
                    close = latest.get('close', 4500.0 if symbol == 'ES' else 15000.0)
                    
                    # Calculer la volatilitÃ© basÃ©e sur high/low
                    high = latest.get('high', close + 5)
                    low = latest.get('low', close - 5)
                    volatility = (high - low) / close if close > 0 else 0.01
                    
                    # Calculer le momentum basÃ© sur open/close
                    open_price = latest.get('open', close)
                    momentum = (close - open_price) / open_price if open_price > 0 else 0.0
                    
                    # Score composite amÃ©liorÃ©
                    volume_score = min(1.0, volume / 1000.0)
                    price_score = 0.5 + (close - (4500.0 if symbol == 'ES' else 15000.0)) / 1000.0
                    volatility_score = 1.0 - abs(volatility - 0.01)  # Optimal Ã  1%
                    momentum_score = abs(momentum)
                    
                    return (volume_score * 0.4 + price_score * 0.2 + volatility_score * 0.2 + momentum_score * 0.2)
                else:
                    return 0.5  # Score neutre dÃ©terministe
            
            # Traitement des dictionnaires (ancien format)
            volume = data.get('volume', 1000)
            price = data.get('price', 4500.0 if symbol == 'ES' else 15000.0)
            
            # Normalisation
            volume_score = min(1.0, volume / 1000.0)
            price_score = 0.5 + (price - (4500.0 if symbol == 'ES' else 15000.0)) / 1000.0
            
            return (volume_score * 0.6 + price_score * 0.4)
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul score instrument {symbol}: {e}")
            return 0.5
    
    def _calculate_correlation_score(self, es_data: Dict, nq_data: Dict) -> float:
        """Calcule le score de corrÃ©lation ES/NQ"""
        try:
            # ğŸ”§ CORRECTION: Calcul de corrÃ©lation rÃ©elle avec DataFrames
            import pandas as pd
            import numpy as np
            
            if isinstance(es_data, pd.DataFrame) and isinstance(nq_data, pd.DataFrame):
                if self._is_valid_data(es_data) and self._is_valid_data(nq_data) and len(es_data) > 5 and len(nq_data) > 5:
                    # Utiliser les prix de clÃ´ture pour la corrÃ©lation
                    es_prices = es_data['close'].values
                    nq_prices = nq_data['close'].values
                    
                    # S'assurer que les arrays ont la mÃªme longueur
                    min_len = min(len(es_prices), len(nq_prices))
                    es_prices = es_prices[-min_len:]
                    nq_prices = nq_prices[-min_len:]
                    
                    # Calculer la corrÃ©lation
                    if min_len > 2:
                        correlation = np.corrcoef(es_prices, nq_prices)[0, 1]
                        
                        # Gestion des valeurs NaN
                        if np.isnan(correlation):
                            logger.warning("âš ï¸ CorrÃ©lation NaN dÃ©tectÃ©e â†’ 0.0")
                            return 0.0
                        
                        return max(0.0, min(1.0, abs(correlation)))
                    else:
                        logger.warning("âš ï¸ Pas assez de donnÃ©es pour corrÃ©lation â†’ score neutre")
                        return 0.85  # Score dÃ©terministe
                else:
                    logger.warning("âš ï¸ DataFrames trop courts â†’ score neutre")
                    return 0.85  # Score dÃ©terministe
            
            # Fallback: Score de corrÃ©lation dÃ©terministe
            base_correlation = 0.85
            correlation = base_correlation  # Score dÃ©terministe
            
            # Gestion des valeurs NaN
            if correlation != correlation:  # NaN check
                logger.warning("âš ï¸ CorrÃ©lation NaN dÃ©tectÃ©e â†’ 0.0")
                return 0.0
            
            return max(0.0, min(1.0, abs(correlation)))
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul corrÃ©lation: {e}")
            return 0.5
    
    def _calculate_bias_score(self, bias: str) -> float:
        """Calcule le score de biais"""
        try:
            bias_scores = {
                'bullish': 0.8,
                'bearish': 0.2,
                'neutral': 0.5
            }
            
            return bias_scores.get(bias, 0.5)
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul biais: {e}")
            return 0.5
    
    def _calculate_leadership_gate(self, es_data: Dict, nq_data: Dict) -> float:
        """Calcule le gate de leadership"""
        try:
            # Analyse de leadership basique
            es_strength = self._calculate_leadership_strength(es_data, 'ES')
            nq_strength = self._calculate_leadership_strength(nq_data, 'NQ')
            
            # Gate basÃ© sur la diffÃ©rence de force
            strength_diff = abs(es_strength - nq_strength)
            leadership_gate = 0.5 + (strength_diff * 0.5)
            
            return max(0.1, min(1.0, leadership_gate))
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul leadership gate: {e}")
            return 0.5
    
    def _calculate_leadership_strength(self, data: Dict, symbol: str) -> float:
        """Calcule la force de leadership d'un instrument"""
        try:
            if not self._is_valid_data(data):
                return 0.5  # Score neutre dÃ©terministe
            
            # ğŸ”§ CORRECTION: Gestion des DataFrames pandas
            import pandas as pd
            if isinstance(data, pd.DataFrame):
                if len(data) > 0:
                    latest = data.iloc[-1]
                    
                    # Extraire les donnÃ©es du DataFrame
                    volume = latest.get('volume', 1000)
                    close = latest.get('close', 4500.0 if symbol == 'ES' else 15000.0)
                    high = latest.get('high', close + 5)
                    low = latest.get('low', close - 5)
                    open_price = latest.get('open', close)
                    
                    # Calculer les facteurs
                    volatility = (high - low) / close if close > 0 else 0.01
                    momentum = (close - open_price) / open_price if open_price > 0 else 0.0
                    
                    # Score composite
                    volume_factor = min(1.0, volume / 1000.0)
                    volatility_factor = 1.0 - abs(volatility - 0.01)  # Optimal Ã  1%
                    momentum_factor = abs(momentum)
                    
                    strength = (
                        volume_factor * 0.4 +
                        volatility_factor * 0.3 +
                        momentum_factor * 0.3
                    )
                    
                    return max(0.0, min(1.0, strength))
                else:
                    return 0.5  # Score neutre dÃ©terministe
            
            # Traitement des dictionnaires (ancien format)
            volume = data.get('volume', 1000)
            volatility = data.get('volatility', 0.5)
            momentum = data.get('momentum', 0.0)
            
            # Score composite
            volume_factor = min(1.0, volume / 1000.0)
            volatility_factor = 1.0 - abs(volatility - 0.5)  # Optimal Ã  0.5
            momentum_factor = abs(momentum)
            
            strength = (
                volume_factor * 0.4 +
                volatility_factor * 0.3 +
                momentum_factor * 0.3
            )
            
            return max(0.0, min(1.0, strength))
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul force leadership {symbol}: {e}")
            return 0.5
    
    def _calculate_risk_multiplier(self, session: str, bias: str) -> float:
        """Calcule le multiplicateur de risque"""
        try:
            # Multiplicateurs par session
            session_multipliers = {
                'london_session': 1.2,
                'new_york_session': 1.0,
                'asian_session': 0.8,
                'unknown': 1.0
            }
            
            # Multiplicateurs par biais
            bias_multipliers = {
                'bullish': 1.1,
                'bearish': 0.9,
                'neutral': 1.0
            }
            
            session_mult = session_multipliers.get(session, 1.0)
            bias_mult = bias_multipliers.get(bias, 1.0)
            
            return session_mult * bias_mult
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul multiplicateur risque: {e}")
            return 1.0
    
    def _validate_confluence_signal(self, final_score: float, leadership_gate: float) -> bool:
        """Valide le signal de confluence avec filtre de leadership"""
        try:
            # Seuils de validation
            min_score = self.config.get('min_confluence_score', 0.3)
            min_leadership = self.config.get('min_leadership_gate', 0.4)
            
            # Validation de base
            score_valid = final_score >= min_score
            leadership_valid = leadership_gate >= min_leadership
            
            # ğŸ†• FILTRE DE LEADERSHIP : Ã‰viter les signaux contre-tendance du leader
            leadership_filter = self._apply_leadership_filter(final_score, leadership_gate)
            
            return score_valid and leadership_valid and leadership_filter
            
        except Exception as e:
            logger.error(f"âŒ Erreur validation confluence: {e}")
            return False
    
    def _apply_leadership_filter(self, final_score: float, leadership_gate: float) -> bool:
        """ğŸ›¡ï¸ Filtre de leadership pour Ã©viter les signaux contre-tendance"""
        try:
            # ğŸ†• Utiliser le filtre amÃ©liorÃ© si disponible
            if ENHANCED_LEADERSHIP_FILTER_AVAILABLE:
                return self._apply_leadership_filter_enhanced(final_score, leadership_gate)
            elif MENTHORQ_RULES_AVAILABLE:
                return self._apply_leadership_filter_with_config(final_score, leadership_gate)
            else:
                return self._apply_leadership_filter_legacy(final_score, leadership_gate)
            
        except Exception as e:
            logger.error(f"âŒ Erreur filtre leadership: {e}")
            return True
    
    def _apply_leadership_filter_enhanced(self, final_score: float, leadership_gate: float) -> bool:
        """ğŸ›¡ï¸ Filtre de leadership amÃ©liorÃ© avec blocage explicite"""
        try:
            # RÃ©cupÃ©rer le filtre amÃ©liorÃ©
            enhanced_filter = LeadershipZMom()
            
            # RÃ©cupÃ©rer les donnÃ©es du leader
            leader = self._get_current_leader()
            leader_trend = self._get_leader_trend(leader) if leader else None
            
            # RÃ©cupÃ©rer les donnÃ©es VIX (simulÃ©es pour l'instant)
            vix_level = 20.0  # TODO: RÃ©cupÃ©rer depuis les donnÃ©es rÃ©elles
            vix_regime = "normal"  # TODO: Calculer depuis les donnÃ©es rÃ©elles
            
            # Appliquer le filtre amÃ©liorÃ©
            filter_result = enhanced_filter.filter_signal(
                signal_score=final_score,
                leadership_gate=leadership_gate,
                leader=leader,
                leader_trend=leader_trend,
                vix_level=vix_level,
                vix_regime=vix_regime
            )
            
            # Log du rÃ©sultat
            if filter_result.is_blocked:
                logger.warning(f"ğŸ›¡ï¸ Signal bloquÃ© par filtre amÃ©liorÃ©: {filter_result.block_message}")
                logger.warning(f"ğŸ›¡ï¸ Raison: {filter_result.block_reason.value if filter_result.block_reason else 'Unknown'}")
            else:
                logger.debug(f"ğŸ›¡ï¸ Signal autorisÃ© par filtre amÃ©liorÃ©: {filter_result.block_message}")
            
            return not filter_result.is_blocked
            
        except Exception as e:
            logger.error(f"âŒ Erreur filtre leadership amÃ©liorÃ©: {e}")
            return True
    
    def _apply_leadership_filter_with_config(self, final_score: float, leadership_gate: float) -> bool:
        """ğŸ›¡ï¸ Filtre de leadership avec configuration centralisÃ©e"""
        try:
            # VÃ©rifier si la rÃ¨gle de blocage contra-trend est activÃ©e
            if not is_hard_rule_enabled('leadership_contra_trend'):
                logger.debug("ğŸ›¡ï¸ RÃ¨gle leadership_contra_trend dÃ©sactivÃ©e - tous les signaux acceptÃ©s")
                return True
            
            # RÃ©cupÃ©rer les seuils de la configuration
            leadership_threshold = get_leadership_threshold('strong')  # 0.7 par dÃ©faut
            signal_threshold = get_leadership_threshold('moderate')    # 0.5 par dÃ©faut
            
            # Si le leadership est faible, on accepte tous les signaux
            if leadership_gate < signal_threshold:
                logger.debug(f"ğŸ›¡ï¸ Leadership faible ({leadership_gate:.3f} < {signal_threshold:.3f}) - signal acceptÃ©")
                return True
            
            # Si le leadership est fort, on filtre les signaux contre-tendance
            if leadership_gate >= leadership_threshold:
                # Signal fort contre-tendance = REJET
                if abs(final_score) >= signal_threshold:
                    # VÃ©rifier si c'est contre-tendance du leader
                    if self._is_against_leader_trend(final_score, leadership_gate):
                        logger.warning(f"ğŸ›¡ï¸ Signal contre-tendance du leader rejetÃ©: score={final_score:.3f}, gate={leadership_gate:.3f}")
                        logger.warning(f"ğŸ›¡ï¸ Seuils config: leadership={leadership_threshold:.3f}, signal={signal_threshold:.3f}")
                        return False
                    else:
                        logger.debug(f"ğŸ›¡ï¸ Signal alignÃ© avec le leader: score={final_score:.3f}, gate={leadership_gate:.3f}")
                else:
                    logger.debug(f"ğŸ›¡ï¸ Signal trop faible pour Ãªtre contre-tendance: score={final_score:.3f}")
            else:
                logger.debug(f"ğŸ›¡ï¸ Leadership modÃ©rÃ© ({leadership_gate:.3f} < {leadership_threshold:.3f}) - signal acceptÃ©")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur filtre leadership avec config: {e}")
            return True
    
    def _apply_leadership_filter_legacy(self, final_score: float, leadership_gate: float) -> bool:
        """ğŸ›¡ï¸ Filtre de leadership legacy (sans configuration centralisÃ©e)"""
        try:
            # Si le leadership est faible, on accepte tous les signaux
            if leadership_gate < 0.5:
                return True
            
            # Si le leadership est fort, on filtre les signaux contre-tendance
            if leadership_gate >= 0.7:
                # Signal fort contre-tendance = REJET
                if abs(final_score) >= 0.6:
                    # VÃ©rifier si c'est contre-tendance du leader
                    if self._is_against_leader_trend(final_score, leadership_gate):
                        logger.warning(f"ğŸ›¡ï¸ Signal contre-tendance du leader rejetÃ©: score={final_score:.3f}, gate={leadership_gate:.3f}")
                        return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur filtre leadership legacy: {e}")
            return True
    
    def _is_against_leader_trend(self, final_score: float, leadership_gate: float) -> bool:
        """DÃ©tecte si le signal est contre-tendance du leader"""
        try:
            # RÃ©cupÃ©rer le leader actuel
            leader = self._get_current_leader()
            if not leader:
                logger.debug("ğŸ›¡ï¸ Aucun leader dÃ©tectÃ© - pas de contre-tendance")
                return False
            
            # RÃ©cupÃ©rer la tendance du leader
            leader_trend = self._get_leader_trend(leader)
            if not leader_trend:
                logger.debug(f"ğŸ›¡ï¸ Tendance du leader {leader} non calculable - pas de contre-tendance")
                return False
            
            # VÃ©rifier la cohÃ©rence
            signal_direction = 1 if final_score > 0 else -1
            leader_direction = 1 if leader_trend > 0 else -1
            
            # ğŸ†• Utiliser la configuration centralisÃ©e pour le seuil de leadership
            if MENTHORQ_RULES_AVAILABLE:
                leadership_threshold = get_leadership_threshold('strong')  # 0.7 par dÃ©faut
            else:
                leadership_threshold = 0.7  # Fallback legacy
            
            # Si directions opposÃ©es et leadership fort = contre-tendance
            if signal_direction != leader_direction and leadership_gate >= leadership_threshold:
                logger.warning(f"ğŸ›¡ï¸ Contre-tendance dÃ©tectÃ©e: signal={signal_direction}, leader={leader_direction}, gate={leadership_gate:.3f}")
                logger.warning(f"ğŸ›¡ï¸ Leader: {leader}, tendance: {leader_trend:.3f}, score: {final_score:.3f}")
                return True
            
            logger.debug(f"ğŸ›¡ï¸ Signal alignÃ© avec le leader: signal={signal_direction}, leader={leader_direction}")
            return False
            
        except Exception as e:
            logger.error(f"âŒ Erreur dÃ©tection contre-tendance: {e}")
            return False
    
    def _get_current_leader(self) -> Optional[str]:
        """RÃ©cupÃ¨re le leader actuel"""
        try:
            # Utiliser l'historique de confluence pour dÃ©terminer le leader
            if not self.confluence_history:
                return None
            
            # Prendre le dernier rÃ©sultat
            last_result = self.confluence_history[-1]
            return last_result.result.leader
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration leader: {e}")
            return None
    
    def _get_leader_trend(self, leader: str) -> Optional[float]:
        """RÃ©cupÃ¨re la tendance du leader"""
        try:
            # Analyser les derniÃ¨res donnÃ©es du leader
            if leader == 'ES':
                es_data = self._get_latest_es_data()
                if es_data:
                    return self._calculate_trend(es_data)
            elif leader == 'NQ':
                nq_data = self._get_latest_nq_data()
                if nq_data:
                    return self._calculate_trend(nq_data)
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul tendance leader: {e}")
            return None
    
    def _get_latest_es_data(self) -> Optional[Any]:
        """RÃ©cupÃ¨re les derniÃ¨res donnÃ©es ES"""
        try:
            # Utiliser le buffer de synchronisation
            es_buffer = self.es_nq_sync_buffer.get('ES', [])
            if es_buffer:
                return es_buffer[-1]['data']
            return None
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration donnÃ©es ES: {e}")
            return None
    
    def _get_latest_nq_data(self) -> Optional[Any]:
        """RÃ©cupÃ¨re les derniÃ¨res donnÃ©es NQ"""
        try:
            # Utiliser le buffer de synchronisation
            nq_buffer = self.es_nq_sync_buffer.get('NQ', [])
            if nq_buffer:
                return nq_buffer[-1]['data']
            return None
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration donnÃ©es NQ: {e}")
            return None
    
    def _calculate_trend(self, data: Any) -> Optional[float]:
        """Calcule la tendance des donnÃ©es"""
        try:
            import pandas as pd
            
            if isinstance(data, pd.DataFrame) and len(data) >= 2:
                # Calculer la tendance sur les 5 derniÃ¨res barres
                recent_data = data.tail(5)
                if 'close' in recent_data.columns:
                    closes = recent_data['close'].values
                    if len(closes) >= 2:
                        # Tendance = diffÃ©rence entre dernier et premier
                        trend = (closes[-1] - closes[0]) / closes[0]
                        return trend
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul tendance: {e}")
            return None
    
    def _make_decision(self, final_score: float, is_valid: bool) -> str:
        """Prend une dÃ©cision basÃ©e sur le score final"""
        try:
            if not is_valid:
                return 'REJECT'
            
            if final_score >= 0.7:
                return 'STRONG_BUY'
            elif final_score >= 0.5:
                return 'BUY'
            elif final_score >= 0.3:
                return 'WEAK_BUY'
            else:
                return 'NEUTRAL'
                
        except Exception as e:
            logger.error(f"âŒ Erreur dÃ©cision: {e}")
            return 'NEUTRAL'
    
    def _determine_leader(self, es_data: Dict, nq_data: Dict, leadership_gate: float) -> Optional[str]:
        """DÃ©termine l'instrument leader"""
        try:
            if leadership_gate < 0.5:
                return None  # Pas de leader clair
            
            es_strength = self._calculate_leadership_strength(es_data, 'ES')
            nq_strength = self._calculate_leadership_strength(nq_data, 'NQ')
            
            if es_strength > nq_strength * 1.1:
                return 'ES'
            elif nq_strength > es_strength * 1.1:
                return 'NQ'
            else:
                return None  # Leadership partagÃ©
                
        except Exception as e:
            logger.error(f"âŒ Erreur dÃ©termination leader: {e}")
            return None
    
    def _determine_alignment(self, final_score: float, leadership_gate: float) -> str:
        """DÃ©termine l'alignement du signal"""
        try:
            if final_score >= 0.7 and leadership_gate >= 0.6:
                return 'strong_leader'
            elif final_score >= 0.5 and leadership_gate >= 0.4:
                return 'moderate_leader'
            elif final_score >= 0.3:
                return 'weak_signal'
            else:
                return 'no_signal'
                
        except Exception as e:
            logger.error(f"âŒ Erreur dÃ©termination alignement: {e}")
            return 'no_signal'
    
    def _create_fallback_result(self) -> ConfluenceResult:
        """CrÃ©e un rÃ©sultat de fallback"""
        return ConfluenceResult(
            base_score=0.5,
            leadership_gate=0.5,
            risk_multiplier=1.0,
            final_score=0.25,
            is_valid=False,
            decision='NEUTRAL',
            leader=None,
            confidence=0.25,
            alignment='no_signal'
        )
    
    def get_confluence_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de confluence"""
        try:
            if not self.confluence_history:
                return {
                    'total_signals': 0, 
                    'valid_signals': 0,
                    'avg_score': 0.0,
                    'validation_rate': 0.0,
                    'contra_trend_blocked': 0,
                    'contra_trend_block_rate': 0.0
                }
            
            total_signals = len(self.confluence_history)
            avg_score = sum(r['result'].final_score for r in self.confluence_history) / total_signals
            valid_signals = sum(1 for r in self.confluence_history if r['result'].is_valid)
            
            # ğŸ†• Calculer les statistiques de blocage contra-trend
            contra_trend_blocked = 0
            for r in self.confluence_history:
                result = r['result']
                # Si le signal n'est pas valide et a un score Ã©levÃ©, c'est probablement un blocage contra-trend
                if not result.is_valid and abs(result.final_score) >= 0.5 and result.leadership_gate >= 0.7:
                    contra_trend_blocked += 1
            
            contra_trend_block_rate = contra_trend_blocked / total_signals if total_signals > 0 else 0.0
            
            return {
                'total_signals': total_signals,
                'valid_signals': valid_signals,
                'avg_score': avg_score,
                'validation_rate': valid_signals / total_signals if total_signals > 0 else 0.0,
                'contra_trend_blocked': contra_trend_blocked,
                'contra_trend_block_rate': contra_trend_block_rate
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul stats confluence: {e}")
            return {
                'total_signals': 0, 
                'valid_signals': 0,
                'avg_score': 0.0,
                'validation_rate': 0.0,
                'contra_trend_blocked': 0,
                'contra_trend_block_rate': 0.0
            }
    
    def get_enhanced_leadership_filter_stats(self) -> Dict[str, Any]:
        """ğŸ†• Retourne les statistiques du filtre de leadership amÃ©liorÃ©"""
        try:
            if not ENHANCED_LEADERSHIP_FILTER_AVAILABLE:
                return {
                    'enhanced_filter_available': False,
                    'message': 'Filtre de leadership amÃ©liorÃ© non disponible'
                }
            
            enhanced_filter = LeadershipZMom()
            stats = enhanced_filter.get_filter_stats()
            
            return {
                'enhanced_filter_available': True,
                'total_signals': stats.total_signals,
                'blocked_signals': stats.blocked_signals,
                'block_rate': stats.block_rate,
                'block_reasons': stats.block_reasons,
                'leadership_distribution': stats.leadership_distribution,
                'vix_regime_blocks': stats.vix_regime_blocks,
                'avg_leadership_gate': stats.avg_leadership_gate,
                'avg_signal_score': stats.avg_signal_score
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration stats filtre amÃ©liorÃ©: {e}")
            return {
                'enhanced_filter_available': False,
                'error': str(e)
            }
    
    def reset_confluence_history(self) -> None:
        """Reset l'historique de confluence"""
        self.confluence_history.clear()
        logger.info("ğŸ”„ Historique confluence resetÃ©")
    
    def get_leadership_filter_config(self) -> Dict[str, Any]:
        """ğŸ†• Retourne la configuration du filtre de leadership"""
        try:
            if MENTHORQ_RULES_AVAILABLE:
                return {
                    'config_available': True,
                    'contra_trend_enabled': is_hard_rule_enabled('leadership_contra_trend'),
                    'leadership_threshold_strong': get_leadership_threshold('strong'),
                    'leadership_threshold_moderate': get_leadership_threshold('moderate'),
                    'leadership_threshold_min': get_leadership_threshold('min'),
                    'config_source': 'menthorq_rules.json'
                }
            else:
                return {
                    'config_available': False,
                    'contra_trend_enabled': True,  # Legacy par dÃ©faut
                    'leadership_threshold_strong': 0.7,
                    'leadership_threshold_moderate': 0.5,
                    'leadership_threshold_min': 0.4,
                    'config_source': 'legacy_hardcoded'
                }
                
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration config leadership: {e}")
            return {
                'config_available': False,
                'contra_trend_enabled': False,
                'error': str(e)
            }
    
    # ğŸ†• MÃ‰THODES DE SYNCHRONISATION ES/NQ
    
    def _synchronize_es_nq_data(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """Synchronise les donnÃ©es ES/NQ basÃ©e sur les timestamps"""
        try:
            # Ajouter les nouvelles donnÃ©es au buffer
            self._add_to_sync_buffer(market_data)
            
            # Nettoyer le buffer des donnÃ©es trop anciennes
            self._clean_sync_buffer()
            
            # Trouver les paires synchronisÃ©es
            synchronized_pairs = self._find_synchronized_pairs()
            
            if synchronized_pairs:
                # Utiliser la paire la plus rÃ©cente
                latest_pair = synchronized_pairs[-1]
                logger.debug(f"ğŸ”„ DonnÃ©es ES/NQ synchronisÃ©es: {len(synchronized_pairs)} paires trouvÃ©es")
                return {
                    'ES': latest_pair['ES'],
                    'NQ': latest_pair['NQ'],
                    'sync_timestamp': latest_pair['timestamp'],
                    'sync_quality': latest_pair['quality']
                }
            else:
                # Fallback: utiliser les donnÃ©es individuelles
                logger.warning("âš ï¸ Aucune paire ES/NQ synchronisÃ©e trouvÃ©e - utilisation des donnÃ©es individuelles")
                return {
                    'ES': market_data.get('ES', {}),
                    'NQ': market_data.get('NQ', {}),
                    'sync_timestamp': None,
                    'sync_quality': 0.0
                }
                
        except Exception as e:
            logger.error(f"âŒ Erreur synchronisation ES/NQ: {e}")
            return {
                'ES': market_data.get('ES', {}),
                'NQ': market_data.get('NQ', {}),
                'sync_timestamp': None,
                'sync_quality': 0.0
            }
    
    def _add_to_sync_buffer(self, market_data: Dict[str, Any]) -> None:
        """Ajoute les donnÃ©es au buffer de synchronisation"""
        try:
            from datetime import datetime, timezone
            
            current_time = datetime.now(timezone.utc)
            
            # Traiter les donnÃ©es ES
            if 'ES' in market_data:
                es_data = market_data['ES']
                if self._is_valid_data(es_data):
                    # Extraire le timestamp
                    timestamp = self._extract_timestamp(es_data, current_time)
                    
                    self.es_nq_sync_buffer['ES'].append({
                        'data': es_data,
                        'timestamp': timestamp,
                        'added_at': current_time
                    })
            
            # Traiter les donnÃ©es NQ
            if 'NQ' in market_data:
                nq_data = market_data['NQ']
                if self._is_valid_data(nq_data):
                    # Extraire le timestamp
                    timestamp = self._extract_timestamp(nq_data, current_time)
                    
                    self.es_nq_sync_buffer['NQ'].append({
                        'data': nq_data,
                        'timestamp': timestamp,
                        'added_at': current_time
                    })
                    
        except Exception as e:
            logger.error(f"âŒ Erreur ajout au buffer sync: {e}")
    
    def _extract_timestamp(self, data: Any, fallback_time: datetime) -> datetime:
        """Extrait le timestamp des donnÃ©es"""
        try:
            from datetime import datetime, timezone
            
            # Gestion des DataFrames pandas
            if hasattr(data, 'iloc') and len(data) > 0:
                latest = data.iloc[-1]
                if 'timestamp' in latest:
                    ts_str = latest['timestamp']
                    if isinstance(ts_str, str):
                        return datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                    elif hasattr(ts_str, 'to_pydatetime'):
                        return ts_str.to_pydatetime()
            
            # Gestion des dictionnaires
            if isinstance(data, dict):
                if 'timestamp' in data:
                    ts_str = data['timestamp']
                    if isinstance(ts_str, str):
                        return datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                elif 'ts' in data:
                    ts_str = data['ts']
                    if isinstance(ts_str, str):
                        return datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
            
            # Fallback
            return fallback_time
            
        except Exception as e:
            logger.warning(f"âš ï¸ Erreur extraction timestamp: {e} - utilisation du fallback")
            return fallback_time
    
    def _clean_sync_buffer(self) -> None:
        """Nettoie le buffer des donnÃ©es trop anciennes"""
        try:
            from datetime import datetime, timezone, timedelta
            
            current_time = datetime.now(timezone.utc)
            cutoff_time = current_time - timedelta(seconds=self.sync_tolerance_seconds * 2)
            
            # Nettoyer ES
            self.es_nq_sync_buffer['ES'] = [
                item for item in self.es_nq_sync_buffer['ES']
                if item['added_at'] > cutoff_time
            ]
            
            # Nettoyer NQ
            self.es_nq_sync_buffer['NQ'] = [
                item for item in self.es_nq_sync_buffer['NQ']
                if item['added_at'] > cutoff_time
            ]
            
            # Limiter la taille du buffer
            if len(self.es_nq_sync_buffer['ES']) > self.max_buffer_size:
                self.es_nq_sync_buffer['ES'] = self.es_nq_sync_buffer['ES'][-self.max_buffer_size:]
            
            if len(self.es_nq_sync_buffer['NQ']) > self.max_buffer_size:
                self.es_nq_sync_buffer['NQ'] = self.es_nq_sync_buffer['NQ'][-self.max_buffer_size:]
                
        except Exception as e:
            logger.error(f"âŒ Erreur nettoyage buffer sync: {e}")
    
    def _find_synchronized_pairs(self) -> List[Dict[str, Any]]:
        """Trouve les paires ES/NQ synchronisÃ©es"""
        try:
            from datetime import timedelta
            
            synchronized_pairs = []
            
            es_buffer = self.es_nq_sync_buffer['ES']
            nq_buffer = self.es_nq_sync_buffer['NQ']
            
            if not es_buffer or not nq_buffer:
                return synchronized_pairs
            
            # Trouver les paires dans la tolÃ©rance de temps
            for es_item in es_buffer:
                es_timestamp = es_item['timestamp']
                
                for nq_item in nq_buffer:
                    nq_timestamp = nq_item['timestamp']
                    
                    # Calculer la diffÃ©rence de temps
                    time_diff = abs((es_timestamp - nq_timestamp).total_seconds())
                    
                    if time_diff <= self.sync_tolerance_seconds:
                        # Calculer la qualitÃ© de synchronisation
                        sync_quality = max(0.0, 1.0 - (time_diff / self.sync_tolerance_seconds))
                        
                        synchronized_pairs.append({
                            'ES': es_item['data'],
                            'NQ': nq_item['data'],
                            'timestamp': min(es_timestamp, nq_timestamp),
                            'time_diff': time_diff,
                            'quality': sync_quality
                        })
            
            # Trier par timestamp (plus rÃ©cent en premier)
            synchronized_pairs.sort(key=lambda x: x['timestamp'], reverse=True)
            
            return synchronized_pairs
            
        except Exception as e:
            logger.error(f"âŒ Erreur recherche paires synchronisÃ©es: {e}")
            return []
    
    def get_es_nq_sync_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de synchronisation ES/NQ"""
        try:
            es_count = len(self.es_nq_sync_buffer['ES'])
            nq_count = len(self.es_nq_sync_buffer['NQ'])
            
            synchronized_pairs = self._find_synchronized_pairs()
            sync_count = len(synchronized_pairs)
            
            avg_quality = 0.0
            if synchronized_pairs:
                avg_quality = sum(pair['quality'] for pair in synchronized_pairs) / len(synchronized_pairs)
            
            return {
                'es_buffer_size': es_count,
                'nq_buffer_size': nq_count,
                'synchronized_pairs': sync_count,
                'sync_tolerance_seconds': self.sync_tolerance_seconds,
                'average_sync_quality': avg_quality,
                'sync_rate': sync_count / max(1, min(es_count, nq_count))
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul stats sync ES/NQ: {e}")
            return {
                'es_buffer_size': 0,
                'nq_buffer_size': 0,
                'synchronized_pairs': 0,
                'sync_tolerance_seconds': self.sync_tolerance_seconds,
                'average_sync_quality': 0.0,
                'sync_rate': 0.0
            }
    
    # ğŸ†• MÃ‰THODES MENTHORQ DEALER'S BIAS
    
    def _calculate_menthorq_bias(self, es_data: Dict[str, Any]) -> Tuple[float, str, str, float]:
        """Calcule le Dealer's Bias MenthorQ"""
        try:
            if not self.menthorq_bias_analyzer:
                logger.debug("MenthorQDealersBiasAnalyzer non disponible")
                return 0.0, "NEUTRAL", "UNKNOWN", 0.0
            
            # Extraire le prix actuel ES
            current_price = es_data.get('price', es_data.get('close', 5294.0))
            symbol = es_data.get('symbol', 'ESZ5')
            vix_level = es_data.get('vix', 20.0)
            
            # Calculer le Dealer's Bias MenthorQ
            bias = self.menthorq_bias_analyzer.calculate_menthorq_dealers_bias(
                current_price=current_price,
                symbol=symbol,
                vix_level=vix_level,
                use_realtime=True
            )
            
            if bias:
                logger.debug(f"ğŸ¯ MenthorQ Dealer's Bias: {bias.direction} {bias.strength} ({bias.bias_score:.3f})")
                return bias.bias_score, bias.direction, bias.strength, bias.composite_score
            else:
                logger.debug("MenthorQ Dealer's Bias non calculÃ©")
                return 0.0, "NEUTRAL", "UNKNOWN", 0.0
                
        except Exception as e:
            logger.error(f"âŒ Erreur calcul Dealer's Bias MenthorQ: {e}")
            return 0.0, "NEUTRAL", "UNKNOWN", 0.0
    
    def _calculate_menthorq_multiplier(self, bias_score: float, bias_strength: str) -> float:
        """Calcule le multiplicateur MenthorQ basÃ© sur le Dealer's Bias"""
        try:
            # Multiplicateur de base
            base_multiplier = 1.0
            
            # Ajustement selon la force du bias
            if bias_strength == "STRONG":
                strength_multiplier = 1.2
            elif bias_strength == "MODERATE":
                strength_multiplier = 1.1
            elif bias_strength == "WEAK":
                strength_multiplier = 1.05
            else:
                strength_multiplier = 1.0
            
            # Ajustement selon le score de bias
            if abs(bias_score) > 0.5:
                # Bias fort = impact important
                score_multiplier = 1.0 + (abs(bias_score) * 0.3)
            elif abs(bias_score) > 0.2:
                # Bias modÃ©rÃ© = impact modÃ©rÃ©
                score_multiplier = 1.0 + (abs(bias_score) * 0.2)
            else:
                # Bias faible = impact minimal
                score_multiplier = 1.0 + (abs(bias_score) * 0.1)
            
            final_multiplier = base_multiplier * strength_multiplier * score_multiplier
            
            # Limiter le multiplicateur entre 0.5 et 2.0
            final_multiplier = max(0.5, min(2.0, final_multiplier))
            
            logger.debug(f"ğŸ¯ MenthorQ Multiplier: {final_multiplier:.3f} (bias: {bias_score:.3f}, strength: {bias_strength})")
            return final_multiplier
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul multiplicateur MenthorQ: {e}")
            return 1.0
    
    def _calculate_advanced_features(self, market_data: Dict[str, Any]) -> Tuple[float, Dict[str, Any]]:
        """ğŸ†• Calcule les Advanced Features"""
        try:
            if not self.advanced_features:
                return 0.0, {}
            
            # Calculer toutes les features avancÃ©es
            advanced_results = self.advanced_features.calculate_all_features(market_data)
            combined_signal = self.advanced_features.get_combined_signal(market_data)
            
            logger.debug(f"âœ… Advanced Features calculÃ©es: {combined_signal:.3f}")
            return combined_signal, advanced_results
            
        except Exception as e:
            logger.warning(f"âš ï¸ Erreur calcul Advanced Features: {e}")
            return 0.0, {}
    
    def _calculate_advanced_multiplier(self, advanced_score: float) -> float:
        """ğŸ†• Calcule le multiplicateur basÃ© sur Advanced Features"""
        try:
            if advanced_score == 0.0:
                return 1.0  # Neutre si pas de donnÃ©es
            
            # Conversion du signal [-1, 1] en multiplicateur [0.8, 1.2]
            # Signal positif = multiplicateur > 1.0 (boost)
            # Signal nÃ©gatif = multiplicateur < 1.0 (rÃ©duction)
            multiplier = 1.0 + (advanced_score * 0.2)
            
            # Limiter dans une plage raisonnable
            multiplier = max(0.8, min(1.2, multiplier))
            
            logger.debug(f"âœ… Advanced Features multiplier: {multiplier:.3f}")
            return multiplier
            
        except Exception as e:
            logger.warning(f"âš ï¸ Erreur calcul Advanced multiplier: {e}")
            return 1.0

def create_confluence_integrator(config=None) -> ConfluenceIntegrator:
    """Factory pour crÃ©er un ConfluenceIntegrator"""
    return ConfluenceIntegrator(config)
