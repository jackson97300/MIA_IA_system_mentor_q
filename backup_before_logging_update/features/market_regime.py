"""
MIA_IA_SYSTEM - Market Regime Detector
CERVEAU DU SYST√àME - D√©termine r√©gime march√© + bias directionnel
Version: Production Ready
Performance: D√©tection temps r√©el <3ms

R√âGIMES D√âTECT√âS :
1. STRONG_TREND_BULLISH   - Tendance haussi√®re forte (HH/HL + VWAP slope+)
2. WEAK_TREND_BULLISH     - Tendance haussi√®re faible (correction possible)
3. STRONG_TREND_BEARISH   - Tendance baissi√®re forte (LH/LL + VWAP slope-)
4. WEAK_TREND_BEARISH     - Tendance baissi√®re faible (correction possible)
5. RANGE_BULLISH_BIAS     - Range avec bias haussier (longs seulement)
6. RANGE_BEARISH_BIAS     - Range avec bias baissier (shorts seulement)
7. RANGE_NEUTRAL          - Range pur (both sides autoris√©s)
8. TRANSITION             - Changement r√©gime en cours
9. UNCLEAR                - Pas de r√©gime clair

FILTRES RANGE :
- Range minimum : 12 ticks (√©viter micro-ranges)
- Range maximum : 50 ticks (√©viter ranges trop larges)
- Dur√©e minimum : 20 minutes
- Tests minimum : 3 par niveau

BIAS DETERMINATION :
- VWAP slope + Dow structure + Volume trend + ES/NQ correlation
"""

import time
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, field
from enum import Enum, IntEnum
import logging
from collections import deque
import statistics

# Local imports
from core.base_types import (
    MarketData, OrderFlowData, ES_TICK_SIZE, ES_TICK_VALUE,
    get_session_phase
)

logger = logging.getLogger(__name__)

# === MARKET REGIME ENUMS ===


class MarketRegime(Enum):
    """R√©gimes de march√© d√©taill√©s"""
    STRONG_TREND_BULLISH = "strong_trend_bullish"    # Trend fort haussier
    WEAK_TREND_BULLISH = "weak_trend_bullish"        # Trend faible haussier
    STRONG_TREND_BEARISH = "strong_trend_bearish"    # Trend fort baissier
    WEAK_TREND_BEARISH = "weak_trend_bearish"        # Trend faible baissier
    RANGE_BULLISH_BIAS = "range_bullish_bias"        # Range bias haussier
    RANGE_BEARISH_BIAS = "range_bearish_bias"        # Range bias baissier
    RANGE_NEUTRAL = "range_neutral"                  # Range neutre
    TRANSITION = "transition"                        # Changement r√©gime
    UNCLEAR = "unclear"                              # Pas de r√©gime clair


class TrendStrength(Enum):
    """Force de la tendance"""
    VERY_STRONG = "very_strong"      # >85%
    STRONG = "strong"                # 70-85%
    MODERATE = "moderate"            # 50-70%
    WEAK = "weak"                    # 30-50%
    VERY_WEAK = "very_weak"          # <30%


class RangeType(Enum):
    """Types de range"""
    TIGHT_RANGE = "tight_range"      # 12-20 ticks
    NORMAL_RANGE = "normal_range"    # 20-35 ticks
    WIDE_RANGE = "wide_range"        # 35-50 ticks
    TOO_SMALL = "too_small"          # <12 ticks (√©viter)
    TOO_LARGE = "too_large"          # >50 ticks (√©viter)

# === DATACLASSES ===


@dataclass
class TrendAnalysis:
    """Analyse tendance compl√®te"""
    timestamp: pd.Timestamp

    # Dow Theory structure
    higher_highs_count: int = 0
    higher_lows_count: int = 0
    lower_highs_count: int = 0
    lower_lows_count: int = 0

    # Trend metrics
    price_slope: float = 0.0
    vwap_slope: float = 0.0
    volume_trend: float = 0.0
    momentum_score: float = 0.0

    # Strength assessment
    trend_strength: TrendStrength = TrendStrength.WEAK
    trend_consistency: float = 0.0
    trend_duration_minutes: int = 0

    # Support/Resistance levels
    key_support: float = 0.0
    key_resistance: float = 0.0
    last_swing_high: float = 0.0
    last_swing_low: float = 0.0

    # Validation
    structure_intact: bool = False
    volume_confirms: bool = False


@dataclass
class RangeAnalysis:
    """Analyse range compl√®te"""
    timestamp: pd.Timestamp

    # Range identification
    range_detected: bool = False
    range_type: RangeType = RangeType.TOO_SMALL

    # Levels
    support_level: float = 0.0
    resistance_level: float = 0.0
    range_midpoint: float = 0.0
    range_size_ticks: float = 0.0

    # Quality metrics
    support_tests: int = 0
    resistance_tests: int = 0
    range_duration_minutes: int = 0
    level_respect_rate: float = 0.0

    # Volume analysis
    range_volume_avg: float = 0.0
    breakout_volume_threshold: float = 0.0
    volume_contraction: bool = False

    # Bias context
    underlying_bias: str = "neutral"  # bullish, bearish, neutral
    bias_strength: float = 0.0


@dataclass
class ESNQCorrelation:
    """Analyse corr√©lation ES/NQ"""
    timestamp: pd.Timestamp

    # Correlation metrics
    correlation_coefficient: float = 0.0
    correlation_strength: str = "weak"

    # Divergence analysis
    price_divergence: float = 0.0
    momentum_divergence: float = 0.0

    # Leadership
    market_leader: str = "ES"  # ES or NQ
    leadership_strength: float = 0.0

    # Signals
    aligned: bool = False
    divergence_warning: bool = False


@dataclass
class MarketRegimeData:
    """Donn√©es compl√®tes r√©gime march√©"""
    timestamp: pd.Timestamp

    # Primary regime
    regime: MarketRegime = MarketRegime.UNCLEAR
    regime_confidence: float = 0.0
    regime_duration_minutes: int = 0

    # Component analysis
    trend_analysis: Optional[TrendAnalysis] = None
    range_analysis: Optional[RangeAnalysis] = None
    es_nq_correlation: Optional[ESNQCorrelation] = None

    # Trading implications
    preferred_strategy: str = "None"  # trend, range, wait
    allowed_directions: List[str] = field(default_factory=list)
    bias_strength: float = 0.0

    # Risk management
    expected_volatility: str = "normal"  # low, normal, high
    position_sizing_multiplier: float = 1.0

    # Session context
    session_phase: str = "unknown"
    session_performance_factor: float = 1.0

# === MAIN MARKET REGIME DETECTOR ===


class MarketRegimeDetector:
    """
    D√©tecteur r√©gime march√© - CERVEAU DU SYST√àME

    Responsabilit√©s :
    1. Analyse tendance (Dow Theory + VWAP + Volume)
    2. D√©tection range (taille + qualit√© + bias)
    3. Corr√©lation ES/NQ
    4. Classification r√©gime final
    5. D√©termination bias trading
    6. Filtrage ranges (minimum 12 ticks)
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialisation d√©tecteur r√©gime"""
        self.config = config or {}

        # Param√®tres trend analysis
        self.trend_lookback = self.config.get('trend_lookback', 50)
        self.min_trend_strength = self.config.get('min_trend_strength', 0.6)
        self.dow_structure_periods = self.config.get('dow_structure_periods', 30)

        # Param√®tres range detection
        self.min_range_size_ticks = self.config.get('min_range_size_ticks', 12)  # IMPORTANT
        self.max_range_size_ticks = self.config.get('max_range_size_ticks', 50)
        self.min_range_duration = self.config.get('min_range_duration', 20)  # minutes
        self.min_level_tests = self.config.get('min_level_tests', 3)
        self.range_respect_threshold = self.config.get('range_respect_threshold', 0.75)

        # Param√®tres corr√©lation
        self.correlation_lookback = self.config.get('correlation_lookback', 100)
        self.min_correlation_strength = self.config.get('min_correlation_strength', 0.7)

        # Param√®tres session
        self.session_volatility_factors = {
            'london_open': 1.3,    # Plus volatil
            'ny_open': 1.5,        # Tr√®s volatil
            'lunch': 0.7,          # Moins volatil
            'afternoon': 1.0,      # Normal
            'close': 1.2,          # Mod√©r√©ment volatil
            'after_hours': 0.5     # Faible volatilit√©
        }

        # √âtat syst√®me
        self.price_history: deque = deque(maxlen=200)
        self.es_nq_history: deque = deque(maxlen=self.correlation_lookback)
        self.regime_history: deque = deque(maxlen=50)
        self.current_regime: Optional[MarketRegimeData] = None

        # Performance tracking
        self.stats = {
            'regimes_detected': 0,
            'trend_periods': 0,
            'range_periods': 0,
            'transition_periods': 0,
            'avg_regime_duration': 0.0,
            'regime_changes': 0,
            'ranges_filtered_small': 0,  # Ranges <12 ticks filtr√©s
            'ranges_filtered_large': 0   # Ranges >50 ticks filtr√©s
        }

        logger.info("MarketRegimeDetector initialis√© - Cerveau syst√®me trading")

    def analyze_market_regime(self,
                              market_data: MarketData,
                              es_nq_data: Optional[Dict[str, float]] = None,
                              structure_data: Optional[Dict[str, Any]] = None,
                              volume_data: Optional[Dict[str, float]] = None) -> MarketRegimeData:
        """
        ANALYSE COMPL√àTE R√âGIME MARCH√â

        Processus :
        1. Analyse tendance (Dow + VWAP + Volume)
        2. D√©tection range (avec filtres taille)
        3. Corr√©lation ES/NQ
        4. Classification r√©gime final
        5. D√©termination bias + implications trading

        Args:
            market_data: Donn√©es OHLC + volume
            es_nq_data: Donn√©es ES/NQ pour corr√©lation
            structure_data: VWAP + Market Profile levels
            volume_data: Donn√©es volume avanc√©es

        Returns:
            MarketRegimeData avec r√©gime + bias + implications
        """
        start_time = time.perf_counter()

        try:
            # Ajout historique
            self.price_history.append(market_data)
            if es_nq_data:
                self.es_nq_history.append(es_nq_data)

            # 1. ANALYSE TENDANCE (DOW THEORY + VWAP)
            trend_analysis = self._analyze_trend_structure(
                market_data, structure_data, volume_data
            )

            # 2. D√âTECTION RANGE (AVEC FILTRES)
            range_analysis = self._analyze_range_structure(
                market_data, structure_data, trend_analysis
            )

            # 3. CORR√âLATION ES/NQ
            es_nq_correlation = self._analyze_es_nq_correlation(es_nq_data)

            # 4. CLASSIFICATION R√âGIME FINAL
            regime, confidence = self._classify_market_regime(
                trend_analysis, range_analysis, es_nq_correlation
            )

            # 5. D√âTERMINATION IMPLICATIONS TRADING
            regime_data = self._generate_regime_implications(
                regime=regime,
                confidence=confidence,
                trend_analysis=trend_analysis,
                range_analysis=range_analysis,
                es_nq_correlation=es_nq_correlation,
                market_data=market_data
            )

            # 6. MISE √Ä JOUR HISTORIQUE
            self._update_regime_history(regime_data)
            self.current_regime = regime_data

            # Performance tracking
            detection_time = (time.perf_counter() - start_time) * 1000
            logger.debug(f"R√©gime d√©tect√© en {detection_time:.2f}ms: {regime.value}")

            return regime_data

        except Exception as e:
            logger.error(f"Erreur analyse r√©gime march√©: {e}")
            return MarketRegimeData(
                timestamp=market_data.timestamp,
                regime=MarketRegime.UNCLEAR,
                regime_confidence=0.0
            )

    def _analyze_trend_structure(self,
                                 market_data: MarketData,
                                 structure_data: Optional[Dict[str, Any]],
                                 volume_data: Optional[Dict[str, float]]) -> TrendAnalysis:
        """
        ANALYSE STRUCTURE TENDANCE

        Combine :
        - Dow Theory (HH/HL vs LH/LL)
        - VWAP slope analysis
        - Volume trend confirmation
        - Momentum indicators
        """

        if len(self.price_history) < self.dow_structure_periods:
            return TrendAnalysis(
                timestamp=market_data.timestamp,
                trend_strength=TrendStrength.VERY_WEAK
            )

        recent_bars = list(self.price_history)[-self.dow_structure_periods:]

        # === DOW THEORY STRUCTURE ANALYSIS ===

        # Identification pivots (m√©thode robuste)
        highs, lows = self._identify_swing_points(recent_bars)

        # Comptage structure Dow
        hh_count, hl_count = self._count_higher_structure(highs, lows)
        lh_count, ll_count = self._count_lower_structure(highs, lows)

        # === VWAP SLOPE ANALYSIS ===

        vwap_slope = 0.0
        if structure_data and 'vwap_slope' in structure_data:
            vwap_slope = structure_data['vwap_slope']
        else:
            # Calcul approximatif si pas fourni
            closes = [bar.close for bar in recent_bars]
            vwap_slope = np.polyfit(range(len(closes)), closes, 1)[0] / ES_TICK_SIZE

        # === PRICE SLOPE ===

        closes = [bar.close for bar in recent_bars]
        price_slope = np.polyfit(range(len(closes)), closes, 1)[0] / ES_TICK_SIZE

        # === VOLUME TREND ===

        volumes = [bar.volume for bar in recent_bars]
        if len(volumes) >= 10:
            recent_vol = np.mean(volumes[-5:])
            older_vol = np.mean(volumes[-15:-5])
            volume_trend = (recent_vol - older_vol) / older_vol if older_vol > 0 else 0
        else:
            volume_trend = 0.0

        # === MOMENTUM SCORE ===

        momentum_score = self._calculate_momentum_score(recent_bars)

        # === TREND STRENGTH ASSESSMENT ===

        # Combinaison facteurs pour force tendance
        structure_score = self._calculate_structure_score(hh_count, hl_count, lh_count, ll_count)
        slope_score = min(abs(vwap_slope) / 2.0, 1.0)  # Normalise slope
        momentum_score_norm = min(momentum_score, 1.0)

        trend_strength_value = (
            structure_score *
            0.4 +
            slope_score *
            0.35 +
            momentum_score_norm *
            0.25)

        # Classification force
        if trend_strength_value >= 0.85:
            trend_strength = TrendStrength.VERY_STRONG
        elif trend_strength_value >= 0.70:
            trend_strength = TrendStrength.STRONG
        elif trend_strength_value >= 0.50:
            trend_strength = TrendStrength.MODERATE
        elif trend_strength_value >= 0.30:
            trend_strength = TrendStrength.WEAK
        else:
            trend_strength = TrendStrength.VERY_WEAK

        # === SUPPORT/RESISTANCE LEVELS ===

        if hh_count + hl_count > lh_count + ll_count:  # Bullish structure
            key_support = min([bar.low for bar in recent_bars[-10:]])
            key_resistance = max([bar.high for bar in recent_bars[-5:]])
        else:  # Bearish structure
            key_support = min([bar.low for bar in recent_bars[-5:]])
            key_resistance = max([bar.high for bar in recent_bars[-10:]])

        # === VALIDATION ===

        structure_intact = (hh_count + hl_count >= 3) or (lh_count + ll_count >= 3)
        volume_confirms = abs(volume_trend) > 0.1  # 10% change in volume trend

        return TrendAnalysis(
            timestamp=market_data.timestamp,
            higher_highs_count=hh_count,
            higher_lows_count=hl_count,
            lower_highs_count=lh_count,
            lower_lows_count=ll_count,
            price_slope=price_slope,
            vwap_slope=vwap_slope,
            volume_trend=volume_trend,
            momentum_score=momentum_score,
            trend_strength=trend_strength,
            trend_consistency=trend_strength_value,
            trend_duration_minutes=len(recent_bars),
            key_support=key_support,
            key_resistance=key_resistance,
            last_swing_high=max(highs) if highs else 0.0,
            last_swing_low=min(lows) if lows else 0.0,
            structure_intact=structure_intact,
            volume_confirms=volume_confirms
        )

    def _analyze_range_structure(self,
                                 market_data: MarketData,
                                 structure_data: Optional[Dict[str, Any]],
                                 trend_analysis: TrendAnalysis) -> RangeAnalysis:
        """
        ANALYSE STRUCTURE RANGE AVEC FILTRES

        FILTRES CRITIQUES :
        - Range minimum : 12 ticks (√©viter micro-ranges)
        - Range maximum : 50 ticks (√©viter ranges trop larges)
        - Dur√©e minimum : 20 minutes
        - Tests minimum : 3 par niveau
        """

        if len(self.price_history) < 30:
            return RangeAnalysis(
                timestamp=market_data.timestamp,
                range_detected=False,
                range_type=RangeType.TOO_SMALL
            )

        # Analyse derni√®re p√©riode pour range
        lookback_bars = min(60, len(self.price_history))  # Max 60 barres
        recent_bars = list(self.price_history)[-lookback_bars:]

        # === D√âTECTION NIVEAUX SUPPORT/R√âSISTANCE ===

        highs = [bar.high for bar in recent_bars]
        lows = [bar.low for bar in recent_bars]

        # M√©thode percentiles + clustering
        resistance_candidates = np.percentile(highs, [85, 90, 95])
        support_candidates = np.percentile(lows, [5, 10, 15])

        # S√©lection niveaux les plus test√©s
        resistance_level = self._find_most_tested_level(highs, resistance_candidates)
        support_level = self._find_most_tested_level(lows, support_candidates)

        # === VALIDATION TAILLE RANGE ===

        range_size_ticks = (resistance_level - support_level) / ES_TICK_SIZE

        # FILTRE PRINCIPAL : Taille range
        if range_size_ticks < self.min_range_size_ticks:
            self.stats['ranges_filtered_small'] += 1
            return RangeAnalysis(
                timestamp=market_data.timestamp,
                range_detected=False,
                range_type=RangeType.TOO_SMALL,
                range_size_ticks=range_size_ticks
            )

        if range_size_ticks > self.max_range_size_ticks:
            self.stats['ranges_filtered_large'] += 1
            return RangeAnalysis(
                timestamp=market_data.timestamp,
                range_detected=False,
                range_type=RangeType.TOO_LARGE,
                range_size_ticks=range_size_ticks
            )

        # === COMPTAGE TESTS NIVEAUX ===

        support_tests = self._count_level_tests(
            lows, support_level, tolerance=1.5 * ES_TICK_SIZE
        )
        resistance_tests = self._count_level_tests(
            highs, resistance_level, tolerance=1.5 * ES_TICK_SIZE
        )

        # FILTRE : Tests minimum
        if support_tests < self.min_level_tests or resistance_tests < self.min_level_tests:
            return RangeAnalysis(
                timestamp=market_data.timestamp,
                range_detected=False,
                range_type=RangeType.TOO_SMALL,
                range_size_ticks=range_size_ticks,
                support_tests=support_tests,
                resistance_tests=resistance_tests
            )

        # === DUR√âE RANGE ===

        range_duration = len(recent_bars)  # Approximation en barres

        # FILTRE : Dur√©e minimum
        if range_duration < self.min_range_duration:
            return RangeAnalysis(
                timestamp=market_data.timestamp,
                range_detected=False,
                range_type=RangeType.TOO_SMALL,
                range_duration_minutes=range_duration
            )

        # === RESPECT NIVEAUX ===

        level_respect_rate = self._calculate_level_respect_rate(
            recent_bars, support_level, resistance_level
        )

        if level_respect_rate < self.range_respect_threshold:
            return RangeAnalysis(
                timestamp=market_data.timestamp,
                range_detected=False,
                level_respect_rate=level_respect_rate
            )

        # === CLASSIFICATION TYPE RANGE ===

        if 12 <= range_size_ticks <= 20:
            range_type = RangeType.TIGHT_RANGE
        elif 20 <= range_size_ticks <= 35:
            range_type = RangeType.NORMAL_RANGE
        elif 35 <= range_size_ticks <= 50:
            range_type = RangeType.WIDE_RANGE
        else:
            range_type = RangeType.TOO_LARGE  # Shouldn't happen due to filters

        # === BIAS DETERMINATION ===

        # Bias bas√© sur tendance sous-jacente
        underlying_bias = "neutral"
        bias_strength = 0.0

        if trend_analysis.trend_strength in [TrendStrength.STRONG, TrendStrength.VERY_STRONG]:
            if trend_analysis.higher_highs_count + trend_analysis.higher_lows_count > 4:
                underlying_bias = "bullish"
                bias_strength = trend_analysis.trend_consistency
            elif trend_analysis.lower_highs_count + trend_analysis.lower_lows_count > 4:
                underlying_bias = "bearish"
                bias_strength = trend_analysis.trend_consistency

        # === VOLUME ANALYSIS ===

        volumes = [bar.volume for bar in recent_bars]
        range_volume_avg = np.mean(volumes)

        # Volume contraction dans range
        if len(volumes) >= 10:
            recent_vol = np.mean(volumes[-5:])
            older_vol = np.mean(volumes[:5])
            volume_contraction = recent_vol < older_vol * 0.8
        else:
            volume_contraction = False

        return RangeAnalysis(
            timestamp=market_data.timestamp,
            range_detected=True,
            range_type=range_type,
            support_level=support_level,
            resistance_level=resistance_level,
            range_midpoint=(support_level + resistance_level) / 2,
            range_size_ticks=range_size_ticks,
            support_tests=support_tests,
            resistance_tests=resistance_tests,
            range_duration_minutes=range_duration,
            level_respect_rate=level_respect_rate,
            range_volume_avg=range_volume_avg,
            breakout_volume_threshold=range_volume_avg * 1.5,
            volume_contraction=volume_contraction,
            underlying_bias=underlying_bias,
            bias_strength=bias_strength
        )

    def _analyze_es_nq_correlation(self,
                                   es_nq_data: Optional[Dict[str, float]]) -> ESNQCorrelation:
        """
        ANALYSE CORR√âLATION ES/NQ

        Examine :
        - Corr√©lation prix
        - Divergences momentum
        - Leadership market
        - Signaux d'alignement
        """

        if not es_nq_data or len(self.es_nq_history) < 20:
            return ESNQCorrelation(
                timestamp=pd.Timestamp.now(),
                correlation_coefficient=0.0,
                correlation_strength="unknown",
                aligned=False
            )

        # Extraction donn√©es historiques
        es_prices = [data.get('es_price', 0) for data in self.es_nq_history]
        nq_prices = [data.get('nq_price', 0) for data in self.es_nq_history]

        # Calcul corr√©lation
        if len(es_prices) >= 20:
            correlation_coef = np.corrcoef(es_prices, nq_prices)[0, 1]
        else:
            correlation_coef = 0.0

        # Classification force corr√©lation
        if abs(correlation_coef) >= 0.8:
            correlation_strength = "very_strong"
        elif abs(correlation_coef) >= 0.6:
            correlation_strength = "strong"
        elif abs(correlation_coef) >= 0.4:
            correlation_strength = "moderate"
        else:
            correlation_strength = "weak"

        # Divergence analysis
        if len(es_prices) >= 10:
            es_momentum = (es_prices[-1] - es_prices[-10]) / \
                es_prices[-10] if es_prices[-10] != 0 else 0
            nq_momentum = (nq_prices[-1] - nq_prices[-10]) / \
                nq_prices[-10] if nq_prices[-10] != 0 else 0

            price_divergence = abs(es_momentum - nq_momentum)
            momentum_divergence = price_divergence
        else:
            price_divergence = 0.0
            momentum_divergence = 0.0

        # Leadership analysis
        if len(es_prices) >= 5:
            es_recent_change = (es_prices[-1] - es_prices[-5]) / \
                es_prices[-5] if es_prices[-5] != 0 else 0
            nq_recent_change = (nq_prices[-1] - nq_prices[-5]) / \
                nq_prices[-5] if nq_prices[-5] != 0 else 0

            if abs(es_recent_change) > abs(nq_recent_change):
                market_leader = "ES"
                leadership_strength = abs(es_recent_change) - abs(nq_recent_change)
            else:
                market_leader = "NQ"
                leadership_strength = abs(nq_recent_change) - abs(es_recent_change)
        else:
            market_leader = "ES"
            leadership_strength = 0.0

        # Signaux
        aligned = correlation_coef > self.min_correlation_strength
        divergence_warning = price_divergence > 0.02  # 2% divergence

        return ESNQCorrelation(
            timestamp=pd.Timestamp.now(),
            correlation_coefficient=correlation_coef,
            correlation_strength=correlation_strength,
            price_divergence=price_divergence,
            momentum_divergence=momentum_divergence,
            market_leader=market_leader,
            leadership_strength=leadership_strength,
            aligned=aligned,
            divergence_warning=divergence_warning
        )

    def _classify_market_regime(self,
                                trend_analysis: TrendAnalysis,
                                range_analysis: RangeAnalysis,
                                es_nq_correlation: ESNQCorrelation) -> Tuple[MarketRegime, float]:
        """
        CLASSIFICATION R√âGIME MARCH√â FINAL

        Hi√©rarchie d√©cision :
        1. TREND fort ‚Üí Strong Trend (bullish/bearish)
        2. TREND faible ‚Üí Weak Trend (bullish/bearish)
        3. RANGE avec bias ‚Üí Range biased
        4. RANGE sans bias ‚Üí Range neutral
        5. Sinon ‚Üí Transition ou Unclear
        """

        confidence = 0.0

        # === ANALYSE TREND PRIORITY ===

        trend_strength = trend_analysis.trend_strength
        hh_hl_score = trend_analysis.higher_highs_count + trend_analysis.higher_lows_count
        lh_ll_score = trend_analysis.lower_highs_count + trend_analysis.lower_lows_count
        vwap_slope = trend_analysis.vwap_slope

        # STRONG TREND BULLISH
        if (trend_strength in [TrendStrength.VERY_STRONG, TrendStrength.STRONG] and
            hh_hl_score >= 4 and hh_hl_score > lh_ll_score and
                vwap_slope > 0.5 and trend_analysis.structure_intact):

            confidence = 0.85 + min(trend_analysis.trend_consistency * 0.15, 0.15)
            return MarketRegime.STRONG_TREND_BULLISH, confidence

        # STRONG TREND BEARISH
        elif (trend_strength in [TrendStrength.VERY_STRONG, TrendStrength.STRONG] and
              lh_ll_score >= 4 and lh_ll_score > hh_hl_score and
              vwap_slope < -0.5 and trend_analysis.structure_intact):

            confidence = 0.85 + min(trend_analysis.trend_consistency * 0.15, 0.15)
            return MarketRegime.STRONG_TREND_BEARISH, confidence

        # WEAK TREND BULLISH
        elif (trend_strength == TrendStrength.MODERATE and
              hh_hl_score >= 2 and hh_hl_score > lh_ll_score and
              vwap_slope > 0.2):

            confidence = 0.65 + min(trend_analysis.trend_consistency * 0.2, 0.2)
            return MarketRegime.WEAK_TREND_BULLISH, confidence

        # WEAK TREND BEARISH
        elif (trend_strength == TrendStrength.MODERATE and
              lh_ll_score >= 2 and lh_ll_score > hh_hl_score and
              vwap_slope < -0.2):

            confidence = 0.65 + min(trend_analysis.trend_consistency * 0.2, 0.2)
            return MarketRegime.WEAK_TREND_BEARISH, confidence

        # === ANALYSE RANGE PRIORITY ===

        elif range_analysis.range_detected:

            bias = range_analysis.underlying_bias
            bias_strength = range_analysis.bias_strength
            range_quality = self._calculate_range_quality_score(range_analysis)

            # RANGE BULLISH BIAS
            if bias == "bullish" and bias_strength > 0.5:
                confidence = 0.70 + (range_quality * 0.2)
                return MarketRegime.RANGE_BULLISH_BIAS, confidence

            # RANGE BEARISH BIAS
            elif bias == "bearish" and bias_strength > 0.5:
                confidence = 0.70 + (range_quality * 0.2)
                return MarketRegime.RANGE_BEARISH_BIAS, confidence

            # RANGE NEUTRAL
            else:
                confidence = 0.60 + (range_quality * 0.25)
                return MarketRegime.RANGE_NEUTRAL, confidence

        # === TRANSITION OU UNCLEAR ===

        # Transition si changement r√©cent de r√©gime
        elif self._detect_regime_transition():
            confidence = 0.50
            return MarketRegime.TRANSITION, confidence

        # Unclear par d√©faut
        else:
            confidence = 0.30
            return MarketRegime.UNCLEAR, confidence

    def _generate_regime_implications(self,
                                      regime: MarketRegime,
                                      confidence: float,
                                      trend_analysis: TrendAnalysis,
                                      range_analysis: RangeAnalysis,
                                      es_nq_correlation: ESNQCorrelation,
                                      market_data: MarketData) -> MarketRegimeData:
        """
        G√âN√âRATION IMPLICATIONS TRADING

        D√©termine :
        - Strat√©gie pr√©f√©r√©e (trend/range/wait)
        - Directions autoris√©es (long/short/both)
        - Multiplicateur position sizing
        - Volatilit√© attendue
        """

        # === STRAT√âGIE PR√âF√âR√âE ===

        if regime in [MarketRegime.STRONG_TREND_BULLISH, MarketRegime.STRONG_TREND_BEARISH]:
            preferred_strategy = "trend"
            position_multiplier = 1.3  # Boost pour trends forts
            expected_volatility = "high"

        elif regime in [MarketRegime.WEAK_TREND_BULLISH, MarketRegime.WEAK_TREND_BEARISH]:
            preferred_strategy = "trend"
            position_multiplier = 1.0  # Standard
            expected_volatility = "normal"

        elif regime in [MarketRegime.RANGE_BULLISH_BIAS, MarketRegime.RANGE_BEARISH_BIAS, MarketRegime.RANGE_NEUTRAL]:
            preferred_strategy = "range"
            position_multiplier = 0.9  # L√©g√®rement r√©duit pour range
            expected_volatility = "low"

        else:  # TRANSITION, UNCLEAR
            preferred_strategy = "wait"
            position_multiplier = 0.5  # Tr√®s r√©duit
            expected_volatility = "normal"

        # === DIRECTIONS AUTORIS√âES ===

        allowed_directions = []
        bias_strength = 0.0

        if regime == MarketRegime.STRONG_TREND_BULLISH:
            allowed_directions = ["LONG"]
            bias_strength = trend_analysis.trend_consistency

        elif regime == MarketRegime.WEAK_TREND_BULLISH:
            allowed_directions = ["LONG"]  # Mais plus prudent
            bias_strength = trend_analysis.trend_consistency * 0.7

        elif regime == MarketRegime.STRONG_TREND_BEARISH:
            allowed_directions = ["SHORT"]
            bias_strength = trend_analysis.trend_consistency

        elif regime == MarketRegime.WEAK_TREND_BEARISH:
            allowed_directions = ["SHORT"]  # Mais plus prudent
            bias_strength = trend_analysis.trend_consistency * 0.7

        elif regime == MarketRegime.RANGE_BULLISH_BIAS:
            allowed_directions = ["LONG"]  # Seulement longs en bas range
            bias_strength = range_analysis.bias_strength

        elif regime == MarketRegime.RANGE_BEARISH_BIAS:
            allowed_directions = ["SHORT"]  # Seulement shorts en haut range
            bias_strength = range_analysis.bias_strength

        elif regime == MarketRegime.RANGE_NEUTRAL:
            allowed_directions = ["LONG", "SHORT"]  # Both sides
            bias_strength = 0.0

        else:  # TRANSITION, UNCLEAR
            allowed_directions = []  # Pas de trade
            bias_strength = 0.0

        # === SESSION CONTEXT ===

        session_phase = get_session_phase(market_data.timestamp)
        session_factor = self.session_volatility_factors.get(session_phase.value, 1.0)

        # Ajustement multiplicateur selon session
        position_multiplier *= session_factor

        # === DUR√âE R√âGIME ===

        regime_duration = 0
        if self.regime_history:
            # Comptage dur√©e r√©gime actuel
            for i, past_regime in enumerate(reversed(self.regime_history)):
                if past_regime.regime == regime:
                    regime_duration += 1
                else:
                    break

        return MarketRegimeData(
            timestamp=market_data.timestamp,
            regime=regime,
            regime_confidence=confidence,
            regime_duration_minutes=regime_duration,
            trend_analysis=trend_analysis,
            range_analysis=range_analysis,
            es_nq_correlation=es_nq_correlation,
            preferred_strategy=preferred_strategy,
            allowed_directions=allowed_directions,
            bias_strength=bias_strength,
            expected_volatility=expected_volatility,
            position_sizing_multiplier=position_multiplier,
            session_phase=session_phase.value,
            session_performance_factor=session_factor
        )

    # === HELPER METHODS ===

    def _identify_swing_points(self, bars: List[MarketData]) -> Tuple[List[float], List[float]]:
        """Identification pivots hauts/bas"""
        highs = []
        lows = []

        for i in range(2, len(bars) - 2):
            # Pivot high : high[i] > high[i-1] and high[i] > high[i+1]
            if (bars[i].high > bars[i-1].high and bars[i].high > bars[i+1].high and
                    bars[i].high > bars[i-2].high and bars[i].high > bars[i+2].high):
                highs.append(bars[i].high)

            # Pivot low : low[i] < low[i-1] and low[i] < low[i+1]
            if (bars[i].low < bars[i-1].low and bars[i].low < bars[i+1].low and
                    bars[i].low < bars[i-2].low and bars[i].low < bars[i+2].low):
                lows.append(bars[i].low)

        return highs, lows

    def _count_higher_structure(self, highs: List[float], lows: List[float]) -> Tuple[int, int]:
        """Comptage Higher Highs / Higher Lows"""
        hh_count = 0
        hl_count = 0

        # Higher Highs
        for i in range(1, len(highs)):
            if highs[i] > highs[i-1]:
                hh_count += 1

        # Higher Lows
        for i in range(1, len(lows)):
            if lows[i] > lows[i-1]:
                hl_count += 1

        return hh_count, hl_count

    def _count_lower_structure(self, highs: List[float], lows: List[float]) -> Tuple[int, int]:
        """Comptage Lower Highs / Lower Lows"""
        lh_count = 0
        ll_count = 0

        # Lower Highs
        for i in range(1, len(highs)):
            if highs[i] < highs[i-1]:
                lh_count += 1

        # Lower Lows
        for i in range(1, len(lows)):
            if lows[i] < lows[i-1]:
                ll_count += 1

        return lh_count, ll_count

    def _calculate_structure_score(self, hh: int, hl: int, lh: int, ll: int) -> float:
        """Score structure Dow Theory"""
        bullish_score = (hh + hl) / max(hh + hl + lh + ll, 1)
        bearish_score = (lh + ll) / max(hh + hl + lh + ll, 1)

        # Retourne force de la structure dominante
        return max(bullish_score, bearish_score)

    def _calculate_momentum_score(self, bars: List[MarketData]) -> float:
        """Calcul score momentum"""
        if len(bars) < 10:
            return 0.0

        # ROC (Rate of Change) sur diff√©rentes p√©riodes
        roc_5 = (bars[-1].close - bars[-6].close) / bars[-6].close if bars[-6].close != 0 else 0
        roc_10 = (bars[-1].close - bars[-11].close) / bars[-11].close if bars[-11].close != 0 else 0

        # Momentum composite
        momentum = (roc_5 * 0.6 + roc_10 * 0.4) * 100  # Percentage

        return min(abs(momentum) / 5.0, 1.0)  # Normalise √† 1.0

    def _find_most_tested_level(self, prices: List[float], candidates: np.ndarray) -> float:
        """Trouve niveau le plus test√© parmi candidats"""
        best_level = candidates[0]
        max_tests = 0

        for candidate in candidates:
            tests = self._count_level_tests(prices, candidate, tolerance=2*ES_TICK_SIZE)
            if tests > max_tests:
                max_tests = tests
                best_level = candidate

        return best_level

    def _count_level_tests(self, prices: List[float], level: float, tolerance: float) -> int:
        """Compte tests d'un niveau"""
        return sum(1 for price in prices if abs(price - level) <= tolerance)

    def _calculate_level_respect_rate(self,
                                      bars: List[MarketData],
                                      support: float,
                                      resistance: float) -> float:
        """Calcul taux respect des niveaux"""

        violations = 0
        total_tests = 0

        for bar in bars:
            # Test support
            if abs(bar.low - support) <= 2 * ES_TICK_SIZE:
                total_tests += 1
                if bar.close < support - ES_TICK_SIZE:  # Violation
                    violations += 1

            # Test r√©sistance
            if abs(bar.high - resistance) <= 2 * ES_TICK_SIZE:
                total_tests += 1
                if bar.close > resistance + ES_TICK_SIZE:  # Violation
                    violations += 1

        if total_tests == 0:
            return 1.0  # Pas de tests = respect parfait

        return 1.0 - (violations / total_tests)

    def _calculate_range_quality_score(self, range_analysis: RangeAnalysis) -> float:
        """Score qualit√© range"""
        score = 0.0

        # Tests des niveaux (30%)
        test_score = min((range_analysis.support_tests + range_analysis.resistance_tests) / 8, 1.0)
        score += test_score * 0.3

        # Respect niveaux (25%)
        score += range_analysis.level_respect_rate * 0.25

        # Dur√©e (20%)
        duration_score = min(range_analysis.range_duration_minutes / 60, 1.0)  # Normalise √† 1h
        score += duration_score * 0.2

        # Taille optimale (15%)
        size = range_analysis.range_size_ticks
        if 15 <= size <= 30:  # Zone optimale
            size_score = 1.0
        elif 12 <= size <= 40:  # Acceptable
            size_score = 0.7
        else:
            size_score = 0.3
        score += size_score * 0.15

        # Volume contraction (10%)
        if range_analysis.volume_contraction:
            score += 0.1

        return min(score, 1.0)

    def _detect_regime_transition(self) -> bool:
        """D√©tection transition de r√©gime"""
        if len(self.regime_history) < 3:
            return False

        # Changement r√©cent de r√©gime
        recent_regimes = [r.regime for r in list(self.regime_history)[-3:]]

        # Si les 3 derniers r√©gimes sont diff√©rents = transition
        return len(set(recent_regimes)) == 3

    def _update_regime_history(self, regime_data: MarketRegimeData):
        """Mise √† jour historique r√©gimes"""
        self.regime_history.append(regime_data)

        # Mise √† jour stats
        self.stats['regimes_detected'] += 1

        if "trend" in regime_data.regime.value:
            self.stats['trend_periods'] += 1
        elif "range" in regime_data.regime.value:
            self.stats['range_periods'] += 1
        else:
            self.stats['transition_periods'] += 1

        # D√©tection changement r√©gime
        if len(self.regime_history) >= 2:
            if self.regime_history[-1].regime != self.regime_history[-2].regime:
                self.stats['regime_changes'] += 1

    def get_statistics(self) -> Dict[str, Any]:
        """Statistiques d√©tecteur r√©gime"""
        total_periods = self.stats['regimes_detected']

        return {
            'total_regimes_detected': total_periods,
            'trend_periods': self.stats['trend_periods'],
            'range_periods': self.stats['range_periods'],
            'transition_periods': self.stats['transition_periods'],
            'regime_changes': self.stats['regime_changes'],
            'trend_percentage': (self.stats['trend_periods'] / total_periods * 100) if total_periods > 0 else 0,
            'range_percentage': (self.stats['range_periods'] / total_periods * 100) if total_periods > 0 else 0,
            'ranges_filtered_small': self.stats['ranges_filtered_small'],
            'ranges_filtered_large': self.stats['ranges_filtered_large'],
            'current_regime': self.current_regime.regime.value if self.current_regime else "None",
            'current_confidence': self.current_regime.regime_confidence if self.current_regime else 0.0,
            'current_bias': self.current_regime.allowed_directions if self.current_regime else [],
            'filter_efficiency': f"{self.stats['ranges_filtered_small'] + self.stats['ranges_filtered_large']} ranges filtr√©s"
        }

# === FACTORY FUNCTIONS ===


def create_market_regime_detector(config: Optional[Dict[str, Any]] = None) -> MarketRegimeDetector:
    """Factory function pour d√©tecteur r√©gime"""
    return MarketRegimeDetector(config)


def analyze_market_regime(market_data: MarketData,
                          es_nq_data: Optional[Dict[str, float]] = None,
                          structure_data: Optional[Dict[str, Any]] = None,
                          volume_data: Optional[Dict[str, float]] = None,
                          detector: Optional[MarketRegimeDetector] = None) -> MarketRegimeData:
    """Helper function pour analyse r√©gime"""

    if detector is None:
        detector = create_market_regime_detector()

    return detector.analyze_market_regime(
        market_data=market_data,
        es_nq_data=es_nq_data,
        structure_data=structure_data,
        volume_data=volume_data
    )

# === TESTING ===


def test_market_regime_detector():
    """Test complet d√©tecteur r√©gime"""
    logger.debug("TEST MARKET REGIME DETECTOR")
    print("=" * 45)

    # Cr√©ation d√©tecteur
    detector = create_market_regime_detector()

    # Simulation trend haussier puis range
    regimes_detected = []

    logger.info("üìà SIMULATION TREND HAUSSIER:")
    base_price = 4500.0

    # Phase 1: Trend haussier (HH/HL)
    for i in range(40):
        trend_price = base_price + (i * 0.5) + np.random.normal(0, 1)

        market_data = MarketData(
            timestamp=pd.Timestamp.now() + pd.Timedelta(minutes=i),
            symbol="ES",
            open=trend_price - 0.5,
            high=trend_price + 1.5,
            low=trend_price - 1.0,
            close=trend_price,
            volume=1500 + int(np.random.normal(0, 200))
        )

        # Structure data avec VWAP slope positif
        structure_data = {
            'vwap_slope': 0.6,  # Slope haussier
            'vwap_price': trend_price - 1,
            'poc_price': trend_price - 0.5
        }

        # ES/NQ data align√©
        es_nq_data = {
            'es_price': trend_price,
            'nq_price': trend_price * 4.5,  # Ratio ES/NQ approximatif
        }

        regime_data = detector.analyze_market_regime(
            market_data=market_data,
            structure_data=structure_data,
            es_nq_data=es_nq_data
        )

        regimes_detected.append(regime_data)

        if i % 10 == 0:
            print(f"[{i:2d}] R√©gime: {regime_data.regime.value} "
                  f"(conf: {regime_data.regime_confidence:.2f})")

    logger.info("\nüìä SIMULATION RANGE (minimum 12 ticks):")

    # Phase 2: Range 4520-4535 (15 ticks - acceptable)
    range_support = 4520.0
    range_resistance = 4535.0
    range_mid = (range_support + range_resistance) / 2

    for i in range(30):
        # Prix oscille dans range
        if i % 6 == 0:  # Test support
            range_price = range_support + np.random.normal(0, 0.5)
        elif i % 6 == 3:  # Test r√©sistance
            range_price = range_resistance + np.random.normal(0, 0.5)
        else:  # Dans range
            range_price = range_mid + np.random.normal(0, 3)

        # Clamp dans range
        range_price = max(range_support - 1, min(range_resistance + 1, range_price))

        market_data = MarketData(
            timestamp=pd.Timestamp.now() + pd.Timedelta(minutes=40+i),
            symbol="ES",
            open=range_price - 0.3,
            high=range_price + 0.8,
            low=range_price - 0.8,
            close=range_price,
            volume=1200 + int(np.random.normal(0, 150))  # Volume plus faible
        )

        # VWAP slope neutre pour range
        structure_data = {
            'vwap_slope': 0.1,  # Quasi flat
            'vwap_price': range_mid,
            'poc_price': range_mid + 1
        }

        regime_data = detector.analyze_market_regime(
            market_data=market_data,
            structure_data=structure_data,
            es_nq_data={'es_price': range_price, 'nq_price': range_price * 4.5}
        )

        regimes_detected.append(regime_data)

        if i % 8 == 0:
            print(f"[{i:2d}] R√©gime: {regime_data.regime.value} "
                  f"(conf: {regime_data.regime_confidence:.2f})")

            if regime_data.range_analysis and regime_data.range_analysis.range_detected:
                range_info = regime_data.range_analysis
                print(f"     Range: {range_info.support_level:.1f}-{range_info.resistance_level:.1f} "
                      f"({range_info.range_size_ticks:.1f} ticks)")

    # Test range trop petit (filtr√©)
    logger.info("\n‚ùå TEST RANGE TROP PETIT (filtre <12 ticks):")

    # Micro-range 4530-4536 (6 ticks - filtr√©)
    micro_support = 4530.0
    micro_resistance = 4536.0  # Seulement 6 ticks

    for i in range(15):
        micro_price = micro_support + (i % 2) * (micro_resistance -
                                                 micro_support) + np.random.normal(0, 0.3)

        market_data = MarketData(
            timestamp=pd.Timestamp.now() + pd.Timedelta(minutes=70+i),
            symbol="ES",
            open=micro_price,
            high=micro_price + 0.5,
            low=micro_price - 0.5,
            close=micro_price,
            volume=1000
        )

        regime_data = detector.analyze_market_regime(market_data=market_data)

        if i == 10:  # Check apr√®s stabilisation
            if regime_data.range_analysis:
                print(f"Range {regime_data.range_analysis.range_size_ticks:.1f} ticks: "
                      f"D√©tect√© = {regime_data.range_analysis.range_detected}")

    # Analyse finale
    final_regime = regimes_detected[-1]

    logger.info("\nüìä R√âGIME FINAL:")
    logger.info("   ‚Ä¢ R√©gime: {final_regime.regime.value}")
    logger.info("   ‚Ä¢ Confidence: {final_regime.regime_confidence:.2f}")
    logger.info("   ‚Ä¢ Strat√©gie: {final_regime.preferred_strategy}")
    logger.info("   ‚Ä¢ Directions: {final_regime.allowed_directions}")
    logger.info("   ‚Ä¢ Bias strength: {final_regime.bias_strength:.2f}")
    logger.info("   ‚Ä¢ Position multiplier: {final_regime.position_sizing_multiplier:.2f}")

    if final_regime.range_analysis and final_regime.range_analysis.range_detected:
        range_data = final_regime.range_analysis
        logger.info("   ‚Ä¢ Range: {range_data.support_level:.1f}-{range_data.resistance_level:.1f}")
        logger.info("   ‚Ä¢ Range size: {range_data.range_size_ticks:.1f} ticks")
        logger.info("   ‚Ä¢ Range type: {range_data.range_type.value}")
        logger.info("   ‚Ä¢ Tests: S={range_data.support_tests}, R={range_data.resistance_tests}")

    # Statistiques
    stats = detector.get_statistics()
    logger.info("\nüìà STATISTICS:")
    for key, value in stats.items():
        logger.info("   ‚Ä¢ {key}: {value}")

    logger.info("\nüéØ MARKET REGIME DETECTOR TEST COMPLETED")
    return True


if __name__ == "__main__":
    test_market_regime_detector()
