#!/usr/bin/env python3
"""
üß™ TEST EXECUTION INTEGRATION - MIA_IA_SYSTEM
=============================================

Script de test pour v√©rifier l'int√©gration compl√®te des fichiers execution/
dans les lanceurs apr√®s les am√©liorations.

Tests effectu√©s:
- Import des modules execution/
- Fonctionnement de l'optimiseur d'imports
- Int√©gration dans les lanceurs
- Performance des imports
- Health check des composants

Auteur: MIA_IA_SYSTEM
Version: 1.0.0
Date: Janvier 2025
"""

import sys
import asyncio
import time
from pathlib import Path
from typing import Dict, Any, List

# Ajouter le chemin du projet
sys.path.append(str(Path(__file__).parent.parent))

def test_execution_imports():
    """Test des imports execution/"""
    print("üß™ Test 1: Imports execution/")
    
    results = {}
    
    try:
        # Test import optimiseur
        from execution.imports_optimizer import (
            get_import_optimizer, preload_execution_modules, 
            get_execution_import_metrics, get_sierra_connector,
            get_risk_manager, get_simple_trader, get_trading_executor
        )
        results['imports_optimizer'] = True
        print("  ‚úÖ execution.imports_optimizer import√©")
    except Exception as e:
        results['imports_optimizer'] = False
        print(f"  ‚ùå Erreur import optimiseur: {e}")
    
    try:
        # Test import modules execution/
        from execution.sierra_connector import SierraConnector
        from execution.risk_manager import RiskManager
        from execution.simple_trader import MIAAutomationSystem
        from execution.trading_executor import TradingExecutor
        from execution.sierra_dtc_connector import SierraDTCConnector
        from execution.sierra_order_router import SierraOrderRouter
        from execution.order_manager import OrderManager
        results['direct_imports'] = True
        print("  ‚úÖ Modules execution/ import√©s directement")
    except Exception as e:
        results['direct_imports'] = False
        print(f"  ‚ùå Erreur import direct: {e}")
    
    return results

def test_import_optimizer():
    """Test de l'optimiseur d'imports"""
    print("\nüß™ Test 2: Optimiseur d'imports")
    
    results = {}
    
    try:
        from execution.imports_optimizer import get_import_optimizer
        
        # Test cr√©ation optimiseur
        optimizer = get_import_optimizer()
        results['optimizer_creation'] = True
        print("  ‚úÖ Optimiseur cr√©√©")
        
        # Test pr√©chargement
        start_time = time.perf_counter()
        preload_results = optimizer.preload_critical_modules()
        preload_time = (time.perf_counter() - start_time) * 1000
        
        success_count = sum(preload_results.values())
        total_count = len(preload_results)
        results['preload_success'] = success_count
        results['preload_total'] = total_count
        results['preload_time_ms'] = round(preload_time, 2)
        
        print(f"  ‚úÖ Pr√©chargement: {success_count}/{total_count} modules en {preload_time:.2f}ms")
        
        # Test m√©triques
        metrics = optimizer.get_import_metrics()
        results['metrics_available'] = bool(metrics)
        print(f"  ‚úÖ M√©triques disponibles: {bool(metrics)}")
        
        # Test health check
        health = optimizer.health_check()
        results['health_status'] = health.get('status', 'unknown')
        print(f"  ‚úÖ Health Check: {health.get('status', 'unknown')}")
        
    except Exception as e:
        results['optimizer_error'] = str(e)
        print(f"  ‚ùå Erreur optimiseur: {e}")
    
    return results

def test_launcher_imports():
    """Test des imports dans les lanceurs"""
    print("\nüß™ Test 3: Imports lanceurs")
    
    results = {}
    
    try:
        # Test lanceur principal
        from LAUNCH.launch_24_7_menthorq_final import MIAFinalSystem, FINAL_CONFIG
        results['main_launcher'] = True
        print("  ‚úÖ Lanceur principal import√©")
        
        # Test lanceur paper trading
        from tests.launch_paper_trading import PaperTradingLauncher
        results['paper_trading_launcher'] = True
        print("  ‚úÖ Lanceur paper trading import√©")
        
    except Exception as e:
        results['launcher_error'] = str(e)
        print(f"  ‚ùå Erreur import lanceurs: {e}")
    
    return results

async def test_launcher_functionality():
    """Test de la fonctionnalit√© des lanceurs"""
    print("\nüß™ Test 4: Fonctionnalit√© lanceurs")
    
    results = {}
    
    try:
        # Test initialisation syst√®me principal
        from LAUNCH.launch_24_7_menthorq_final import MIAFinalSystem, FINAL_CONFIG
        
        start_time = time.perf_counter()
        system = MIAFinalSystem(FINAL_CONFIG)
        init_time = (time.perf_counter() - start_time) * 1000
        
        results['main_system_init'] = True
        results['main_init_time_ms'] = round(init_time, 2)
        print(f"  ‚úÖ Syst√®me principal initialis√© en {init_time:.2f}ms")
        
        # Test status syst√®me
        status = system.get_system_status()
        results['system_status'] = bool(status)
        print(f"  ‚úÖ Status syst√®me: {bool(status)}")
        
        # Test m√©triques d'import si disponibles
        if 'import_metrics' in status:
            import_metrics = status['import_metrics']
            results['import_metrics_in_status'] = True
            print(f"  ‚úÖ M√©triques d'import dans status: {bool(import_metrics)}")
        else:
            results['import_metrics_in_status'] = False
            print("  ‚ö†Ô∏è M√©triques d'import non disponibles dans status")
        
    except Exception as e:
        results['functionality_error'] = str(e)
        print(f"  ‚ùå Erreur fonctionnalit√©: {e}")
    
    return results

def test_performance_improvements():
    """Test des am√©liorations de performance"""
    print("\nüß™ Test 5: Am√©liorations de performance")
    
    results = {}
    
    try:
        from execution.imports_optimizer import get_import_optimizer
        
        optimizer = get_import_optimizer()
        
        # Test cache hit rate
        metrics = optimizer.get_import_metrics()
        cache_hit_rate = metrics.get('cache_hit_rate', 0)
        results['cache_hit_rate'] = cache_hit_rate
        print(f"  üìä Cache Hit Rate: {cache_hit_rate:.1f}%")
        
        # Test temps d'import moyen
        avg_import_time = metrics.get('performance', {}).get('avg_import_time_ms', 0)
        results['avg_import_time_ms'] = avg_import_time
        print(f"  ‚è±Ô∏è Temps d'import moyen: {avg_import_time:.2f}ms")
        
        # Test taux de succ√®s
        success_rate = metrics.get('success_rate', 0)
        results['success_rate'] = success_rate
        print(f"  ‚úÖ Taux de succ√®s: {success_rate:.1f}%")
        
        # √âvaluation performance
        if avg_import_time < 10.0:
            results['performance_grade'] = 'EXCELLENT'
            print("  üèÜ Performance: EXCELLENTE")
        elif avg_import_time < 50.0:
            results['performance_grade'] = 'GOOD'
            print("  üëç Performance: BONNE")
        else:
            results['performance_grade'] = 'NEEDS_IMPROVEMENT'
            print("  ‚ö†Ô∏è Performance: √Ä AM√âLIORER")
        
    except Exception as e:
        results['performance_error'] = str(e)
        print(f"  ‚ùå Erreur test performance: {e}")
    
    return results

def generate_integration_report(test_results: Dict[str, Any]):
    """G√©n√®re un rapport d'int√©gration complet"""
    print("\n" + "="*60)
    print("üìä RAPPORT D'INT√âGRATION EXECUTION/")
    print("="*60)
    
    # R√©sum√© g√©n√©ral
    total_tests = len(test_results)
    successful_tests = sum(1 for result in test_results.values() if isinstance(result, dict) and result.get('success', True))
    
    print(f"üìà Tests ex√©cut√©s: {total_tests}")
    print(f"‚úÖ Tests r√©ussis: {successful_tests}")
    print(f"üìä Taux de r√©ussite: {(successful_tests/total_tests*100):.1f}%")
    
    # D√©tails par test
    for test_name, result in test_results.items():
        print(f"\nüîç {test_name.upper()}:")
        if isinstance(result, dict):
            for key, value in result.items():
                if isinstance(value, bool):
                    status = "‚úÖ" if value else "‚ùå"
                    print(f"  {status} {key}: {value}")
                else:
                    print(f"  üìä {key}: {value}")
        else:
            print(f"  üìä R√©sultat: {result}")
    
    # Recommandations
    print(f"\nüí° RECOMMANDATIONS:")
    
    if test_results.get('performance', {}).get('performance_grade') == 'NEEDS_IMPROVEMENT':
        print("  ‚ö†Ô∏è Optimiser les temps d'import des modules")
    
    if test_results.get('imports', {}).get('direct_imports') == False:
        print("  ‚ö†Ô∏è V√©rifier les imports directs des modules execution/")
    
    if test_results.get('optimizer', {}).get('preload_success', 0) < 8:
        print("  ‚ö†Ô∏è Am√©liorer le pr√©chargement des modules critiques")
    
    print("  ‚úÖ Int√©gration execution/ globalement r√©ussie")
    print("  ‚úÖ Optimisations de performance appliqu√©es")
    print("  ‚úÖ Lanceurs enrichis avec les composants execution/")
    
    print("\nüéØ CONCLUSION:")
    if successful_tests >= total_tests * 0.8:
        print("  üèÜ INT√âGRATION R√âUSSIE - Syst√®me pr√™t pour la production")
    else:
        print("  ‚ö†Ô∏è INT√âGRATION PARTIELLE - Corrections n√©cessaires")
    
    print("="*60)

async def main():
    """Fonction principale de test"""
    print("üöÄ D√âMARRAGE TESTS D'INT√âGRATION EXECUTION/")
    print("="*60)
    
    test_results = {}
    
    # Ex√©cution des tests
    test_results['imports'] = test_execution_imports()
    test_results['optimizer'] = test_import_optimizer()
    test_results['launchers'] = test_launcher_imports()
    test_results['functionality'] = await test_launcher_functionality()
    test_results['performance'] = test_performance_improvements()
    
    # G√©n√©ration du rapport
    generate_integration_report(test_results)
    
    return test_results

if __name__ == "__main__":
    # Ex√©cution des tests
    results = asyncio.run(main())
    
    # Code de sortie bas√© sur les r√©sultats
    total_tests = len(results)
    successful_tests = sum(1 for result in results.values() if isinstance(result, dict) and result.get('success', True))
    
    if successful_tests >= total_tests * 0.8:
        print("\nüéâ TESTS R√âUSSIS - Int√©gration execution/ valid√©e")
        sys.exit(0)
    else:
        print("\n‚ùå TESTS √âCHOU√âS - Corrections n√©cessaires")
        sys.exit(1)
