#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de synthÃ¨se des anomalies dÃ©tectÃ©es dans chart_3_20250904.jsonl
Analyse les rÃ©sultats et propose des solutions
"""

import json
import csv
from pathlib import Path
from collections import Counter, defaultdict

def analyser_synthese():
    """Analyse la synthÃ¨se des anomalies dÃ©tectÃ©es"""
    print("ðŸ” SYNTHÃˆSE DES ANOMALIES DÃ‰TECTÃ‰ES")
    print("=" * 60)
    
    # VÃ©rifier l'existence des fichiers
    report_path = Path("report.md")
    anomalies_path = Path("anomalies.csv")
    
    if not report_path.exists():
        print("âŒ Fichier report.md non trouvÃ©. ExÃ©cutez d'abord analyze_chart_data.py")
        return
        
    if not anomalies_path.exists():
        print("âŒ Fichier anomalies.csv non trouvÃ©. ExÃ©cutez d'abord analyze_chart_data.py")
        return
    
    # Analyser le rapport
    print("ðŸ“Š ANALYSE DU RAPPORT...")
    print("-" * 40)
    
    with open(report_path, 'r', encoding='utf-8') as f:
        content = f.read()
        
    # Extraire les informations clÃ©s
    lines = content.split('\n')
    
    # Chercher les statistiques
    total_records = None
    total_anomalies = None
    
    for line in lines:
        if "Total des enregistrements:" in line:
            total_records = line.split(":")[1].strip().replace(",", "")
        elif "Total des anomalies:" in line:
            total_anomalies = line.split(":")[1].strip()
            
    if total_records and total_anomalies:
        print(f"ðŸ“ˆ Total enregistrements: {total_records}")
        print(f"âš ï¸  Total anomalies: {total_anomalies}")
        
        # Calculer le pourcentage d'anomalies
        try:
            total_records_int = int(total_records)
            total_anomalies_int = int(total_anomalies)
            pourcentage = (total_anomalies_int / total_records_int) * 100
            print(f"ðŸ“Š Pourcentage d'anomalies: {pourcentage:.2f}%")
        except:
            pass
    
    # Analyser le CSV des anomalies
    print("\nðŸ“‹ ANALYSE DÃ‰TAILLÃ‰E DES ANOMALIES...")
    print("-" * 40)
    
    anomalies_by_type = defaultdict(list)
    anomalies_by_rule = defaultdict(list)
    
    try:
        with open(anomalies_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                anomalies_by_type[row['type']].append(row)
                anomalies_by_rule[row['rule']].append(row)
                
    except Exception as e:
        print(f"âŒ Erreur lecture CSV: {e}")
        return
    
    # Afficher le rÃ©sumÃ© par type
    print("\nðŸŽ¯ RÃ‰SUMÃ‰ PAR TYPE DE DONNÃ‰ES:")
    print("-" * 40)
    
    for data_type, anomalies in anomalies_by_type.items():
        count = len(anomalies)
        if count > 0:
            print(f"ðŸ”¹ {data_type}: {count} anomalies")
            
            # Analyser les rÃ¨gles les plus frÃ©quentes pour ce type
            rules = Counter(anom['rule'] for anom in anomalies)
            top_rules = rules.most_common(3)
            for rule, rule_count in top_rules:
                print(f"   - {rule}: {rule_count}")
    
    # Analyser les rÃ¨gles les plus problÃ©matiques
    print("\nðŸš¨ RÃˆGLES LES PLUS PROBLÃ‰MATIQUES:")
    print("-" * 40)
    
    rule_counts = Counter(anom['rule'] for anom in anomalies_by_rule['scale_issue'])
    for rule, count in rule_counts.most_common(10):
        print(f"ðŸ”´ {rule}: {count} violations")
        
        # Analyser quelques exemples
        examples = anomalies_by_rule[rule][:3]
        for i, example in enumerate(examples, 1):
            print(f"   Exemple {i}: {example['message'][:80]}...")
    
    # Analyser les problÃ¨mes spÃ©cifiques
    print("\nðŸ” ANALYSE DES PROBLÃˆMES SPÃ‰CIFIQUES:")
    print("-" * 40)
    
    # 1. ProblÃ¨me d'Ã©chelle des quotes
    scale_issues = anomalies_by_rule.get('scale_issue', [])
    if scale_issues:
        print(f"ðŸ”´ PROBLÃˆME D'Ã‰CHELLE QUOTES: {len(scale_issues)} violations")
        print("   ðŸ’¡ Les quotes semblent avoir une Ã©chelle incorrecte (Ã—10, Ã—100, etc.)")
        print("   ðŸŽ¯ Solution: VÃ©rifier la configuration d'Ã©chelle dans Sierra Chart")
        
        # Analyser quelques exemples
        for i, issue in enumerate(scale_issues[:3], 1):
            print(f"   Exemple {i}: {issue['message']}")
    
    # 2. ProblÃ¨me VVA (VAL >= VAH)
    vva_issues = anomalies_by_rule.get('val_vah_inverted', [])
    if vva_issues:
        print(f"\nðŸ”´ PROBLÃˆME VVA: {len(vva_issues)} violations")
        print("   ðŸ’¡ VAL (Volume Area Low) >= VAH (Volume Area High) - IncohÃ©rent")
        print("   ðŸŽ¯ Solution: VÃ©rifier la logique de calcul du Volume Profile")
        
        # Analyser quelques exemples
        for i, issue in enumerate(vva_issues[:3], 1):
            print(f"   Exemple {i}: {issue['message']}")
    
    # 3. ProblÃ¨me VIX mode
    vix_issues = anomalies_by_rule.get('mode_invalid', [])
    if vix_issues:
        print(f"\nðŸ”´ PROBLÃˆME VIX: {len(vix_issues)} violations")
        print("   ðŸ’¡ Mode VIX invalide (0 au lieu de 'normal', 'contango', 'backwardation')")
        print("   ðŸŽ¯ Solution: VÃ©rifier la configuration des Ã©tudes VIX dans Sierra Chart")
    
    # 4. ProblÃ¨me NBCV delta
    nbcv_issues = anomalies_by_rule.get('delta_mismatch', [])
    if nbcv_issues:
        print(f"\nðŸ”´ PROBLÃˆME NBCV: {len(nbcv_issues)} violations")
        print("   ðŸ’¡ Delta calculÃ© â‰  Delta fourni")
        print("   ðŸŽ¯ Solution: VÃ©rifier la logique de calcul du delta dans Sierra Chart")
    
    # 5. ProblÃ¨me de timestamps dÃ©croissants
    time_issues = anomalies_by_rule.get('decreasing_time', [])
    if time_issues:
        print(f"\nðŸ”´ PROBLÃˆME TIMESTAMPS: {len(time_issues)} violations")
        print("   ðŸ’¡ Timestamps non chronologiques")
        print("   ðŸŽ¯ Solution: VÃ©rifier la synchronisation des donnÃ©es")
    
    # Recommandations gÃ©nÃ©rales
    print("\nðŸ’¡ RECOMMANDATIONS GÃ‰NÃ‰RALES:")
    print("-" * 40)
    
    print("1. ðŸ”§ CONFIGURATION SIERRA CHART:")
    print("   - VÃ©rifier les paramÃ¨tres d'Ã©chelle des quotes")
    print("   - ContrÃ´ler la configuration des Ã©tudes VIX")
    print("   - Valider les paramÃ¨tres du Volume Profile")
    
    print("\n2. ðŸ“Š QUALITÃ‰ DES DONNÃ‰ES:")
    print("   - VÃ©rifier la source des donnÃ©es (feed, provider)")
    print("   - ContrÃ´ler la synchronisation des timestamps")
    print("   - Valider la cohÃ©rence des calculs NBCV")
    
    print("\n3. ðŸš¨ PRIORITÃ‰S DE CORRECTION:")
    print("   - Ã‰chelle des quotes (151,018 violations)")
    print("   - Configuration VVA (7,072 violations)")
    print("   - Mode VIX (3,536 violations)")
    print("   - CohÃ©rence NBCV (20 violations)")
    
    print("\n4. ðŸ“ˆ MONITORING:")
    print("   - Mettre en place des alertes sur les anomalies")
    print("   - Surveiller la qualitÃ© des donnÃ©es en temps rÃ©el")
    print("   - Valider les corrections aprÃ¨s reconfiguration")
    
    # Statistiques finales
    print("\nðŸ“Š STATISTIQUES FINALES:")
    print("-" * 40)
    
    total_anomalies = sum(len(anomalies) for anomalies in anomalies_by_type.values())
    total_records_analyzed = 178423  # D'aprÃ¨s le rapport
    
    print(f"ðŸ“ˆ Enregistrements analysÃ©s: {total_records_analyzed:,}")
    print(f"âš ï¸  Anomalies dÃ©tectÃ©es: {total_anomalies:,}")
    print(f"ðŸ“Š Taux d'anomalies: {(total_anomalies/total_records_analyzed)*100:.2f}%")
    
    # Types de donnÃ©es avec problÃ¨mes
    problematic_types = [t for t, anomalies in anomalies_by_type.items() if len(anomalies) > 0]
    print(f"ðŸ”´ Types problÃ©matiques: {len(problematic_types)}")
    
    # Types de donnÃ©es sains
    healthy_types = [t for t, anomalies in anomalies_by_type.items() if len(anomalies) == 0]
    print(f"âœ… Types sains: {len(healthy_types)}")
    
    print("\n" + "=" * 60)
    print("ðŸŽ¯ SYNTHÃˆSE TERMINÃ‰E")
    print("=" * 60)

if __name__ == "__main__":
    analyser_synthese()







