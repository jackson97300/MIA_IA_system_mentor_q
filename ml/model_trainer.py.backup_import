"""
ml/model_trainer.py

PIPELINE ENTRA√éNEMENT ML COMPLET - OBJECTIF FINAL ML MODULE
Orchestrateur central pour l'entra√Ænement des mod√®les Battle Navale
Int√©gration compl√®te avec snapshots, validation, et d√©ploiement automatique

FONCTIONNALIT√âS :
1. Pipeline complet de training automatis√©
2. Int√©gration native avec snapshots Battle Navale
3. Gestion versions de mod√®les et d√©ploiement
4. Training incr√©mental et continuous learning
5. Validation robuste et A/B testing
6. Export mod√®les production-ready
7. Monitoring performance et d√©gradation
8. Interface simple pour automation

ARCHITECTURE : Production-grade, robuste, int√©gr√© Battle Navale
"""

# === STDLIB ===
import os
import sys
import time
import logging
import json
import pickle
import shutil
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field, asdict
from pathlib import Path
from datetime import datetime, timezone, timedelta
from enum import Enum
from collections import defaultdict
import threading
import schedule

# === THIRD-PARTY ===
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import joblib

# === LOCAL IMPORTS ===
from config import get_trading_config, get_automation_config
from core.base_types import (
    MarketData, TradingSignal, SignalType, SignalStrength,
    TradeResult, ES_TICK_SIZE, ES_TICK_VALUE
)

# ML Components integration
from ml.simple_model import SimpleLinearPredictor, ModelType, ModelStatus, create_signal_classifier
from ml.data_processor import MLDataProcessor, ProcessedDataset, create_battle_navale_processor
from ml.model_validator import ModelValidator, ValidationLevel, create_rigorous_validator

# Logger
logger = logging.getLogger(__name__)

# === TRAINING ENUMS ===


class TrainingMode(Enum):
    """Modes d'entra√Ænement"""
    INITIAL = "initial"              # Premier entra√Ænement
    INCREMENTAL = "incremental"      # Entra√Ænement incr√©mental
    RETRAIN = "retrain"             # Re-entra√Ænement complet
    CONTINUOUS = "continuous"        # Continuous learning
    EXPERIMENTAL = "experimental"   # Mode exp√©rimental


class ModelStage(Enum):
    """√âtapes du mod√®le"""
    DEVELOPMENT = "development"      # En d√©veloppement
    TESTING = "testing"             # En test
    STAGING = "staging"             # Pre-production
    PRODUCTION = "production"       # En production
    RETIRED = "retired"             # Retir√©


class TrainingStatus(Enum):
    """Statuts d'entra√Ænement"""
    IDLE = "idle"
    PREPARING_DATA = "preparing_data"
    TRAINING = "training"
    VALIDATING = "validating"
    DEPLOYING = "deploying"
    COMPLETED = "completed"
    FAILED = "failed"


class PerformanceThreshold(Enum):
    """Seuils de performance"""
    MINIMUM_ACCURACY = 0.60         # 60% minimum
    TARGET_ACCURACY = 0.70          # 70% cible
    EXCELLENCE_ACCURACY = 0.80      # 80% excellence
    MINIMUM_PRECISION = 0.65        # 65% precision minimum
    MINIMUM_F1_SCORE = 0.65         # 65% F1 minimum

# === TRAINING DATA STRUCTURES ===


@dataclass
class TrainingConfig:
    """Configuration d'entra√Ænement"""
    # Donn√©es
    min_samples_required: int = 100
    max_samples_per_training: int = 5000
    train_test_split: float = 0.8
    validation_split: float = 0.1

    # Mod√®le
    model_type: ModelType = ModelType.SIGNAL_CLASSIFIER
    hyperparameters: Dict[str, Any] = field(default_factory=dict)

    # Training
    training_mode: TrainingMode = TrainingMode.INITIAL
    auto_retrain_threshold: float = 0.05  # 5% d√©gradation performance
    max_training_time_minutes: int = 30

    # Validation
    validation_level: ValidationLevel = ValidationLevel.RIGOROUS
    performance_thresholds: Dict[str, float] = field(default_factory=lambda: {
        "min_accuracy": PerformanceThreshold.MINIMUM_ACCURACY.value,
        "target_accuracy": PerformanceThreshold.TARGET_ACCURACY.value,
        "min_precision": PerformanceThreshold.MINIMUM_PRECISION.value,
        "min_f1_score": PerformanceThreshold.MINIMUM_F1_SCORE.value
    })

    # D√©ploiement
    auto_deploy_if_better: bool = False
    staging_period_hours: int = 24
    backup_previous_model: bool = True


@dataclass
class TrainingSession:
    """Session d'entra√Ænement"""
    session_id: str
    config: TrainingConfig
    start_time: datetime
    end_time: Optional[datetime] = None
    status: TrainingStatus = TrainingStatus.IDLE

    # Donn√©es
    data_period_start: Optional[datetime] = None
    data_period_end: Optional[datetime] = None
    samples_count: int = 0
    features_count: int = 0

    # R√©sultats
    model_performance: Optional[Dict[str, float]] = None
    validation_results: Optional[Dict[str, Any]] = None
    model_path: Optional[str] = None

    # M√©triques
    training_duration_seconds: float = 0.0
    memory_usage_mb: float = 0.0
    cpu_usage_percent: float = 0.0

    # Messages
    error_message: Optional[str] = None
    warnings: List[str] = field(default_factory=list)
    notes: List[str] = field(default_factory=list)


@dataclass
class ModelVersion:
    """Version de mod√®le"""
    version_id: str
    model_type: ModelType
    stage: ModelStage
    creation_date: datetime

    # Performance
    accuracy: float
    precision: float
    recall: float
    f1_score: float

    # M√©tadonn√©es
    training_samples: int
    features_used: List[str]
    training_config: TrainingConfig

    # Paths
    model_path: str
    metadata_path: str

    # Status
    is_active: bool = False
    deployment_date: Optional[datetime] = None
    retirement_date: Optional[datetime] = None

# === ALIAS POUR COMPATIBILIT√â __init__.py ===


# Le __init__.py importe SimpleMLModel, on cr√©e un alias
SimpleMLModel = SimpleLinearModel

# === MAIN MODEL TRAINER CLASS ===


class ModelTrainer:
    """
    ORCHESTRATEUR CENTRAL ML POUR BATTLE NAVALE

    Pipeline complet d'entra√Ænement automatis√© :
    - Collecte et pr√©paration donn√©es depuis snapshots
    - Entra√Ænement mod√®les avec validation rigoureuse
    - Gestion versions et d√©ploiement automatique
    - Monitoring performance et re-training automatique
    - Int√©gration native avec syst√®me Battle Navale
    """

    def __init__(self, config: Optional[TrainingConfig] = None):
        """
        Initialisation du trainer

        Args:
            config: Configuration d'entra√Ænement (sinon defaults)
        """
        self.config = config or TrainingConfig()
        self.trading_config = get_trading_config()
        self.auto_config = get_automation_config()

        # √âtat du trainer
        self.current_session: Optional[TrainingSession] = None
        self.training_history: List[TrainingSession] = []
        self.model_versions: Dict[str, ModelVersion] = {}
        self.active_model: Optional[ModelVersion] = None

        # Composants ML
        self.data_processor = create_battle_navale_processor()
        self.current_model: Optional[SimpleLinearModel] = None
        self.model_validator: Optional[ModelValidator] = None

        # Threads et scheduling
        self.training_thread: Optional[threading.Thread] = None
        self.monitoring_thread: Optional[threading.Thread] = None
        self.auto_training_enabled = False

        # Paths
        self.models_dir = Path("data/models")
        self.training_dir = Path("data/training")
        self.snapshots_dir = Path("data/snapshots")

        # Cr√©ation dossiers
        for directory in [self.models_dir, self.training_dir]:
            directory.mkdir(parents=True, exist_ok=True)
            for subdir in ["trained", "staging", "backup", "experimental"]:
                (directory / subdir).mkdir(exist_ok=True)

        # Chargement √©tat pr√©c√©dent
        self._load_model_versions()
        self._load_training_history()

        logger.info("ModelTrainer initialis√©")

    def train_model_from_snapshots(self,
                                   start_date: Optional[datetime] = None,
                                   end_date: Optional[datetime] = None,
                                   training_mode: TrainingMode = TrainingMode.INITIAL) -> TrainingSession:
        """
        Entra√Ænement mod√®le depuis snapshots Battle Navale

        Args:
            start_date: Date d√©but donn√©es (None = auto)
            end_date: Date fin donn√©es (None = maintenant)
            training_mode: Mode d'entra√Ænement

        Returns:
            Session d'entra√Ænement avec r√©sultats
        """
        # Cr√©ation session
        session_id = f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        session = TrainingSession(
            session_id=session_id,
            config=self.config,
            start_time=datetime.now(timezone.utc)
        )

        self.current_session = session
        session.status = TrainingStatus.PREPARING_DATA

        logger.info(f"=== D√âBUT ENTRA√éNEMENT MOD√àLE {session_id} ===")

        try:
            # 1. Collecte et pr√©paration donn√©es
            logger.info("Collecte donn√©es depuis snapshots...")
            raw_snapshots = self._collect_snapshots_data(start_date, end_date)

            if len(raw_snapshots) < self.config.min_samples_required:
                raise ValueError(
                    f"Donn√©es insuffisantes: {
                        len(raw_snapshots)} < {
                        self.config.min_samples_required}")

            session.samples_count = len(raw_snapshots)
            session.data_period_start = start_date or datetime.now(
                timezone.utc) - timedelta(days=30)
            session.data_period_end = end_date or datetime.now(timezone.utc)

            # 2. Processing ML dataset
            logger.info("Pr√©paration dataset ML...")
            ml_dataset = self.data_processor.create_ml_dataset(
                raw_snapshots, target_column="profitable")

            if not ml_dataset:
                raise ValueError("√âchec cr√©ation dataset ML")

            session.features_count = len(ml_dataset.feature_names)
            session.status = TrainingStatus.TRAINING

            # 3. Cr√©ation et entra√Ænement mod√®le
            logger.info("Entra√Ænement mod√®le...")
            self.current_model = self._create_model_for_training()

            # Entra√Ænement selon mode
            if training_mode == TrainingMode.INCREMENTAL and self.active_model:
                training_result = self._incremental_training(ml_dataset)
            else:
                training_result = self._full_training(ml_dataset)

            if not training_result.success:
                raise ValueError(f"√âchec entra√Ænement: {training_result.error_message}")

            session.model_performance = {
                "accuracy": training_result.model_performance.accuracy,
                "precision": training_result.model_performance.precision,
                "recall": training_result.model_performance.recall,
                "f1_score": training_result.model_performance.f1_score
            }

            # 4. Validation rigoureuse
            session.status = TrainingStatus.VALIDATING
            logger.info("Validation mod√®le...")

            validation_results = self._validate_trained_model(ml_dataset)
            session.validation_results = validation_results

            # 5. V√©rification seuils performance
            if not self._meets_performance_thresholds(session.model_performance):
                session.warnings.append("Performance sous les seuils requis")
                logger.warning("Mod√®le ne respecte pas les seuils de performance")

            # 6. Sauvegarde mod√®le
            model_version = self._save_model_version(session, training_result.model_path)
            session.model_path = model_version.model_path

            # 7. D√©ploiement automatique si configur√©
            if (self.config.auto_deploy_if_better and
                    self._is_better_than_current(session.model_performance)):

                session.status = TrainingStatus.DEPLOYING
                logger.info("D√©ploiement automatique du mod√®le...")

                self._deploy_model_to_staging(model_version)
                session.notes.append("Mod√®le d√©ploy√© automatiquement en staging")

            # 8. Finalisation
            session.status = TrainingStatus.COMPLETED
            session.end_time = datetime.now(timezone.utc)
            session.training_duration_seconds = (
                session.end_time - session.start_time).total_seconds()

            self.training_history.append(session)
            self._save_training_session(session)

            logger.info(f"‚úÖ Entra√Ænement termin√© avec succ√®s")
            logger.info(f"Performance: {session.model_performance}")
            logger.info(f"Dur√©e: {session.training_duration_seconds:.1f}s")

            return session

        except Exception as e:
            error_msg = f"Erreur entra√Ænement: {str(e)}"
            logger.error(error_msg)

            session.status = TrainingStatus.FAILED
            session.error_message = error_msg
            session.end_time = datetime.now(timezone.utc)

            return session

        finally:
            self.current_session = None

    def setup_continuous_learning(self,
                                  check_interval_hours: int = 24,
                                  retrain_threshold: float = 0.05) -> bool:
        """
        Configuration apprentissage continu

        Args:
            check_interval_hours: Intervalle v√©rification en heures
            retrain_threshold: Seuil d√©gradation pour re-training

        Returns:
            True si configuration r√©ussie, False sinon
        """
        try:
            logger.info("Configuration apprentissage continu...")

            # Configuration seuils
            self.config.auto_retrain_threshold = retrain_threshold

            # Planification v√©rifications automatiques
            schedule.every(check_interval_hours).hours.do(self._check_model_performance)

            # Planification re-training hebdomadaire
            schedule.every().sunday.at("02:00").do(self._scheduled_retraining)

            # D√©marrage thread monitoring
            if not self.monitoring_thread or not self.monitoring_thread.is_alive():
                self.auto_training_enabled = True
                self.monitoring_thread = threading.Thread(
                    target=self._continuous_learning_loop,
                    daemon=True
                )
                self.monitoring_thread.start()

            logger.info(f"‚úÖ Apprentissage continu configur√©:")
            logger.info(f"  - V√©rification toutes les {check_interval_hours}h")
            logger.info(f"  - Seuil re-training: {retrain_threshold*100:.1f}%")
            logger.info(f"  - Re-training auto: Dimanche 02:00")

            return True

        except Exception as e:
            logger.error(f"Erreur configuration apprentissage continu: {e}")
            return False

    def deploy_model_to_production(self, version_id: str) -> bool:
        """
        D√©ploiement mod√®le en production

        Args:
            version_id: ID version √† d√©ployer

        Returns:
            True si d√©ploiement r√©ussi, False sinon
        """
        try:
            logger.info(f"D√©ploiement mod√®le en production: {version_id}")

            # Recherche version
            if version_id not in self.model_versions:
                logger.error(f"Version {version_id} non trouv√©e")
                return False

            model_version = self.model_versions[version_id]

            # V√©rifications pr√©-d√©ploiement
            if not self._validate_production_readiness(model_version):
                logger.error("Mod√®le non pr√™t pour production")
                return False

            # Backup mod√®le actuel
            if self.active_model and self.config.backup_previous_model:
                self._backup_current_model()

            # D√©ploiement
            production_path = self.models_dir / "production" / f"model_{version_id}.joblib"
            shutil.copy2(model_version.model_path, production_path)

            # Mise √† jour statuts
            if self.active_model:
                self.active_model.is_active = False

            model_version.stage = ModelStage.PRODUCTION
            model_version.is_active = True
            model_version.deployment_date = datetime.now(timezone.utc)

            self.active_model = model_version

            # Sauvegarde m√©tadonn√©es
            self._save_model_versions()

            logger.info(f"‚úÖ Mod√®le {version_id} d√©ploy√© en production")
            logger.info(
                f"Performance: Accuracy={
                    model_version.accuracy:.3f}, F1={
                    model_version.f1_score:.3f}")

            return True

        except Exception as e:
            logger.error(f"Erreur d√©ploiement production: {e}")
            return False

    def get_model_for_trading(self) -> Optional[SimpleLinearModel]:
        """
        R√©cup√©ration mod√®le actif pour trading

        Returns:
            Mod√®le ML pr√™t pour trading ou None
        """
        try:
            if not self.active_model:
                logger.warning("Aucun mod√®le actif disponible")
                return None

            # Chargement mod√®le depuis fichier
            model = SimpleLinearPredictor(self.config.model_type)

            if model.load_model(self.active_model.model_path):
                logger.info(f"Mod√®le actif charg√©: {self.active_model.version_id}")
                return model
            else:
                logger.error("√âchec chargement mod√®le actif")
                return None

        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration mod√®le trading: {e}")
            return None

    def get_training_status(self) -> Dict[str, Any]:
        """Statut complet du syst√®me d'entra√Ænement"""

        try:
            # Session actuelle
            current_session_info = None
            if self.current_session:
                current_session_info = {
                    "session_id": self.current_session.session_id,
                    "status": self.current_session.status.value,
                    "start_time": self.current_session.start_time.isoformat(),
                    "samples_count": self.current_session.samples_count,
                    "features_count": self.current_session.features_count
                }

            # Mod√®le actif
            active_model_info = None
            if self.active_model:
                active_model_info = {
                    "version_id": self.active_model.version_id,
                    "accuracy": self.active_model.accuracy,
                    "f1_score": self.active_model.f1_score,
                    "deployment_date": self.active_model.deployment_date.isoformat() if self.active_model.deployment_date else None,
                    "training_samples": self.active_model.training_samples
                }

            # Historique r√©cent
            recent_sessions = [
                {
                    "session_id": session.session_id,
                    "status": session.status.value,
                    "start_time": session.start_time.isoformat(),
                    "performance": session.model_performance
                }
                for session in self.training_history[-5:]  # 5 derni√®res sessions
            ]

            # Statistiques globales
            total_models = len(self.model_versions)
            production_models = len([v for v in self.model_versions.values()
                                    if v.stage == ModelStage.PRODUCTION])

            return {
                "system_status": {
                    "trainer_active": self.current_session is not None,
                    "continuous_learning": self.auto_training_enabled,
                    "models_total": total_models,
                    "models_in_production": production_models
                },
                "current_session": current_session_info,
                "active_model": active_model_info,
                "recent_sessions": recent_sessions,
                "configuration": {
                    "min_samples_required": self.config.min_samples_required,
                    "auto_deploy": self.config.auto_deploy_if_better,
                    "validation_level": self.config.validation_level.value,
                    "performance_thresholds": self.config.performance_thresholds
                }
            }

        except Exception as e:
            logger.error(f"Erreur statut training: {e}")
            return {"error": str(e)}

    def retrain_if_needed(self) -> Optional[TrainingSession]:
        """
        Re-training automatique si performance d√©grad√©e

        Returns:
            Session d'entra√Ænement si lanc√©e, None sinon
        """
        try:
            if not self.active_model:
                logger.info("Aucun mod√®le actif - pas de re-training n√©cessaire")
                return None

            # √âvaluation performance actuelle
            current_performance = self._evaluate_current_model_performance()

            if not current_performance:
                logger.warning("Impossible d'√©valuer performance actuelle")
                return None

            # Comparaison avec performance de r√©f√©rence
            baseline_f1 = self.active_model.f1_score
            current_f1 = current_performance.get("f1_score", 0)

            degradation = baseline_f1 - current_f1
            degradation_pct = degradation / baseline_f1 if baseline_f1 > 0 else 0

            logger.info(
                f"Performance check: Baseline F1={
                    baseline_f1:.3f}, Current F1={
                    current_f1:.3f}")
            logger.info(f"D√©gradation: {degradation_pct*100:.1f}%")

            # D√©cision re-training
            if degradation_pct > self.config.auto_retrain_threshold:
                logger.info(
                    f"üîÑ D√©gradation d√©tect√©e ({
                        degradation_pct *
                        100:.1f}%) - Lancement re-training")

                return self.train_model_from_snapshots(
                    training_mode=TrainingMode.RETRAIN
                )
            else:
                logger.info("Performance stable - Pas de re-training n√©cessaire")
                return None

        except Exception as e:
            logger.error(f"Erreur √©valuation re-training: {e}")
            return None

    # === M√âTHODES PRIV√âES ===

    def _collect_snapshots_data(self,
                                start_date: Optional[datetime],
                                end_date: Optional[datetime]) -> List[Dict]:
        """Collection donn√©es depuis snapshots"""

        snapshots = []

        try:
            # D√©finition p√©riode
            if not start_date:
                start_date = datetime.now(timezone.utc) - timedelta(days=30)
            if not end_date:
                end_date = datetime.now(timezone.utc)

            # Recherche fichiers snapshots dans la p√©riode
            current_date = start_date.date()
            end_date_only = end_date.date()

            while current_date <= end_date_only:
                daily_snapshots_file = self.snapshots_dir / "daily" / \
                    f"trades_{current_date.isoformat()}.jsonl"

                if daily_snapshots_file.exists():
                    # Lecture snapshots du jour
                    with open(daily_snapshots_file, 'r') as f:
                        for line in f:
                            try:
                                snapshot = json.loads(line.strip())
                                snapshots.append(snapshot)
                            except json.JSONDecodeError:
                                continue

                current_date += timedelta(days=1)

            # Si pas assez de donn√©es, g√©n√©ration simul√©e
            if len(snapshots) < self.config.min_samples_required:
                logger.warning(f"Donn√©es insuffisantes ({len(snapshots)}), g√©n√©ration simul√©e...")
                snapshots.extend(self._generate_simulated_snapshots(
                    self.config.min_samples_required - len(snapshots)
                ))

            logger.info(f"Snapshots collect√©s: {len(snapshots)}")
            return snapshots

        except Exception as e:
            logger.error(f"Erreur collection snapshots: {e}")
            return []

    def _generate_simulated_snapshots(self, count: int) -> List[Dict]:
        """G√©n√©ration snapshots simul√©s pour d√©veloppement"""

        snapshots = []

        for i in range(count):
            # Simulation snapshot Battle Navale
            snapshot = {
                "trade_id": f"sim_trade_{i}",
                "timestamp": (datetime.now(timezone.utc) - timedelta(hours=i)).isoformat(),
                "battle_score": np.random.uniform(0.3, 1.0),
                "confluence_score": np.random.uniform(0.2, 0.9),
                "signal_strength": np.random.choice(["WEAK", "MEDIUM", "STRONG"]),
                "trade_pnl": np.random.normal(0, ES_TICK_VALUE * 2),

                # Features Battle Navale (vos 8 features)
                "vwap_trend_signal": np.random.uniform(0, 1),
                "sierra_pattern_strength": np.random.uniform(0, 1),
                "dow_trend_regime": np.random.uniform(0, 1),
                "gamma_levels_proximity": np.random.uniform(0, 1),
                "level_proximity": np.random.uniform(0, 1),
                "es_nq_correlation": np.random.uniform(0, 1),
                "volume_confirmation": np.random.uniform(0, 1),
                "options_flow_bias": np.random.uniform(0, 1),

                # M√©tadonn√©es
                "signal_type": np.random.choice(["LONG", "SHORT"]),
                "session": np.random.choice(["LONDON", "NY", "ASIA"]),
                "market_condition": np.random.choice(["TREND", "RANGE", "TRANSITION"])
            }

            snapshots.append(snapshot)

        return snapshots

    def _create_model_for_training(self) -> SimpleLinearModel:
        """Cr√©ation mod√®le pour entra√Ænement"""

        model = SimpleLinearPredictor(self.config.model_type)

        # Configuration hyperparam√®tres si fournis
        if self.config.hyperparameters:
            # TODO: Application hyperparam√®tres au mod√®le
            pass

        return model

    def _full_training(self, dataset: ProcessedDataset):
        """Entra√Ænement complet du mod√®le"""

        # Conversion dataset pour entra√Ænement
        training_data = pd.concat([dataset.X_train, dataset.X_test], ignore_index=True)

        # Ajout colonnes target et autres m√©tadonn√©es n√©cessaires
        all_targets = pd.concat([dataset.y_train, dataset.y_test], ignore_index=True)
        training_data["profitable"] = all_targets

        # Entra√Ænement
        return self.current_model.train_on_snapshots(training_data)

    def _incremental_training(self, dataset: ProcessedDataset):
        """Entra√Ænement incr√©mental"""

        if not self.active_model:
            logger.warning("Pas de mod√®le actif pour training incr√©mental - training complet")
            return self._full_training(dataset)

        # Chargement mod√®le actuel
        current_model = SimpleLinearPredictor(self.config.model_type)
        if not current_model.load_model(self.active_model.model_path):
            logger.error("√âchec chargement mod√®le actuel - training complet")
            return self._full_training(dataset)

        # Update avec nouvelles donn√©es
        new_data = pd.concat([dataset.X_train, dataset.X_test], ignore_index=True)
        all_targets = pd.concat([dataset.y_train, dataset.y_test], ignore_index=True)
        new_data["profitable"] = all_targets

        success = current_model.update_model_weights(new_data)

        if success:
            self.current_model = current_model
            # Simulation TrainingResult pour compatibilit√©
            from ml.simple_model import TrainingResult, ModelPerformance

            # Performance simul√©e (en production, √©valuer vraiment)
            perf = ModelPerformance(
                accuracy=0.75, precision=0.73, recall=0.77, f1_score=0.75,
                mse=0.2, mae=0.15, r2_score=0.6, feature_importance={}
            )

            return TrainingResult(
                success=True,
                model_performance=perf,
                training_samples=len(new_data),
                features_count=len(dataset.feature_names),
                training_duration=10.0,
                model_path=None
            )
        else:
            # Fallback vers training complet
            return self._full_training(dataset)

    def _validate_trained_model(self, dataset: ProcessedDataset) -> Dict[str, Any]:
        """Validation rigoureuse du mod√®le entra√Æn√©"""

        try:
            # Cr√©ation validateur
            validator = create_rigorous_validator(self.current_model)

            # Validation compl√®te
            validation_report = validator.validate_model_comprehensive(dataset)

            return {
                "validation_level": validation_report.validation_level.value,
                "model_health": validation_report.model_health.value,
                "overall_score": validation_report.overall_score,
                "production_readiness": validation_report.production_readiness,
                "confidence_rating": validation_report.confidence_rating,
                "cross_validation": asdict(validation_report.cross_validation) if validation_report.cross_validation else None,
                "out_of_sample": asdict(validation_report.out_of_sample) if validation_report.out_of_sample else None,
                "strengths": validation_report.strengths,
                "weaknesses": validation_report.weaknesses,
                "recommendations": validation_report.recommendations
            }

        except Exception as e:
            logger.error(f"Erreur validation mod√®le: {e}")
            return {"error": str(e)}

    def _meets_performance_thresholds(self, performance: Dict[str, float]) -> bool:
        """V√©rification seuils de performance"""

        thresholds = self.config.performance_thresholds

        checks = [
            performance.get("accuracy", 0) >= thresholds["min_accuracy"],
            performance.get("precision", 0) >= thresholds["min_precision"],
            performance.get("f1_score", 0) >= thresholds["min_f1_score"]
        ]

        return all(checks)

    def _save_model_version(self, session: TrainingSession,
                            model_path: Optional[str]) -> ModelVersion:
        """Sauvegarde version de mod√®le"""

        version_id = f"v_{session.session_id}"
        timestamp = session.start_time

        # Path de sauvegarde
        if not model_path:
            model_filename = f"model_{version_id}.joblib"
            model_path = str(self.models_dir / "trained" / model_filename)

            # Sauvegarde mod√®le
            self.current_model.model_path = model_path
            joblib.dump(self.current_model, model_path)

        # M√©tadonn√©es
        metadata_path = str(self.models_dir / "trained" / f"metadata_{version_id}.json")

        # Cr√©ation version
        model_version = ModelVersion(
            version_id=version_id,
            model_type=self.config.model_type,
            stage=ModelStage.DEVELOPMENT,
            creation_date=timestamp,
            accuracy=session.model_performance["accuracy"],
            precision=session.model_performance["precision"],
            recall=session.model_performance["recall"],
            f1_score=session.model_performance["f1_score"],
            training_samples=session.samples_count,
            features_used=list(range(session.features_count)),  # Simplification
            training_config=self.config,
            model_path=model_path,
            metadata_path=metadata_path
        )

        # Sauvegarde m√©tadonn√©es
        with open(metadata_path, 'w') as f:
            json.dump(asdict(model_version), f, indent=2, default=str)

        # Ajout au registre
        self.model_versions[version_id] = model_version
        self._save_model_versions()

        logger.info(f"Version mod√®le sauvegard√©e: {version_id}")
        return model_version

    def _is_better_than_current(self, new_performance: Dict[str, float]) -> bool:
        """Comparaison avec mod√®le actuel"""

        if not self.active_model:
            return True  # Premier mod√®le

        # Comparaison F1-score principalement
        current_f1 = self.active_model.f1_score
        new_f1 = new_performance.get("f1_score", 0)

        improvement_threshold = 0.02  # 2% d'am√©lioration minimum

        return new_f1 > (current_f1 + improvement_threshold)

    def _deploy_model_to_staging(self, model_version: ModelVersion):
        """D√©ploiement en staging"""

        # Copie vers staging
        staging_path = self.models_dir / "staging" / f"model_{model_version.version_id}.joblib"
        shutil.copy2(model_version.model_path, staging_path)

        # Mise √† jour statut
        model_version.stage = ModelStage.STAGING

        logger.info(f"Mod√®le d√©ploy√© en staging: {model_version.version_id}")

    def _validate_production_readiness(self, model_version: ModelVersion) -> bool:
        """Validation pr√™t pour production"""

        checks = [
            model_version.accuracy >= PerformanceThreshold.MINIMUM_ACCURACY.value,
            model_version.f1_score >= PerformanceThreshold.MINIMUM_F1_SCORE.value,
            model_version.training_samples >= self.config.min_samples_required,
            model_version.stage in [ModelStage.STAGING, ModelStage.TESTING]
        ]

        return all(checks)

    def _backup_current_model(self):
        """Backup du mod√®le actuel"""

        if not self.active_model:
            return

        backup_path = self.models_dir / "backup" / \
            f"model_{self.active_model.version_id}_backup.joblib"
        shutil.copy2(self.active_model.model_path, backup_path)

        logger.info(f"Mod√®le actuel sauvegard√©: {backup_path}")

    def _continuous_learning_loop(self):
        """Boucle apprentissage continu"""

        logger.info("D√©marrage boucle apprentissage continu")

        while self.auto_training_enabled:
            try:
                # Ex√©cution t√¢ches planifi√©es
                schedule.run_pending()

                # Pause
                time.sleep(3600)  # 1 heure

            except Exception as e:
                logger.error(f"Erreur boucle apprentissage continu: {e}")
                time.sleep(600)  # 10 minutes avant retry

    def _check_model_performance(self):
        """V√©rification performance mod√®le (planifi√©e)"""
        logger.info("V√©rification performance mod√®le planifi√©e")

        result = self.retrain_if_needed()
        if result:
            logger.info(f"Re-training automatique lanc√©: {result.session_id}")

    def _scheduled_retraining(self):
        """Re-training planifi√© hebdomadaire"""
        logger.info("Re-training hebdomadaire planifi√©")

        session = self.train_model_from_snapshots(
            training_mode=TrainingMode.RETRAIN
        )

        logger.info(
            f"Re-training hebdomadaire: {session.session_id} - Status: {session.status.value}")

    def _evaluate_current_model_performance(self) -> Optional[Dict[str, float]]:
        """√âvaluation performance mod√®le actuel"""

        try:
            if not self.active_model:
                return None

            # Chargement donn√©es r√©centes pour √©valuation
            recent_snapshots = self._collect_snapshots_data(
                start_date=datetime.now(timezone.utc) - timedelta(days=7),
                end_date=None
            )

            if len(recent_snapshots) < 20:  # Minimum pour √©valuation
                return None

            # Pr√©paration dataset
            recent_dataset = self.data_processor.create_ml_dataset(recent_snapshots)
            if not recent_dataset:
                return None

            # Chargement mod√®le actuel
            current_model = SimpleLinearPredictor(self.config.model_type)
            if not current_model.load_model(self.active_model.model_path):
                return None

            # √âvaluation sur donn√©es r√©centes
            X_test = recent_dataset.X_test
            y_test = recent_dataset.y_test

            predictions = []
            for idx, (_, features) in enumerate(X_test.iterrows()):
                feature_dict = features.to_dict()
                quality_score = current_model.predict_signal_quality(feature_dict)
                prediction = 1 if quality_score > 0.5 else 0
                predictions.append(prediction)

            # Calcul m√©triques
            accuracy = accuracy_score(y_test, predictions)
            precision = precision_score(y_test, predictions, average='weighted', zero_division=0)
            recall = recall_score(y_test, predictions, average='weighted', zero_division=0)
            f1 = f1_score(y_test, predictions, average='weighted', zero_division=0)

            return {
                "accuracy": accuracy,
                "precision": precision,
                "recall": recall,
                "f1_score": f1
            }

        except Exception as e:
            logger.error(f"Erreur √©valuation performance actuelle: {e}")
            return None

    def _load_model_versions(self):
        """Chargement versions de mod√®les"""

        try:
            versions_file = self.models_dir / "model_versions.json"

            if versions_file.exists():
                with open(versions_file, 'r') as f:
                    data = json.load(f)

                for version_id, version_data in data.items():
                    # Reconstruction ModelVersion
                    version = ModelVersion(
                        version_id=version_data["version_id"],
                        model_type=ModelType(version_data["model_type"]),
                        stage=ModelStage(version_data["stage"]),
                        creation_date=datetime.fromisoformat(version_data["creation_date"]),
                        accuracy=version_data["accuracy"],
                        precision=version_data["precision"],
                        recall=version_data["recall"],
                        f1_score=version_data["f1_score"],
                        training_samples=version_data["training_samples"],
                        features_used=version_data["features_used"],
                        training_config=self.config,  # Simplification
                        model_path=version_data["model_path"],
                        metadata_path=version_data["metadata_path"],
                        is_active=version_data.get("is_active", False),
                        deployment_date=datetime.fromisoformat(
                            version_data["deployment_date"]) if version_data.get("deployment_date") else None
                    )

                    self.model_versions[version_id] = version

                    # Identification mod√®le actif
                    if version.is_active:
                        self.active_model = version

                logger.info(f"Versions mod√®les charg√©es: {len(self.model_versions)}")

        except Exception as e:
            logger.error(f"Erreur chargement versions: {e}")

    def _save_model_versions(self):
        """Sauvegarde versions de mod√®les"""

        try:
            versions_file = self.models_dir / "model_versions.json"

            data = {}
            for version_id, version in self.model_versions.items():
                data[version_id] = {
                    "version_id": version.version_id,
                    "model_type": version.model_type.value,
                    "stage": version.stage.value,
                    "creation_date": version.creation_date.isoformat(),
                    "accuracy": version.accuracy,
                    "precision": version.precision,
                    "recall": version.recall,
                    "f1_score": version.f1_score,
                    "training_samples": version.training_samples,
                    "features_used": version.features_used,
                    "model_path": version.model_path,
                    "metadata_path": version.metadata_path,
                    "is_active": version.is_active,
                    "deployment_date": version.deployment_date.isoformat() if version.deployment_date else None
                }

            with open(versions_file, 'w') as f:
                json.dump(data, f, indent=2)

        except Exception as e:
            logger.error(f"Erreur sauvegarde versions: {e}")

    def _load_training_history(self):
        """Chargement historique training"""

        try:
            history_file = self.training_dir / "training_history.json"

            if history_file.exists():
                with open(history_file, 'r') as f:
                    data = json.load(f)

                for session_data in data:
                    # Reconstruction TrainingSession (simplifi√©e)
                    session = TrainingSession(
                        session_id=session_data["session_id"],
                        config=self.config,  # Simplification
                        start_time=datetime.fromisoformat(session_data["start_time"]),
                        end_time=datetime.fromisoformat(
                            session_data["end_time"]) if session_data.get("end_time") else None,
                        status=TrainingStatus(session_data["status"]),
                        samples_count=session_data.get("samples_count", 0),
                        model_performance=session_data.get("model_performance")
                    )

                    self.training_history.append(session)

                logger.info(f"Historique training charg√©: {len(self.training_history)} sessions")

        except Exception as e:
            logger.error(f"Erreur chargement historique: {e}")

    def _save_training_session(self, session: TrainingSession):
        """Sauvegarde session training"""

        try:
            # Ajout √† l'historique si pas d√©j√† pr√©sent
            if session not in self.training_history:
                self.training_history.append(session)

            # Sauvegarde historique complet
            history_file = self.training_dir / "training_history.json"

            data = []
            for s in self.training_history:
                data.append({
                    "session_id": s.session_id,
                    "start_time": s.start_time.isoformat(),
                    "end_time": s.end_time.isoformat() if s.end_time else None,
                    "status": s.status.value,
                    "samples_count": s.samples_count,
                    "features_count": s.features_count,
                    "model_performance": s.model_performance,
                    "training_duration_seconds": s.training_duration_seconds,
                    "error_message": s.error_message
                })

            with open(history_file, 'w') as f:
                json.dump(data, f, indent=2)

        except Exception as e:
            logger.error(f"Erreur sauvegarde session: {e}")

# === FACTORY FUNCTIONS ===


def create_model_trainer(config: Optional[TrainingConfig] = None) -> ModelTrainer:
    """Factory pour trainer de mod√®les"""
    return ModelTrainer(config)


def create_battle_navale_trainer() -> ModelTrainer:
    """Factory sp√©cialis√©e pour Battle Navale"""
    config = TrainingConfig(
        model_type=ModelType.SIGNAL_CLASSIFIER,
        min_samples_required=100,
        validation_level=ValidationLevel.RIGOROUS,
        auto_deploy_if_better=False  # S√©curit√© pour Battle Navale
    )
    return ModelTrainer(config)


def train_model_from_recent_data(days_back: int = 30) -> Optional[TrainingSession]:
    """Training rapide depuis donn√©es r√©centes"""
    trainer = create_battle_navale_trainer()

    start_date = datetime.now(timezone.utc) - timedelta(days=days_back)

    return trainer.train_model_from_snapshots(
        start_date=start_date,
        training_mode=TrainingMode.INITIAL
    )

# === TEST FUNCTION ===


def test_model_trainer():
    """Test complet du trainer de mod√®les"""
    logger.info("=== TEST MODEL TRAINER ===")

    # Configuration test
    config = TrainingConfig(
        min_samples_required=50,  # R√©duit pour test
        max_training_time_minutes=5,
        auto_deploy_if_better=False
    )

    # Cr√©ation trainer
    trainer = create_model_trainer(config)

    logger.info("Test 1: Training depuis snapshots")
    session = trainer.train_model_from_snapshots(
        start_date=datetime.now(timezone.utc) - timedelta(days=7),
        training_mode=TrainingMode.INITIAL
    )

    logger.info("Training session: {session.session_id}")
    logger.info("Status: {session.status.value}")
    logger.info("Samples: {session.samples_count}")

    if session.model_performance:
        logger.info("Performance: {session.model_performance}")

    logger.info("Training: {'‚úÖ' if session.status == TrainingStatus.COMPLETED else '‚ùå'}")

    logger.info("Test 2: R√©cup√©ration mod√®le pour trading")
    model = trainer.get_model_for_trading()
    logger.info("Mod√®le r√©cup√©r√©: {'‚úÖ' if model is not None else '‚ùå'}")

    logger.info("Test 3: Statut syst√®me")
    status = trainer.get_training_status()
    logger.info("Statut syst√®me: {'‚úÖ' if 'system_status' in status else '‚ùå'}")
    logger.info("Models total: {status.get('system_status', {}).get('models_total', 0)}")

    logger.info("Test 4: Configuration apprentissage continu")
    continuous_setup = trainer.setup_continuous_learning(check_interval_hours=1)
    logger.info("Apprentissage continu: {'‚úÖ' if continuous_setup else '‚ùå'}")

    logger.info("=== TEST TERMIN√â ===")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    test_model_trainer()
