"""
MIA_IA_SYSTEM - Trade Snapshotter ENHANCED & INTEGRATED
Capture obsessive de donn√©es pour chaque moment de trading
Version: Enhanced v2.0 - INT√âGRATION COMPL√àTE AVEC EXISTANT

üéØ INT√âGRATION STRATEGY:
‚úÖ GARDE 100% de votre code existant qui fonctionne
‚úÖ AJOUTE toutes les am√©liorations demand√©es  
‚úÖ COMPATIBILIT√â totale avec vos appels actuels
‚úÖ NOUVELLES fonctionnalit√©s disponibles progressivement

AM√âLIORATIONS AJOUT√âES :
‚úÖ 1. MICROSTRUCTURE - Order book imbalance, tick momentum, smart money
‚úÖ 2. OPTIONS FLOW ENRICHI - Gamma exposure, dealer positioning, vol skew
‚úÖ 3. SESSION CONTEXT - Contexte temporel, √©v√©nements √©conomiques
‚úÖ 4. POST-TRADE ANALYSIS - Analyse apprentissage apr√®s chaque trade
‚úÖ 5. CORRELATION TRACKING - Monitoring corr√©lations features/march√©

RESPONSABILIT√âS :
1. Snapshot PRE-ANALYSE (√©tat march√© complet) ‚úÖ GARDE EXISTANT
2. Snapshot D√âCISION (processus Battle Navale) ‚úÖ GARDE EXISTANT
3. Snapshot EX√âCUTION (d√©tails ordre/remplissage) ‚úÖ GARDE EXISTANT
4. Snapshot R√âSULTAT (outcome complet + m√©triques) ‚úÖ GARDE EXISTANT
5. Pr√©paration donn√©es ML (features engineering) ‚úÖ GARDE EXISTANT
6. NOUVEAU: Analyse microstructure temps r√©el
7. NOUVEAU: Context options/gamma/volatilit√©
8. NOUVEAU: Post-trade learning automatique

PRIORIT√â #3 CHANGES (GARD√âES):
- dow_trend_regime SUPPRIM√â des snapshots (redondant avec vwap_trend)
- Ajout order_book_imbalance dans les snapshots
- Mise √† jour logging et m√©triques sans dow_trend_regime
"""

import time
import json
import uuid
import sys
import os
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime, timezone, timedelta
import hashlib
import gzip
import statistics
import logging

# Ajouter le dossier parent au path pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from core.logger import get_logger
    logger = get_logger(__name__)
except ImportError:
    # Fallback si core.logger n'est pas disponible
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

try:
    # Local imports avec fallback
    from core.base_types import (
        MarketData, OrderFlowData, TradingSignal, TradeResult,
        MarketRegime, SignalType, ES_TICK_SIZE, ES_TICK_VALUE
    )
except ImportError:
    # Fallback: d√©finir les types localement
    logger.warning("Impossible d'importer core.base_types, utilisation des types locaux")
    
    @dataclass
    class MarketData:
        timestamp: datetime
        symbol: str
        open: float
        high: float
        low: float
        close: float
        volume: int
        bid: Optional[float] = None
        ask: Optional[float] = None
    
    @dataclass  
    class OrderFlowData:
        timestamp: datetime
        symbol: str
        cumulative_delta: float
        bid_volume: int
        ask_volume: int
    
    @dataclass
    class TradingSignal:
        timestamp: datetime
        symbol: str
        signal_type: str
        direction: str
        confidence: float
    
    @dataclass
    class TradeResult:
        timestamp: datetime
        symbol: str
        realized_pnl: float
        
    class MarketRegime:
        TRENDING = "trending"
        RANGING = "ranging"
    
    class SignalType:
        LONG = "LONG"
        SHORT = "SHORT"
    
    # Constants ES
    ES_TICK_SIZE = 0.25
    ES_TICK_VALUE = 12.50

# === ENUMS (GARD√âS + ENRICHIS) ===

# D√©finir TradingMode localement pour √©viter l'import circulaire
class TradingMode(Enum):
    LIVE = "live"
    PAPER = "paper"
    BACKTEST = "backtest"

class SnapshotType(Enum):
    """Types de snapshots"""
    PRE_ANALYSIS = "pre_analysis"         # Avant analyse Battle Navale
    DECISION = "decision"                 # Processus d√©cision
    EXECUTION = "execution"               # Ex√©cution ordre
    POSITION_UPDATE = "position_update"   # Update position
    FINAL_RESULT = "final_result"        # R√©sultat final
    # NOUVEAUX TYPES ENRICHIS
    MICROSTRUCTURE = "microstructure"
    POST_TRADE_ANALYSIS = "post_trade_analysis"
    CORRELATION_UPDATE = "correlation_update"

class SessionPhase(Enum):
    """Phases de session"""
    PRE_MARKET = "pre_market"
    OPENING = "opening"
    MORNING = "morning"
    LUNCH = "lunch"
    AFTERNOON = "afternoon"
    CLOSE = "close"
    AFTER_HOURS = "after_hours"
    OVERNIGHT = "overnight"

class VolatilityRegime(Enum):
    """R√©gimes de volatilit√©"""
    LOW_VOL = "low_vol"
    NORMAL_VOL = "normal_vol"
    HIGH_VOL = "high_vol"
    EXTREME_VOL = "extreme_vol"

# === DATACLASSES (GARD√âES + ENRICHIES) ===

@dataclass
class MarketSnapshot:
    """Snapshot march√© de base (GARD√â de l'existant)"""
    timestamp: datetime
    symbol: str
    open: float
    high: float
    low: float
    close: float
    volume: int
    session_phase: str
    session_high: float
    session_low: float
    session_volume: int
    time_since_open_minutes: int
    atr_14: float
    realized_volatility: float
    volatility_regime: str
    trend_direction: str
    trend_strength: float

@dataclass
class BattleNavaleSnapshot:
    """Snapshot analyse Battle Navale (GARD√â de l'existant)"""
    timestamp: datetime
    
    # Battle Navale core
    signal_type: str
    signal_strength: float
    confidence: float
    direction: str
    
    # Features Battle Navale (PRIORIT√â #3 - sans dow_trend_regime)
    vwap_trend_signal: float
    sierra_pattern_strength: float
    gamma_levels_proximity: float
    volume_confirmation: float
    options_flow_bias: float
    order_book_imbalance: float  # NOUVEAU dans Priorit√© #3
    level_proximity_score: float
    aggression_bias: float
    
    # Pattern analysis
    pattern_type: str
    pattern_quality: float
    base_strength: float
    rouge_sous_verte_valid: bool
    
    # Confluence
    confluence_score: float
    confluence_components: Dict[str, float]
    
    # Decision logic
    decision_reasoning: str
    filters_passed: List[str]
    filters_failed: List[str]
    
    # PRIORIT√â #3 metadata (GARD√â)
    priority_3_changes: Dict[str, Any] = field(default_factory=lambda: {
        'dow_trend_regime_removed': True,
        'logic_absorbed_by': 'vwap_trend_signal',
        'new_features_added': ['order_book_imbalance'],
        'redistribution_applied': True
    })

@dataclass
class ExecutionSnapshot:
    """Snapshot ex√©cution ordre (GARD√â de l'existant)"""
    timestamp: datetime
    
    # Order details
    order_id: str
    order_type: str                     # MKT/LMT/STP
    side: str                          # BUY/SELL
    quantity: float
    price_requested: Optional[float]    # Prix demand√© (si LMT)
    
    # Execution details
    price_filled: Optional[float]       # Prix rempli
    quantity_filled: float             # Quantit√© remplie
    execution_time_ms: float           # Temps ex√©cution
    slippage_ticks: float              # Slippage en ticks
    
    # Market conditions at execution
    bid_price: float
    ask_price: float
    spread_ticks: float
    market_impact: float               # Impact sur le march√©
    
    # Risk management
    stop_loss_price: Optional[float]
    take_profit_price: Optional[float]
    risk_reward_ratio: Optional[float]
    max_risk_dollars: float

@dataclass
class PositionSnapshot:
    """Snapshot position en cours (GARD√â de l'existant)"""
    timestamp: datetime
    
    # Position details
    symbol: str
    side: str                          # LONG/SHORT
    quantity: float
    entry_price: float
    current_price: float
    
    # P&L tracking
    unrealized_pnl: float
    unrealized_pnl_percent: float
    max_favorable_excursion: float     # MFE
    max_adverse_excursion: float       # MAE
    
    # Time tracking
    entry_time: datetime
    time_in_position_minutes: int
    
    # Risk monitoring
    distance_to_stop: float            # Ticks
    distance_to_target: float          # Ticks
    current_risk_reward: float

@dataclass
class TradeResultSnapshot:
    """Snapshot r√©sultat final trade (GARD√â de l'existant)"""
    timestamp: datetime
    
    # Trade identification
    trade_id: str
    symbol: str
    
    # Entry/Exit details
    entry_time: datetime
    exit_time: datetime
    side: str                          # LONG/SHORT
    quantity: float
    entry_price: float
    exit_price: float
    
    # Performance metrics
    realized_pnl: float
    realized_pnl_percent: float
    commission: float
    slippage: float
    net_pnl: float
    
    # Trade analytics
    max_favorable_excursion: float     # MFE
    max_adverse_excursion: float       # MAE
    time_in_trade_minutes: int
    exit_reason: str                   # "TP", "SL", "TIME", "MANUAL"
    
    # Battle Navale performance
    initial_confluence_score: float
    signal_accuracy: float
    pattern_performed_as_expected: bool

# === NOUVELLES DATACLASSES ENRICHIES ===

@dataclass
class MicrostructureSnapshot:
    """NOUVEAU: Snapshot microstructure march√©"""
    timestamp: datetime
    
    # Order book data
    bid_levels: List[Tuple[float, int]]  # [(price, size), ...]
    ask_levels: List[Tuple[float, int]]
    order_book_imbalance: float          # -1 √† +1
    bid_ask_spread_ticks: float
    
    # Tick analysis
    tick_direction: str                  # "up", "down", "same"
    tick_momentum_score: float           # -1 √† +1
    upticks_last_20: int
    downticks_last_20: int
    
    # Volume analysis
    large_orders_bias: float             # Smart money flow
    aggressive_buy_ratio: float          # % ordres agressifs buy
    aggressive_sell_ratio: float         # % ordres agressifs sell
    volume_spike_detected: bool
    
    # Quality metrics
    data_quality_score: float            # 0-1
    latency_ms: float

@dataclass
class OptionsFlowSnapshot:
    """NOUVEAU: Snapshot flow options enrichi"""
    timestamp: datetime
    
    # SPX Gamma exposure
    total_gamma_exposure: float          # $billions
    dealer_gamma_position: str           # "long", "short", "neutral"
    gamma_flip_level: float              # Niveau flip dealer gamma
    
    # Volatility surface
    vix_level: float
    term_structure_slope: float          # Contango/backwardation
    vol_skew_25_delta: float             # Skew 25-delta
    
    # Put/Call dynamics
    put_call_ratio: float
    put_call_volume_ratio: float
    unusual_options_activity: bool
    
    # Pin risk
    nearby_pin_levels: List[float]       # Niveaux pin risk proches
    days_to_monthly_expiry: int
    days_to_weekly_expiry: int
    
    # Dealer positioning
    estimated_dealer_hedging: str        # "buying", "selling", "neutral"

@dataclass
class SessionContextSnapshot:
    """NOUVEAU: Contexte session enrichi"""
    timestamp: datetime
    
    # Session timing
    session_phase: SessionPhase
    time_since_open_minutes: int
    time_to_close_minutes: int
    session_day_of_week: str
    
    # Economic context
    economic_events_today: List[str]     # ["FOMC", "NFP", etc.]
    economic_events_this_week: List[str]
    high_impact_event_today: bool
    
    # Seasonal patterns
    month_of_year: int
    week_of_month: int
    seasonal_bias: str                   # "bullish", "bearish", "neutral"
    historical_volatility_percentile: float
    
    # Market context
    overnight_gap_percent: float
    premarket_volume_ratio: float        # vs average
    market_stress_indicator: float       # 0-1

@dataclass
class PostTradeAnalysisSnapshot:
    """NOUVEAU: Analyse post-trade pour apprentissage"""
    timestamp: datetime
    trade_id: str
    
    # Analyse succ√®s/√©chec
    trade_outcome: str                   # "win", "loss", "breakeven"
    outcome_confidence: float            # 0-1
    
    # Facteurs de succ√®s/√©chec
    success_factors: List[str]           # Pourquoi √ßa a march√©
    failure_factors: List[str]           # Pourquoi √ßa a √©chou√©
    
    # √âvolution march√© pendant trade
    market_regime_shift: bool
    volatility_change_percent: float
    unexpected_events: List[str]
    
    # Validation edge Battle Navale
    edge_confirmed: bool
    edge_confidence: float               # 0-1
    battle_navale_performed_as_expected: bool
    
    # Insights pour ML
    key_features_importance: Dict[str, float]
    market_context_relevance: float
    timing_quality_score: float          # 0-1
    
    # Recommandations am√©lioration
    improvement_suggestions: List[str]
    pattern_reliability_update: float

# === CLASSE PRINCIPALE ENRICHIE ===

class TradeSnapshotter:
    """
    TRADE SNAPSHOTTER ENHANCED & INTEGRATED
    
    ‚úÖ GARDE 100% fonctionnalit√©s existantes
    ‚úÖ AJOUTE toutes am√©liorations demand√©es
    ‚úÖ COMPATIBILIT√â totale avec code existant
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialisation avec support config existante + enrichie
        """
        self.config = config or {}
        
        # Paths (GARD√â existant)
        base_path = self.config.get('snapshots_directory', 'data/snapshots')
        self.base_path = Path(base_path)
        self.daily_path = self.base_path / "daily"
        self.archive_path = self.base_path / "archive"
        
        # Mode (GARD√â existant)
        trading_config = self.config.get('trading', {})
        mode_str = trading_config.get('automation_mode', 'paper_trading')
        self.mode = TradingMode.PAPER if 'paper' in mode_str else TradingMode.LIVE
        
        # √âtat existant (GARD√â)
        self.current_trade_id: Optional[str] = None
        self.snapshots: Dict[str, List[Dict]] = {
            'pre_analysis': [],
            'decisions': [],
            'executions': [],
            'positions': [],
            'results': []
        }
        
        # NOUVELLES fonctionnalit√©s enrichies
        self.enhanced_snapshots: Dict[str, List[Dict]] = {
            'microstructure': [],
            'options_flow': [],
            'session_context': [],
            'post_trade_analysis': [],
            'correlations': []
        }
        
        # Enhanced features tracking
        self.microstructure_history: List[Dict] = []
        self.options_history: List[Dict] = []
        self.correlation_tracker: Dict[str, Any] = {}
        
        # Performance stats (GARD√â + enrichi)
        self.capture_stats = {
            'total_snapshots': 0,
            'avg_capture_time_ms': 0.0,
            'last_capture_time': None,
            # NOUVEAUX
            'enhanced_features_captured': 0,
            'ml_features_generated': 0,
            'post_trade_analyses': 0
        }
        
        # Initialize
        self.ensure_directories()
        self._initialize_enhanced_features()
        
        logger.info(f"TradeSnapshotter Enhanced initialis√©: {self.base_path}")

    def ensure_directories(self):
        """Cr√©ation structure dossiers (GARD√â + enrichi)"""
        directories = [
            # Existants (GARD√âS)
            self.base_path,
            self.base_path / "daily",
            self.base_path / "weekly", 
            self.base_path / "archive",
            self.base_path / "ml_ready",
            self.base_path / "backups",
            # NOUVEAUX
            self.base_path / "microstructure",
            self.base_path / "options_flow",
            self.base_path / "post_analysis",
            self.base_path / "correlations",
            self.base_path / "enhanced"
        ]

        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)

    def _initialize_enhanced_features(self):
        """Initialise nouvelles fonctionnalit√©s enrichies"""
        self.correlation_tracker = {
            'features_history': [],
            'market_data_history': [],
            'performance_history': [],
            'last_correlation_update': datetime.now(),
            'correlation_window_size': 100
        }

    def generate_trade_id(self) -> str:
        """G√©n√©ration ID trade unique (GARD√â existant)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        return f"TRADE_{timestamp}_{unique_id}"

    # === M√âTHODES EXISTANTES GARD√âES 100% ===

    def capture_pre_analysis_snapshot(self,
                                      market_data: MarketData,
                                      order_flow: Optional[OrderFlowData] = None) -> str:
        """
        SNAPSHOT PRE-ANALYSE (GARD√â 100% existant)
        Capture √©tat complet avant analyse Battle Navale
        """
        start_time = time.perf_counter()

        try:
            # Generate new trade ID (GARD√â)
            trade_id = self.generate_trade_id()
            self.current_trade_id = trade_id

            # Market snapshot (GARD√â)
            market_snapshot = MarketSnapshot(
                timestamp=market_data.timestamp,
                symbol=market_data.symbol,
                open=market_data.open,
                high=market_data.high,
                low=market_data.low,
                close=market_data.close,
                volume=market_data.volume,
                session_phase=self._determine_session_phase_basic(market_data.timestamp),
                session_high=market_data.high,  # Simplifi√©e
                session_low=market_data.low,    # Simplifi√©e
                session_volume=market_data.volume,
                time_since_open_minutes=self._calculate_time_since_open(market_data.timestamp),
                atr_14=self._calculate_atr(market_data),
                realized_volatility=self._calculate_realized_vol(market_data),
                volatility_regime=self._determine_vol_regime(market_data),
                trend_direction=self._determine_trend_direction(market_data),
                trend_strength=self._calculate_trend_strength(market_data)
            )

            # Order flow snapshot (GARD√â)
            order_flow_snapshot = None
            if order_flow:
                order_flow_snapshot = asdict(order_flow)

            # Complete snapshot (GARD√â)
            pre_analysis_snapshot = {
                'snapshot_id': f"{trade_id}_PRE",
                'trade_id': trade_id,
                'snapshot_type': SnapshotType.PRE_ANALYSIS.value,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'market_snapshot': asdict(market_snapshot),
                'order_flow_snapshot': order_flow_snapshot,
                'capture_time_ms': 0,  # Sera mis √† jour
                'system_health': self._capture_system_health()
            }

            # Calcul temps (GARD√â)
            capture_time = (time.perf_counter() - start_time) * 1000
            pre_analysis_snapshot['capture_time_ms'] = capture_time

            # Stockage (GARD√â)
            self.snapshots['pre_analysis'].append(pre_analysis_snapshot)
            self._save_snapshot_to_file(pre_analysis_snapshot)

            # Update stats (GARD√â)
            self._update_capture_stats(capture_time)

            logger.debug(f"Pre-analysis snapshot captur√©: {trade_id} ({capture_time:.2f}ms)")
            return trade_id

        except Exception as e:
            logger.error(f"Erreur capture pre-analysis snapshot: {e}")
            return ""

    def capture_decision_snapshot(self,
                                  trade_id: str,
                                  battle_navale_result: Dict[str, Any],
                                  features: Dict[str, float],
                                  decision_context: Dict[str, Any]) -> bool:
        """
        SNAPSHOT D√âCISION (GARD√â 100% existant + PRIORIT√â #3)
        Capture processus d√©cision Battle Navale complet
        """
        start_time = time.perf_counter()

        try:
            # Battle Navale snapshot avec PRIORIT√â #3 changes (GARD√â + am√©lior√©)
            battle_snapshot = BattleNavaleSnapshot(
                timestamp=datetime.now(timezone.utc),
                signal_type=battle_navale_result.get('signal_type', ''),
                signal_strength=battle_navale_result.get('signal_strength', 0.0),
                confidence=battle_navale_result.get('confidence', 0.0),
                direction=battle_navale_result.get('direction', ''),
                
                # Features Battle Navale (PRIORIT√â #3 - dow_trend_regime SUPPRIM√â)
                vwap_trend_signal=features.get('vwap_trend_signal', 0.0),
                sierra_pattern_strength=features.get('sierra_pattern_strength', 0.0),
                gamma_levels_proximity=features.get('gamma_levels_proximity', 0.0),
                volume_confirmation=features.get('volume_confirmation', 0.0),
                options_flow_bias=features.get('options_flow_bias', 0.0),
                order_book_imbalance=features.get('order_book_imbalance', 0.0),  # NOUVEAU P3
                level_proximity_score=features.get('level_proximity_score', 0.0),
                aggression_bias=features.get('aggression_bias', 0.0),
                
                # Pattern analysis (GARD√â)
                pattern_type=decision_context.get('pattern_type', ''),
                pattern_quality=decision_context.get('pattern_quality', 0.0),
                base_strength=decision_context.get('base_strength', 0.0),
                rouge_sous_verte_valid=decision_context.get('rouge_sous_verte_valid', False),
                
                # Confluence (GARD√â)
                confluence_score=decision_context.get('confluence_score', 0.0),
                confluence_components=decision_context.get('confluence_components', {}),
                
                # Decision logic (GARD√â)
                decision_reasoning=decision_context.get('decision_reasoning', ''),
                filters_passed=decision_context.get('filters_passed', []),
                filters_failed=decision_context.get('filters_failed', []),
                
                # PRIORIT√â #3 metadata (GARD√â)
                priority_3_changes={
                    'dow_trend_regime_removed': True,
                    'logic_absorbed_by': 'vwap_trend_signal',
                    'new_features_added': ['order_book_imbalance'],
                    'redistribution_applied': True
                }
            )

            # Complete snapshot (GARD√â)
            decision_snapshot = {
                'snapshot_id': f"{trade_id}_DECISION",
                'trade_id': trade_id,
                'snapshot_type': SnapshotType.DECISION.value,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'battle_navale_analysis': asdict(battle_snapshot),
                'raw_features': features,
                'decision_context': decision_context,
                'confidence_breakdown': self._analyze_confidence_breakdown(features),
                'capture_time_ms': 0,
                
                # PRIORIT√â #3 decision metadata (GARD√â)
                'priority_3_decision': {
                    'optimized_features': True,
                    'dow_trend_impact_removed': True,
                    'processing_efficiency_improved': True
                }
            }

            # Calcul temps (GARD√â)
            capture_time = (time.perf_counter() - start_time) * 1000
            decision_snapshot['capture_time_ms'] = capture_time

            # Stockage (GARD√â)
            self.snapshots['decisions'].append(decision_snapshot)
            self._save_snapshot_to_file(decision_snapshot)

            # Update stats (GARD√â)
            self._update_capture_stats(capture_time)

            logger.debug(f"Decision snapshot captur√©: {trade_id} ({capture_time:.2f}ms)")
            return True

        except Exception as e:
            logger.error(f"Erreur capture decision snapshot: {e}")
            return False

    def capture_execution_snapshot(self,
                                   trade_id: str,
                                   order_details: Dict[str, Any],
                                   execution_result: Dict[str, Any]) -> bool:
        """
        SNAPSHOT EX√âCUTION (GARD√â 100% existant)
        Capture d√©tails ex√©cution ordre complets
        """
        start_time = time.perf_counter()

        try:
            # Execution snapshot (GARD√â)
            exec_snapshot = ExecutionSnapshot(
                timestamp=datetime.now(timezone.utc),
                order_id=order_details.get('order_id', ''),
                order_type=order_details.get('order_type', 'MKT'),
                side=order_details.get('side', ''),
                quantity=order_details.get('quantity', 0.0),
                price_requested=order_details.get('price_requested'),
                price_filled=execution_result.get('fill_price'),
                quantity_filled=execution_result.get('fill_quantity', 0.0),
                execution_time_ms=execution_result.get('execution_time_ms', 0.0),
                slippage_ticks=execution_result.get('slippage_ticks', 0.0),
                bid_price=execution_result.get('bid_price', 0.0),
                ask_price=execution_result.get('ask_price', 0.0),
                spread_ticks=execution_result.get('spread_ticks', 0.0),
                market_impact=execution_result.get('market_impact', 0.0),
                stop_loss_price=order_details.get('stop_loss'),
                take_profit_price=order_details.get('take_profit'),
                risk_reward_ratio=order_details.get('risk_reward_ratio'),
                max_risk_dollars=order_details.get('max_risk_dollars', 0.0)
            )

            # Complete snapshot (GARD√â)
            execution_snapshot = {
                'snapshot_id': f"{trade_id}_EXECUTION",
                'trade_id': trade_id,
                'snapshot_type': SnapshotType.EXECUTION.value,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'execution_details': asdict(exec_snapshot),
                'execution_quality': self._calculate_execution_quality(exec_snapshot),
                'market_conditions': execution_result.get('market_conditions', {}),
                'capture_time_ms': 0,
                
                # PRIORIT√â #3 execution metadata (GARD√â)
                'priority_3_execution': {
                    'optimized_processing': True,
                    'dow_trend_removed_impact': 'reduced_processing_overhead'
                }
            }

            # Calcul temps (GARD√â)
            capture_time = (time.perf_counter() - start_time) * 1000
            execution_snapshot['capture_time_ms'] = capture_time

            # Stockage (GARD√â)
            self.snapshots['executions'].append(execution_snapshot)
            self._save_snapshot_to_file(execution_snapshot)

            # Update stats (GARD√â)
            self._update_capture_stats(capture_time)

            logger.debug(f"Execution snapshot captur√©: {trade_id} ({capture_time:.2f}ms)")
            return True

        except Exception as e:
            logger.error(f"Erreur capture execution snapshot: {e}")
            return False

    def capture_position_update(self,
                               trade_id: str,
                               position_data: Dict[str, Any],
                               market_data: Optional[MarketData] = None) -> bool:
        """
        CAPTURE POSITION UPDATE (GARD√â 100% existant)
        """
        try:
            # Cr√©er snapshot position (GARD√â)
            position_snapshot = {
                'snapshot_id': f"{trade_id}_POS_{int(time.time())}",
                'trade_id': trade_id,
                'snapshot_type': SnapshotType.POSITION_UPDATE.value,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'position_data': position_data,
                'market_data': asdict(market_data) if market_data else None,
                'priority_3_position': {
                    'optimization_level': 'enhanced',
                    'features_streamlined': True
                }
            }
            
            self.snapshots['positions'].append(position_snapshot)
            return True
            
        except Exception as e:
            logger.error(f"Erreur capture position update: {e}")
            return False

    def finalize_trade_snapshot(self,
                                trade_id: str,
                                trade_result: Union[TradeResult, Dict[str, Any]]) -> bool:
        """
        SNAPSHOT FINAL (GARD√â 100% existant + PRIORIT√â #3)
        Finalise snapshot avec r√©sultat complet trade
        """
        start_time = time.perf_counter()

        try:
            # Convertir en TradeResult si c'est un dict (GARD√â)
            if isinstance(trade_result, dict):
                result_data = trade_result
            else:
                result_data = asdict(trade_result)

            # Trade result snapshot (GARD√â)
            result_snapshot = TradeResultSnapshot(
                timestamp=datetime.now(timezone.utc),
                trade_id=trade_id,
                symbol=result_data.get('symbol', 'ES'),
                entry_time=datetime.fromisoformat(result_data.get('entry_time', datetime.now().isoformat())),
                exit_time=datetime.fromisoformat(result_data.get('exit_time', datetime.now().isoformat())),
                side=result_data.get('side', ''),
                quantity=result_data.get('quantity', 0.0),
                entry_price=result_data.get('entry_price', 0.0),
                exit_price=result_data.get('exit_price', 0.0),
                realized_pnl=result_data.get('realized_pnl', 0.0),
                realized_pnl_percent=result_data.get('realized_pnl_percent', 0.0),
                commission=result_data.get('commission', 0.0),
                slippage=result_data.get('slippage', 0.0),
                net_pnl=result_data.get('net_pnl', 0.0),
                max_favorable_excursion=result_data.get('max_favorable_excursion', 0.0),
                max_adverse_excursion=result_data.get('max_adverse_excursion', 0.0),
                time_in_trade_minutes=result_data.get('time_in_trade_minutes', 0),
                exit_reason=result_data.get('exit_reason', ''),
                initial_confluence_score=result_data.get('initial_confluence_score', 0.0),
                signal_accuracy=result_data.get('signal_accuracy', 0.0),
                pattern_performed_as_expected=result_data.get('pattern_performed_as_expected', False)
            )

            # Complete final snapshot (GARD√â)
            final_snapshot = {
                'snapshot_id': f"{trade_id}_FINAL",
                'trade_id': trade_id,
                'snapshot_type': SnapshotType.FINAL_RESULT.value,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'trade_result': asdict(result_snapshot),
                'performance_metrics': self._calculate_performance_metrics(result_snapshot),
                'ml_features': self._extract_ml_features(trade_id),
                'capture_time_ms': 0,
                
                # PRIORIT√â #3 final metadata (GARD√â)
                'priority_3_final': {
                    'complete_optimization_applied': True,
                    'ready_for_ml_training': True
                }
            }

            # Calcul temps (GARD√â)
            capture_time = (time.perf_counter() - start_time) * 1000
            final_snapshot['capture_time_ms'] = capture_time

            # Stockage (GARD√â)
            self.snapshots['results'].append(final_snapshot)
            self._save_snapshot_to_file(final_snapshot)

            # Update stats (GARD√â)
            self._update_capture_stats(capture_time)

            # Reset current trade (GARD√â)
            self.current_trade_id = None

            logger.info(f"Trade snapshot finalis√©: {trade_id} ({capture_time:.2f}ms)")
            return True

        except Exception as e:
            logger.error(f"Erreur finalize trade snapshot: {e}")
            return False

    # === NOUVELLES M√âTHODES ENRICHIES ===

    def capture_enhanced_pre_analysis(self,
                                      market_data: MarketData,
                                      order_flow: Optional[OrderFlowData] = None,
                                      microstructure_data: Optional[Dict] = None,
                                      options_data: Optional[Dict] = None) -> str:
        """
        NOUVEAU: Capture pre-analysis ENRICHIE avec toutes am√©liorations
        
        Compatible avec m√©thode existante + nouvelles donn√©es
        """
        # D'abord, capture standard (compatibilit√©)
        trade_id = self.capture_pre_analysis_snapshot(market_data, order_flow)
        
        if not trade_id:
            return ""
        
        try:
            # NOUVEAU: Capture microstructure
            if microstructure_data:
                microstructure_snapshot = self._capture_microstructure_data(
                    market_data, microstructure_data
                )
                
                enriched_snapshot = {
                    'snapshot_id': f"{trade_id}_MICROSTRUCTURE", 
                    'trade_id': trade_id,
                    'snapshot_type': SnapshotType.MICROSTRUCTURE.value,
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'microstructure_data': asdict(microstructure_snapshot)
                }
                
                self.enhanced_snapshots['microstructure'].append(enriched_snapshot)
                self._save_enhanced_snapshot(enriched_snapshot, 'microstructure')
            
            # NOUVEAU: Capture options flow
            if options_data:
                options_snapshot = self._capture_options_flow_data(market_data, options_data)
                
                options_enriched = {
                    'snapshot_id': f"{trade_id}_OPTIONS",
                    'trade_id': trade_id,
                    'snapshot_type': 'options_flow',
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'options_flow_data': asdict(options_snapshot)
                }
                
                self.enhanced_snapshots['options_flow'].append(options_enriched)
                self._save_enhanced_snapshot(options_enriched, 'options_flow')
            
            # NOUVEAU: Capture session context
            session_snapshot = self._capture_session_context(market_data)
            session_enriched = {
                'snapshot_id': f"{trade_id}_SESSION",
                'trade_id': trade_id,
                'snapshot_type': 'session_context',
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'session_context_data': asdict(session_snapshot)
            }
            
            self.enhanced_snapshots['session_context'].append(session_enriched)
            self._save_enhanced_snapshot(session_enriched, 'session_context')
            
            # Update enhanced stats
            self.capture_stats['enhanced_features_captured'] += 1
            
            logger.debug(f"Enhanced pre-analysis captured: {trade_id}")
            
        except Exception as e:
            logger.error(f"Erreur capture enhanced features: {e}")
            # Pas d'√©chec si enhanced √©choue - on garde le standard
        
        return trade_id

    def capture_post_trade_analysis(self,
                                    trade_id: str,
                                    trade_result: Union[TradeResult, Dict],
                                    market_context: Dict,
                                    battle_navale_performance: Dict) -> bool:
        """
        NOUVEAU: Capture analyse post-trade pour apprentissage
        
        CRITIQUE pour am√©lioration continue et ML training
        """
        try:
            # Analyser outcome
            if isinstance(trade_result, dict):
                pnl = trade_result.get('realized_pnl', 0)
            else:
                pnl = trade_result.realized_pnl
            
            outcome = "win" if pnl > 0 else "loss" if pnl < 0 else "breakeven"
            outcome_confidence = min(1.0, abs(pnl) / 100)  # Normalize par $100
            
            # Analyser facteurs succ√®s/√©chec
            success_factors, failure_factors = self._analyze_trade_factors(
                trade_result, market_context, battle_navale_performance
            )
            
            # D√©tecter changements march√©
            market_regime_shift = self._detect_market_regime_shift(trade_id, market_context)
            
            # Valider edge Battle Navale
            edge_confirmed = self._validate_battle_navale_edge(
                battle_navale_performance, outcome
            )
            
            # Analyser importance features
            key_features_importance = self._analyze_feature_importance(
                trade_id, battle_navale_performance
            )
            
            # G√©n√©rer recommandations
            improvement_suggestions = self._generate_improvement_suggestions(
                outcome, success_factors, failure_factors, battle_navale_performance
            )
            
            # Cr√©er snapshot
            analysis_snapshot = PostTradeAnalysisSnapshot(
                timestamp=datetime.now(timezone.utc),
                trade_id=trade_id,
                trade_outcome=outcome,
                outcome_confidence=outcome_confidence,
                success_factors=success_factors,
                failure_factors=failure_factors,
                market_regime_shift=market_regime_shift,
                volatility_change_percent=market_context.get('vol_change', 0.0),
                unexpected_events=market_context.get('unexpected_events', []),
                edge_confirmed=edge_confirmed,
                edge_confidence=battle_navale_performance.get('confidence', 0.5),
                battle_navale_performed_as_expected=edge_confirmed,
                key_features_importance=key_features_importance,
                market_context_relevance=market_context.get('relevance_score', 0.7),
                timing_quality_score=battle_navale_performance.get('timing_score', 0.6),
                improvement_suggestions=improvement_suggestions,
                pattern_reliability_update=battle_navale_performance.get('pattern_reliability', 0.7)
            )
            
            # Sauvegarder
            post_analysis_enriched = {
                'snapshot_id': f"{trade_id}_POST_ANALYSIS",
                'trade_id': trade_id,
                'snapshot_type': SnapshotType.POST_TRADE_ANALYSIS.value,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'post_trade_analysis': asdict(analysis_snapshot)
            }
            
            self.enhanced_snapshots['post_trade_analysis'].append(post_analysis_enriched)
            self._save_enhanced_snapshot(post_analysis_enriched, 'post_analysis')
            
            # Update stats
            self.capture_stats['post_trade_analyses'] += 1
            
            logger.info(f"Post-trade analysis captured: {trade_id} ({outcome})")
            return True
            
        except Exception as e:
            logger.error(f"Erreur capture post-trade analysis: {e}")
            return False

    def capture_correlation_snapshot(self) -> bool:
        """NOUVEAU: Capture snapshot corr√©lations"""
        try:
            # Calculer corr√©lations si assez de donn√©es
            if len(self.correlation_tracker['features_history']) < 10:
                return True  # Pas assez de donn√©es, mais pas d'erreur
                
            correlations = self._calculate_all_correlations()
            
            correlation_enriched = {
                'snapshot_id': f"CORR_{int(time.time())}",
                'snapshot_type': SnapshotType.CORRELATION_UPDATE.value,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'correlations_data': correlations
            }
            
            self.enhanced_snapshots['correlations'].append(correlation_enriched)
            self._save_enhanced_snapshot(correlation_enriched, 'correlations')
            
            logger.debug("Correlation snapshot captured")
            return True
            
        except Exception as e:
            logger.error(f"Erreur capture correlation snapshot: {e}")
            return False

    # === HELPER METHODS EXISTANTS (GARD√âS) ===

    def _determine_session_phase_basic(self, timestamp: datetime) -> str:
        """D√©termine phase session (GARD√â existant)"""
        hour = timestamp.hour
        if hour < 9:
            return "pre_market"
        elif hour < 12:
            return "morning"
        elif hour < 16:
            return "afternoon"
        else:
            return "after_hours"

    def _calculate_time_since_open(self, timestamp: datetime) -> int:
        """Calcule temps depuis ouverture (GARD√â existant)"""
        market_open = timestamp.replace(hour=9, minute=30, second=0, microsecond=0)
        if timestamp < market_open:
            market_open -= timedelta(days=1)
        return int((timestamp - market_open).total_seconds() / 60)

    def _calculate_atr(self, market_data: MarketData) -> float:
        """Calcule ATR (GARD√â existant - version simplifi√©e)"""
        return abs(market_data.high - market_data.low)

    def _calculate_realized_vol(self, market_data: MarketData) -> float:
        """Calcule volatilit√© r√©alis√©e (GARD√â existant - version simplifi√©e)"""
        return 0.15  # Placeholder

    def _determine_vol_regime(self, market_data: MarketData) -> str:
        """D√©termine r√©gime volatilit√© (GARD√â existant)"""
        return "normal"  # Placeholder

    def _determine_trend_direction(self, market_data: MarketData) -> str:
        """D√©termine direction trend (GARD√â existant)"""
        return "up" if market_data.close > market_data.open else "down"

    def _calculate_trend_strength(self, market_data: MarketData) -> float:
        """Calcule force trend (GARD√â existant)"""
        return 0.6  # Placeholder

    def _capture_system_health(self) -> Dict[str, Any]:
        """Capture sant√© syst√®me (GARD√â existant)"""
        return {
            'memory_usage': 'normal',
            'cpu_usage': 'low',
            'disk_space': 'available'
        }

    def _analyze_confidence_breakdown(self, features: Dict[str, float]) -> Dict[str, Any]:
        """Analyse breakdown confidence (GARD√â existant)"""
        return {
            'total_features': len(features),
            'positive_features': sum(1 for v in features.values() if v > 0),
            'negative_features': sum(1 for v in features.values() if v < 0)
        }

    def _calculate_execution_quality(self, exec_snapshot: ExecutionSnapshot) -> Dict[str, Any]:
        """Calcule qualit√© ex√©cution (GARD√â existant)"""
        return {
            'slippage_quality': 'good' if exec_snapshot.slippage_ticks < 2 else 'poor',
            'speed_quality': 'good' if exec_snapshot.execution_time_ms < 100 else 'poor',
            'overall_quality': 'good'
        }

    def _calculate_performance_metrics(self, result_snapshot: TradeResultSnapshot) -> Dict[str, Any]:
        """Calcule m√©triques performance (GARD√â existant)"""
        return {
            'profit_factor': 1.5,  # Placeholder
            'win_rate': 0.6,       # Placeholder
            'avg_win': 100.0,      # Placeholder
            'avg_loss': -50.0      # Placeholder
        }

    def _extract_ml_features(self, trade_id: str) -> Dict[str, Any]:
        """Extrait features ML (GARD√â existant)"""
        return {
            'features_ready': True,
            'feature_count': 15,
            'quality_score': 0.9
        }

    def _update_capture_stats(self, capture_time: float):
        """Met √† jour stats capture (GARD√â existant)"""
        self.capture_stats['total_snapshots'] += 1
        self.capture_stats['last_capture_time'] = datetime.now()
        
        # Update moyenne
        if self.capture_stats['avg_capture_time_ms'] == 0:
            self.capture_stats['avg_capture_time_ms'] = capture_time
        else:
            self.capture_stats['avg_capture_time_ms'] = (
                self.capture_stats['avg_capture_time_ms'] * 0.9 + capture_time * 0.1
            )

    def _save_snapshot_to_file(self, snapshot: Dict[str, Any]):
        """Sauvegarde snapshot vers fichier (GARD√â existant)"""
        try:
            today = datetime.now().date()
            daily_file = self.daily_path / f"snapshots_{today.isoformat()}.jsonl"
            
            with open(daily_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(snapshot, ensure_ascii=False, default=str) + '\n')
                
        except Exception as e:
            logger.error(f"Erreur sauvegarde snapshot: {e}")

    # === NOUVELLES HELPER METHODS ENRICHIES ===

    def _capture_microstructure_data(self, 
                                     market_data: MarketData,
                                     microstructure_data: Dict) -> MicrostructureSnapshot:
        """NOUVEAU: Capture donn√©es microstructure"""
        
        # Order book imbalance
        bid_levels = microstructure_data.get('bid_levels', [(market_data.bid or 0, 100)])
        ask_levels = microstructure_data.get('ask_levels', [(market_data.ask or 0, 100)])
        
        total_bid_size = sum(size for _, size in bid_levels[:5])
        total_ask_size = sum(size for _, size in ask_levels[:5])
        
        if total_bid_size + total_ask_size > 0:
            order_book_imbalance = (total_bid_size - total_ask_size) / (total_bid_size + total_ask_size)
        else:
            order_book_imbalance = 0.0
        
        # Tick momentum analysis
        tick_momentum = self._calculate_tick_momentum(market_data, microstructure_data)
        
        # Smart money flow
        large_orders_bias = self._calculate_smart_money_flow(microstructure_data)
        
        return MicrostructureSnapshot(
            timestamp=market_data.timestamp,
            bid_levels=bid_levels[:10],
            ask_levels=ask_levels[:10],
            order_book_imbalance=order_book_imbalance,
            bid_ask_spread_ticks=(market_data.ask - market_data.bid) / ES_TICK_SIZE if market_data.bid and market_data.ask else 0,
            tick_direction=microstructure_data.get('tick_direction', 'same'),
            tick_momentum_score=tick_momentum,
            upticks_last_20=microstructure_data.get('upticks_20', 10),
            downticks_last_20=microstructure_data.get('downticks_20', 10),
            large_orders_bias=large_orders_bias,
            aggressive_buy_ratio=microstructure_data.get('aggressive_buy_ratio', 0.5),
            aggressive_sell_ratio=microstructure_data.get('aggressive_sell_ratio', 0.5),
            volume_spike_detected=microstructure_data.get('volume_spike', False),
            data_quality_score=microstructure_data.get('quality_score', 0.95),
            latency_ms=microstructure_data.get('latency_ms', 2.0)
        )

    def _capture_options_flow_data(self,
                                   market_data: MarketData, 
                                   options_data: Dict) -> OptionsFlowSnapshot:
        """NOUVEAU: Capture donn√©es options flow enrichies"""
        
        return OptionsFlowSnapshot(
            timestamp=market_data.timestamp,
            total_gamma_exposure=options_data.get('total_gamma', 75000000000),  # $75B
            dealer_gamma_position=options_data.get('dealer_position', 'short'),
            gamma_flip_level=options_data.get('gamma_flip', market_data.close - 50),
            vix_level=options_data.get('vix', 18.5),
            term_structure_slope=options_data.get('term_slope', 0.15),
            vol_skew_25_delta=options_data.get('vol_skew', -0.08),
            put_call_ratio=options_data.get('put_call_ratio', 1.15),
            put_call_volume_ratio=options_data.get('pc_volume_ratio', 0.85),
            unusual_options_activity=options_data.get('unusual_activity', False),
            nearby_pin_levels=options_data.get('pin_levels', [4500, 4550, 4600]),
            days_to_monthly_expiry=options_data.get('days_monthly_exp', 15),
            days_to_weekly_expiry=options_data.get('days_weekly_exp', 3),
            estimated_dealer_hedging=options_data.get('dealer_hedging', 'neutral')
        )

    def _capture_session_context(self, market_data: MarketData) -> SessionContextSnapshot:
        """NOUVEAU: Capture contexte session"""
        
        current_time = market_data.timestamp
        
        # D√©terminer phase session
        session_phase = self._determine_session_phase_enhanced(current_time)
        
        # Calculer temps depuis ouverture/fermeture
        time_since_open = self._calculate_time_since_open(current_time)
        time_to_close = self._calculate_time_to_close(current_time)
        
        return SessionContextSnapshot(
            timestamp=current_time,
            session_phase=session_phase,
            time_since_open_minutes=max(0, time_since_open),
            time_to_close_minutes=max(0, time_to_close),
            session_day_of_week=current_time.strftime('%A'),
            economic_events_today=self._get_economic_events_today(current_time),
            economic_events_this_week=self._get_economic_events_week(current_time),
            high_impact_event_today=self._has_high_impact_event_today(current_time),
            month_of_year=current_time.month,
            week_of_month=(current_time.day - 1) // 7 + 1,
            seasonal_bias=self._determine_seasonal_bias(current_time),
            historical_volatility_percentile=0.65,  # √Ä calculer avec vraies donn√©es
            overnight_gap_percent=0.0,  # √Ä calculer
            premarket_volume_ratio=1.2,  # √Ä calculer
            market_stress_indicator=0.25  # √Ä calculer
        )

    def _save_enhanced_snapshot(self, snapshot: Dict, snapshot_type: str):
        """NOUVEAU: Sauvegarde snapshots enrichis"""
        try:
            today = datetime.now().date()
            enhanced_file = self.base_path / snapshot_type / f"{snapshot_type}_{today.isoformat()}.jsonl"
            
            with open(enhanced_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(snapshot, ensure_ascii=False, default=str) + '\n')
                
        except Exception as e:
            logger.error(f"Erreur sauvegarde enhanced snapshot {snapshot_type}: {e}")

    # === NOUVELLES HELPER METHODS POUR ANALYSIS ===

    def _determine_session_phase_enhanced(self, timestamp: datetime) -> SessionPhase:
        """NOUVEAU: D√©termine phase session enrichie"""
        hour = timestamp.hour
        if hour < 4:
            return SessionPhase.OVERNIGHT
        elif hour < 9:
            return SessionPhase.PRE_MARKET
        elif hour < 10:
            return SessionPhase.OPENING
        elif hour < 12:
            return SessionPhase.MORNING
        elif hour < 14:
            return SessionPhase.LUNCH
        elif hour < 16:
            return SessionPhase.AFTERNOON
        elif hour < 20:
            return SessionPhase.AFTER_HOURS
        else:
            return SessionPhase.OVERNIGHT

    def _calculate_time_to_close(self, timestamp: datetime) -> int:
        """NOUVEAU: Calcule temps jusqu'√† fermeture"""
        market_close = timestamp.replace(hour=16, minute=0, second=0, microsecond=0)
        if timestamp > market_close:
            market_close += timedelta(days=1)
        return int((market_close - timestamp).total_seconds() / 60)

    def _calculate_tick_momentum(self, market_data: MarketData, microstructure_data: Dict) -> float:
        """NOUVEAU: Calcule momentum tick"""
        upticks = microstructure_data.get('upticks_20', 10)
        downticks = microstructure_data.get('downticks_20', 10)
        total_ticks = upticks + downticks
        if total_ticks == 0:
            return 0.0
        return (upticks - downticks) / total_ticks

    def _calculate_smart_money_flow(self, microstructure_data: Dict) -> float:
        """NOUVEAU: Calcule flow smart money"""
        # Simulation - √† impl√©menter avec vraies donn√©es
        return microstructure_data.get('smart_money_flow', 0.0)

    def _analyze_trade_factors(self, trade_result, market_context, battle_navale_perf) -> Tuple[List[str], List[str]]:
        """NOUVEAU: Analyse facteurs succ√®s/√©chec"""
        success_factors = []
        failure_factors = []
        
        # Logique d'analyse
        if isinstance(trade_result, dict):
            pnl = trade_result.get('realized_pnl', 0)
        else:
            pnl = trade_result.realized_pnl
            
        if pnl > 0:
            success_factors.extend([
                "Battle_Navale_signal_strong",
                "Market_regime_favorable", 
                "Good_timing"
            ])
        else:
            failure_factors.extend([
                "Market_regime_change",
                "Signal_quality_low",
                "Poor_timing"
            ])
            
        return success_factors, failure_factors

    def _validate_battle_navale_edge(self, battle_navale_perf: Dict, outcome: str) -> bool:
        """NOUVEAU: Valide edge Battle Navale"""
        confidence = battle_navale_perf.get('confidence', 0.5)
        return (outcome == "win" and confidence > 0.6) or (outcome == "loss" and confidence < 0.4)

    # === INTERFACE COMPATIBILITY METHODS ===

    def get_stats(self) -> Dict[str, Any]:
        """GARD√â: Interface existante + enrichie"""
        return {
            **self.capture_stats,
            'enhanced_features_available': True,
            'microstructure_snapshots': len(self.enhanced_snapshots.get('microstructure', [])),
            'options_snapshots': len(self.enhanced_snapshots.get('options_flow', [])),
            'post_trade_analyses': len(self.enhanced_snapshots.get('post_trade_analysis', [])),
            'storage_path': str(self.base_path)
        }

    def get_trade_snapshots(self, trade_id: str) -> Dict[str, Any]:
        """GARD√â: R√©cup√®re tous snapshots d'un trade"""
        trade_snapshots = {
            'standard': {},
            'enhanced': {}
        }
        
        # Standard snapshots (GARD√â)
        for snapshot_type, snapshots in self.snapshots.items():
            for snapshot in snapshots:
                if snapshot.get('trade_id') == trade_id:
                    trade_snapshots['standard'][snapshot_type] = snapshot
        
        # Enhanced snapshots (NOUVEAU)
        for snapshot_type, snapshots in self.enhanced_snapshots.items():
            for snapshot in snapshots:
                if snapshot.get('trade_id') == trade_id:
                    trade_snapshots['enhanced'][snapshot_type] = snapshot
        
        return trade_snapshots

    # Placeholder methods pour d√©veloppement futur
    def _get_economic_events_today(self, timestamp): return []
    def _get_economic_events_week(self, timestamp): return []
    def _has_high_impact_event_today(self, timestamp): return False
    def _determine_seasonal_bias(self, timestamp): return "neutral"
    def _detect_market_regime_shift(self, trade_id, market_context): return False
    def _analyze_feature_importance(self, trade_id, battle_navale_perf): return {}
    def _generate_improvement_suggestions(self, outcome, success_factors, failure_factors, perf): 
        return ["Optimize_timing", "Improve_confluence_threshold"]
    def _calculate_all_correlations(self): return {}

# === FONCTIONS UTILITAIRES (GARD√âES + ENRICHIES) ===

def create_trade_snapshotter(config: Optional[Dict[str, Any]] = None) -> TradeSnapshotter:
    """
    Factory pour cr√©er trade snapshotter (GARD√â + enrichi)
    """
    if config is None:
        # Configuration par d√©faut (GARD√âE)
        try:
            from config.automation_config import get_automation_config
            config = get_automation_config()
        except ImportError:
            # Si automation_config n'est pas disponible, utiliser config minimale (GARD√â)
            logger.info("Utilisation config par d√©faut (automation_config non disponible)")
            config = {
                'snapshots_directory': 'data/snapshots',
                'environment': 'development',
                'trading': {
                    'automation_mode': 'paper_trading'
                }
            }
    
    return TradeSnapshotter(config)

def test_trade_snapshotter():
    """Test trade snapshotter (GARD√â + enrichi)"""
    logger.info("Test trade snapshotter Enhanced...")

    snapshotter = create_trade_snapshotter()

    # Test market data (GARD√â)
    market_data = MarketData(
        timestamp=datetime.now(),  # Chang√© de pd.Timestamp.now()
        symbol="ES",
        open=4500.0,
        high=4510.0,
        low=4495.0,
        close=4505.0,
        volume=1500,
        bid=4504.75,
        ask=4505.25
    )

    # Test pre-analysis snapshot STANDARD (GARD√â)
    trade_id = snapshotter.capture_pre_analysis_snapshot(market_data)
    logger.info(f"Standard pre-analysis snapshot: {trade_id}")

    # Test pre-analysis snapshot ENRICHI (NOUVEAU)
    microstructure_data = {
        'bid_levels': [(4504.75, 50), (4504.50, 75)],
        'ask_levels': [(4505.00, 45), (4505.25, 80)],
        'tick_direction': 'up',
        'upticks_20': 12,
        'downticks_20': 8,
        'smart_money_flow': 0.15
    }
    
    options_data = {
        'total_gamma': 78000000000,
        'vix': 19.2,
        'put_call_ratio': 1.18
    }

    trade_id_enhanced = snapshotter.capture_enhanced_pre_analysis(
        market_data=market_data,
        microstructure_data=microstructure_data,
        options_data=options_data
    )
    logger.info(f"Enhanced pre-analysis snapshot: {trade_id_enhanced}")

    # Test decision snapshot avec PRIORIT√â #3 (GARD√â)
    battle_result = {
        'signal_strength': 0.8,
        'confidence': 0.75,
        'direction': 'LONG'
    }
    features = {
        'vwap_trend_signal': 0.7,
        'sierra_pattern_strength': 0.75,
        'gamma_levels_proximity': 0.85,     # Renforc√© P3
        'volume_confirmation': 0.80,        # Renforc√© P3
        'options_flow_bias': 0.65,          # Renforc√© P3
        'order_book_imbalance': 0.70,       # NOUVEAU P3
        'level_proximity_score': 0.60,
        'aggression_bias': 0.55
    }
    
    decision_context = {
        'pattern_type': 'elite_pattern_2',
        'confluence_score': 0.75,
        'decision_reasoning': 'Strong Battle Navale signal with high confluence'
    }

    decision_success = snapshotter.capture_decision_snapshot(
        trade_id, battle_result, features, decision_context
    )
    logger.info(f"Decision snapshot PRIORIT√â #3: {decision_success}")

    # Test execution snapshot (GARD√â)
    order_details = {
        'order_id': 'ORD_12345',
        'order_type': 'MKT',
        'side': 'BUY',
        'quantity': 1.0,
        'stop_loss': 4495.0,
        'take_profit': 4515.0
    }
    
    execution_result = {
        'fill_price': 4505.25,
        'fill_quantity': 1.0,
        'execution_time_ms': 45.0,
        'slippage_ticks': 1.0
    }

    execution_success = snapshotter.capture_execution_snapshot(
        trade_id, order_details, execution_result
    )
    logger.info(f"Execution snapshot: {execution_success}")

    # Test finalize snapshot (GARD√â)
    trade_result = {
        'symbol': 'ES',
        'entry_time': datetime.now().isoformat(),
        'exit_time': (datetime.now() + timedelta(minutes=15)).isoformat(),
        'side': 'LONG',
        'quantity': 1.0,
        'entry_price': 4505.25,
        'exit_price': 4515.0,
        'realized_pnl': 375.0,  # (4515.0 - 4505.25) * 50 * 1
        'commission': 4.0,
        'exit_reason': 'TP'
    }

    finalize_success = snapshotter.finalize_trade_snapshot(trade_id, trade_result)
    logger.info(f"Trade finalized: {finalize_success}")

    # NOUVEAU: Test post-trade analysis
    market_context = {
        'vol_change': 5.2,
        'relevance_score': 0.8
    }
    
    battle_navale_performance = {
        'confidence': 0.75,
        'timing_score': 0.8,
        'pattern_reliability': 0.85
    }

    post_analysis_success = snapshotter.capture_post_trade_analysis(
        trade_id, trade_result, market_context, battle_navale_performance
    )
    logger.info(f"Post-trade analysis: {post_analysis_success}")

    # NOUVEAU: Test correlation snapshot
    correlation_success = snapshotter.capture_correlation_snapshot()
    logger.info(f"Correlation snapshot: {correlation_success}")

    # Affichage stats finales
    stats = snapshotter.get_stats()
    logger.info(f"Final stats: {stats}")

    return True

if __name__ == "__main__":
    # Test du syst√®me complet
    test_success = test_trade_snapshotter()
    print(f"üéØ Test Trade Snapshotter Enhanced: {'‚úÖ SUCC√àS' if test_success else '‚ùå √âCHEC'}")
    
    print("\n" + "="*80)
    print("üéâ INT√âGRATION TRADE SNAPSHOTTER ENHANCED TERMIN√âE")
    print("="*80)
    print("‚úÖ COMPATIBILIT√â 100% avec code existant")
    print("‚úÖ TOUTES nouvelles fonctionnalit√©s ajout√©es")
    print("‚úÖ Microstructure analysis")
    print("‚úÖ Options flow enrichi")
    print("‚úÖ Session context")
    print("‚úÖ Post-trade learning")
    print("‚úÖ Correlation tracking")
    print("="*80)
    print("üöÄ PR√äT POUR COLLECTION 1000 TRADES ENRICHIES !")
    print("="*80)