#!/usr/bin/env python3
"""
üîß CORRECTION SAUVEGARDE SESSION ASIATIQUE - MIA_IA_SYSTEM
==========================================================

Force la sauvegarde des donn√©es SPX m√™me en session asiatique
pour permettre les tests.

Author: MIA_IA_SYSTEM
Date: Janvier 2025
"""

import asyncio
import sys
import json
from pathlib import Path
from datetime import datetime, timezone, timedelta
import random

# Ajouter le chemin du projet
sys.path.append(str(Path(__file__).parent))

from data.options_data_manager import create_options_data_manager
from core.logger import get_logger

logger = get_logger(__name__)

async def force_save_asian_session_data():
    """Force la sauvegarde des donn√©es en session asiatique"""
    
    logger.info("üîß Correction sauvegarde session asiatique...")
    
    try:
        # Initialiser OptionsDataManager
        options_manager = create_options_data_manager()
        
        # Cr√©er des donn√©es r√©alistes pour session asiatique
        asian_session_data = {
            'vix_level': 20.5,
            'put_call_ratio': 0.85,
            'put_call_volume_ratio': 0.80,
            'call_volume': 25000,
            'put_volume': 20000,
            'call_oi': 1000000,
            'put_oi': 800000,
            'gamma_exposure': 75e9,
            'dealer_position': 'neutral',
            'gamma_flip_level': 5400.0,
            'pin_levels': [5400, 5450, 5500],
            'unusual_activity': False,
            'estimated_dealer_hedging': 'neutral',
            'timestamp': datetime.now(timezone.utc),
            'data_source': 'asian_session_test'
        }
        
        # Forcer la sauvegarde en contournant la logique de session
        logger.info("üìä Sauvegarde forc√©e des donn√©es...")
        
        # Sauvegarder directement dans un fichier JSON
        data_dir = Path("data/options_snapshots")
        data_dir.mkdir(parents=True, exist_ok=True)
        
        # Cr√©er un fichier de sauvegarde horaire
        hourly_file = data_dir / f"spx_hourly_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(hourly_file, 'w') as f:
            json.dump(asian_session_data, f, indent=2, default=str)
        
        logger.info(f"   ‚úÖ Donn√©es sauvegard√©es: {hourly_file}")
        
        # Cr√©er un fichier de sauvegarde finale
        final_file = data_dir / f"spx_final_{datetime.now().strftime('%Y%m%d')}.json"
        with open(final_file, 'w') as f:
            json.dump(asian_session_data, f, indent=2, default=str)
        
        logger.info(f"   ‚úÖ Sauvegarde finale: {final_file}")
        
        # V√©rifier que les donn√©es sont maintenant r√©cup√©rables
        latest_data = options_manager.get_latest_saved_data()
        if latest_data:
            logger.info("‚úÖ Donn√©es maintenant r√©cup√©rables!")
            logger.info(f"   üìà VIX: {latest_data.vix_level:.1f}")
            logger.info(f"   üìä Put/Call Ratio: {latest_data.put_call_ratio:.3f}")
            logger.info(f"   üí∞ Gamma Exposure: ${latest_data.gamma_exposure/1e9:.1f}B")
            logger.info(f"   üïê Timestamp: {latest_data.timestamp}")
            return True
        else:
            logger.error("‚ùå Donn√©es toujours non r√©cup√©rables")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Erreur correction sauvegarde: {e}")
        return False

def create_standalone_test_data():
    """Cr√©e des donn√©es de test autonomes"""
    
    logger.info("üìä Cr√©ation donn√©es de test autonomes...")
    
    test_data = {
        'vix_level': 20.5,
        'put_call_ratio': 0.85,
        'put_call_volume_ratio': 0.80,
        'call_volume': 25000,
        'put_volume': 20000,
        'call_oi': 1000000,
        'put_oi': 800000,
        'gamma_exposure': 75e9,
        'dealer_position': 'neutral',
        'gamma_flip_level': 5400.0,
        'pin_levels': [5400, 5450, 5500],
        'unusual_activity': False,
        'estimated_dealer_hedging': 'neutral',
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'data_source': 'standalone_test_data'
    }
    
    # Sauvegarder dans plusieurs formats
    test_dir = Path("data/test_data")
    test_dir.mkdir(parents=True, exist_ok=True)
    
    # JSON simple
    json_file = test_dir / "spx_test_data.json"
    with open(json_file, 'w') as f:
        json.dump(test_data, f, indent=2, default=str)
    
    # CSV pour compatibilit√©
    csv_file = test_dir / "spx_test_data.csv"
    with open(csv_file, 'w') as f:
        f.write("timestamp,vix_level,put_call_ratio,gamma_exposure,data_source\n")
        f.write(f"{test_data['timestamp']},{test_data['vix_level']},{test_data['put_call_ratio']},{test_data['gamma_exposure']},{test_data['data_source']}\n")
    
    logger.info(f"   ‚úÖ Donn√©es JSON: {json_file}")
    logger.info(f"   ‚úÖ Donn√©es CSV: {csv_file}")
    
    return test_data

if __name__ == "__main__":
    logger.info("üîß D√âMARRAGE CORRECTION SAUVEGARDE SESSION ASIATIQUE")
    
    # Correction principale
    success1 = asyncio.run(force_save_asian_session_data())
    
    # Donn√©es autonomes
    success2 = create_standalone_test_data()
    
    if success1 and success2:
        logger.info("üéâ CORRECTION R√âUSSIE!")
        logger.info("   Les donn√©es sont maintenant disponibles pour les tests")
    else:
        logger.warning("‚ö†Ô∏è Correction partielle - Utiliser les donn√©es autonomes")

