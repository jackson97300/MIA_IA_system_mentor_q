#!/usr/bin/env python3
"""
üìä DATA COLLECTOR ENHANCED - MIA_IA_SYSTEM
==========================================

Module de collecte de donn√©es am√©lior√© extrait du fichier monstre
- Initialisation du collecteur de donn√©es
- Sauvegarde des donn√©es de barres
- Sauvegarde des donn√©es de signaux
- R√©cup√©ration des donn√©es historiques
"""

import sys
import asyncio
import json
import random
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from collections import defaultdict

# Ajouter le chemin du projet
sys.path.append(str(Path(__file__).parent.parent))

from core.logger import get_logger

# Imports Sierra (fa√ßon s√ªre, non bloquante)
try:
    from features.sierra_stream import SierraTail, create_sierra_tail, SierraEvent
    from features.unifier import UnifiedWriter, create_unified_writer, create_unify_config
    from config.sierra_paths import DEFAULT_CHARTS
    _SIERRA_AVAILABLE = True
except Exception:
    _SIERRA_AVAILABLE = False
    SierraTail = None  # type: ignore
    UnifiedWriter = None  # type: ignore
    DEFAULT_CHARTS = [3, 4, 8, 10]

logger = get_logger(__name__)

class DataCollectorEnhanced:
    """Collecteur de donn√©es am√©lior√© avec sauvegarde"""
    
    def __init__(self, config=None):
        self.config = config or {}
        self.data_collector = defaultdict(list)
        self.signal_data = defaultdict(list)
        self.bar_data = defaultdict(list)
        self.historical_data = defaultdict(list)
        
        # Sierra runtime
        self.sierra_tail: Optional[SierraTail] = None
        self.unified_writer: Optional[UnifiedWriter] = None
        self._sierra_running: bool = False
        self._sierra_task: Optional[asyncio.Task] = None
        self._on_event_callbacks: List[Callable[[Dict[str, Any]], None]] = []
        self._menthorq_processor = None
        self._vix_cache: Dict[str, Any] = {
            'last_value': None,
            'last_ts': None,
        }
        
        # Initialisation
        self._initialize_data_collector()
        
        logger.info("üìä Data Collector Enhanced initialis√©")
    
    def _initialize_data_collector(self) -> None:
        """Initialise le collecteur de donn√©es"""
        try:
            # Cr√©er les r√©pertoires de donn√©es si n√©cessaire
            data_dir = Path("data")
            data_dir.mkdir(exist_ok=True)
            
            # Sous-r√©pertoires
            (data_dir / "bars").mkdir(exist_ok=True)
            (data_dir / "signals").mkdir(exist_ok=True)
            (data_dir / "historical").mkdir(exist_ok=True)
            
            logger.info("‚úÖ R√©pertoires de donn√©es cr√©√©s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation data collector: {e}")
    
    def save_bar_data(self, symbol: str, bar_data: Dict[str, Any]) -> None:
        """Sauvegarde les donn√©es de barres"""
        try:
            # Ajouter timestamp
            bar_data['timestamp'] = datetime.now().isoformat()
            bar_data['symbol'] = symbol
            
            # Stocker en m√©moire
            self.bar_data[symbol].append(bar_data)
            
            # Limiter la taille en m√©moire (garder les 100 derni√®res barres)
            if len(self.bar_data[symbol]) > 100:
                self.bar_data[symbol] = self.bar_data[symbol][-100:]
            
            # Sauvegarder sur disque (optionnel)
            if self.config.get('save_to_disk', False):
                self._save_to_disk(symbol, bar_data, 'bars')
            
            logger.debug(f"üìä Barre sauvegard√©e pour {symbol}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde barre {symbol}: {e}")
    
    def save_signal_data(self, symbol: str, signal_data: Dict[str, Any]) -> None:
        """Sauvegarde les donn√©es de signaux"""
        try:
            # Ajouter timestamp
            signal_data['timestamp'] = datetime.now().isoformat()
            signal_data['symbol'] = symbol
            
            # Stocker en m√©moire
            self.signal_data[symbol].append(signal_data)
            
            # Limiter la taille en m√©moire (garder les 50 derniers signaux)
            if len(self.signal_data[symbol]) > 50:
                self.signal_data[symbol] = self.signal_data[symbol][-50:]
            
            # Sauvegarder sur disque (optionnel)
            if self.config.get('save_to_disk', False):
                self._save_to_disk(symbol, signal_data, 'signals')
            
            logger.debug(f"üìä Signal sauvegard√© pour {symbol}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde signal {symbol}: {e}")
    
    def get_historical_data_for_symbol(self, symbol: str, max_bars: int = 20) -> List[Dict]:
        """R√©cup√®re les donn√©es historiques pour un symbole"""
        try:
            # V√©rifier si on est en mode r√©el
            if hasattr(self.config, 'use_real_data') and self.config.use_real_data:
                # PRIORIT√â 1: Essayer Sierra Chart DTC (plus fiable)
                try:
                    from execution.sierra_connector import SierraConnector
                    
                    # Connexion Sierra Chart pour vraies donn√©es
                    sierra_connector = SierraConnector()
                    
                    if sierra_connector.connect():
                        # Souscrire aux donn√©es
                        sierra_connector.subscribe_market_data(symbol)
                        
                        # Attendre un peu pour recevoir des donn√©es
                        import time
                        time.sleep(1)
                        
                        # R√©cup√©rer donn√©es Sierra Chart
                        sierra_data = sierra_connector.get_market_data(symbol)
                        if sierra_data and sierra_data.get('price'):
                            # Cr√©er une barre avec les vraies donn√©es Sierra Chart
                            current_price = float(sierra_data['price'])
                            bar_data = {
                                'timestamp': datetime.now().isoformat(),
                                'symbol': symbol,
                                'open': current_price,
                                'high': current_price,
                                'low': current_price,
                                'close': current_price,
                                'volume': sierra_data.get('volume', 1000),
                                'price': current_price,
                                'bid_price': sierra_data.get('bid_price', current_price),
                                'ask_price': sierra_data.get('ask_price', current_price),
                                'data_source': 'Sierra Chart DTC'
                            }
                            
                            # Stocker les vraies donn√©es
                            if symbol not in self.bar_data:
                                self.bar_data[symbol] = []
                            self.bar_data[symbol].append(bar_data)
                            
                            logger.info(f"‚úÖ Vraies donn√©es Sierra Chart r√©cup√©r√©es pour {symbol}: {current_price}")
                            sierra_connector.disconnect()
                            return [bar_data]
                        
                        sierra_connector.disconnect()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de r√©cup√©rer vraies donn√©es Sierra Chart: {e}")
                
                # PRIORIT√â 2: Fallback Sierra (remplace IBKR)
                try:
                    # Utiliser le cache VIX et les donn√©es Sierra si disponibles
                    vix_cache = self.get_vix_cache()
                    if vix_cache.get('last_value'):
                        # Cr√©er une barre avec les donn√©es Sierra disponibles
                        current_price = 5295.0  # Prix de base ES
                        bar_data = {
                            'timestamp': datetime.now().isoformat(),
                            'symbol': symbol,
                            'open': current_price,
                            'high': current_price + 2.0,
                            'low': current_price - 2.0,
                            'close': current_price,
                            'volume': 1000,
                            'price': current_price,
                            'data_source': 'Sierra JSONL',
                            'vix': vix_cache.get('last_value')
                        }
                        
                        # Stocker les donn√©es Sierra
                        if symbol not in self.bar_data:
                            self.bar_data[symbol] = []
                        self.bar_data[symbol].append(bar_data)
                        
                        logger.info(f"‚úÖ Donn√©es Sierra r√©cup√©r√©es pour {symbol}: {current_price}")
                        return [bar_data]
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de r√©cup√©rer donn√©es Sierra: {e}")
            
            # Donn√©es en m√©moire
            if symbol in self.bar_data and self.bar_data[symbol]:
                return self.bar_data[symbol][-max_bars:]
            
            # Donn√©es historiques sauvegard√©es
            if symbol in self.historical_data and self.historical_data[symbol]:
                return self.historical_data[symbol][-max_bars:]
            
            # G√©n√©rer des donn√©es simul√©es si aucune donn√©e disponible
            return self._generate_simulated_data(symbol, max_bars)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration donn√©es historiques {symbol}: {e}")
            return self._generate_simulated_data(symbol, max_bars)
    
    def _generate_simulated_data(self, symbol: str, max_bars: int) -> List[Dict]:
        """G√©n√®re des donn√©es simul√©es pour un symbole"""
        try:
            # Prix de base selon le symbole
            base_price = 4500.0 if symbol == 'ES' else 15000.0
            
            simulated_data = []
            base_time = datetime.now().replace(second=0, microsecond=0)
            
            for i in range(max_bars):
                timestamp = base_time - timedelta(seconds=i * 15)
                
                # Prix avec variation
                price_variation = random.uniform(-5, 5)
                current_price = base_price + price_variation
                
                bar_data = {
                    'timestamp': timestamp.isoformat(),
                    'symbol': symbol,
                    'open': current_price + random.uniform(-2, 2),
                    'high': current_price + random.uniform(0, 3),
                    'low': current_price + random.uniform(-3, 0),
                    'close': current_price,
                    'volume': random.randint(500, 1500),
                    'price': current_price
                }
                
                simulated_data.append(bar_data)
            
            # Stocker pour r√©utilisation
            self.historical_data[symbol] = simulated_data
            
            logger.debug(f"üé≠ Donn√©es simul√©es g√©n√©r√©es pour {symbol}: {len(simulated_data)} barres")
            return simulated_data
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration donn√©es simul√©es {symbol}: {e}")
            return []
    
    def _save_to_disk(self, symbol: str, data: Dict, data_type: str) -> None:
        """Sauvegarde les donn√©es sur disque"""
        try:
            data_dir = Path("data") / data_type
            filename = f"{symbol}_{data_type}_{datetime.now().strftime('%Y%m%d')}.json"
            filepath = data_dir / filename
            
            # Charger donn√©es existantes ou cr√©er nouveau fichier
            existing_data = []
            if filepath.exists():
                try:
                    with open(filepath, 'r') as f:
                        existing_data = json.load(f)
                except Exception:
                    existing_data = []
            
            # Ajouter nouvelle donn√©e
            existing_data.append(data)
            
            # Sauvegarder
            with open(filepath, 'w') as f:
                json.dump(existing_data, f, indent=2)
            
            logger.debug(f"üíæ Donn√©es sauvegard√©es: {filepath}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde disque {symbol}: {e}")
    
    def get_latest_data(self, symbol: str) -> Optional[Dict]:
        """R√©cup√®re les derni√®res donn√©es pour un symbole"""
        try:
            # Priorit√© aux barres r√©centes
            if symbol in self.bar_data and self.bar_data[symbol]:
                return self.bar_data[symbol][-1]
            
            # Sinon donn√©es historiques
            if symbol in self.historical_data and self.historical_data[symbol]:
                return self.historical_data[symbol][-1]
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration derni√®res donn√©es {symbol}: {e}")
            return None
    
    def get_data_summary(self) -> Dict[str, Any]:
        """Retourne un r√©sum√© des donn√©es collect√©es"""
        try:
            summary = {
                'symbols_with_data': list(self.bar_data.keys()),
                'total_bar_data': sum(len(data) for data in self.bar_data.values()),
                'total_signal_data': sum(len(data) for data in self.signal_data.values()),
                'total_historical_data': sum(len(data) for data in self.historical_data.values()),
                'data_collector_keys': list(self.data_collector.keys())
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©sum√© donn√©es: {e}")
            return {}
    
    def clear_old_data(self, max_age_hours: int = 24) -> None:
        """Nettoie les anciennes donn√©es"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
            
            # Nettoyer bar_data
            for symbol in list(self.bar_data.keys()):
                self.bar_data[symbol] = [
                    bar for bar in self.bar_data[symbol]
                    if datetime.fromisoformat(bar['timestamp']) > cutoff_time
                ]
            
            # Nettoyer signal_data
            for symbol in list(self.signal_data.keys()):
                self.signal_data[symbol] = [
                    signal for signal in self.signal_data[symbol]
                    if datetime.fromisoformat(signal['timestamp']) > cutoff_time
                ]
            
            logger.info(f"üßπ Nettoyage donn√©es > {max_age_hours}h termin√©")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur nettoyage donn√©es: {e}")
    
    def reset_data(self) -> None:
        """Reset toutes les donn√©es"""
        try:
            self.data_collector.clear()
            self.signal_data.clear()
            self.bar_data.clear()
            self.historical_data.clear()
            
            logger.info("üîÑ Toutes les donn√©es reset√©es")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur reset donn√©es: {e}")

def create_data_collector_enhanced(config=None) -> DataCollectorEnhanced:
    """Factory pour cr√©er un DataCollectorEnhanced"""
    return DataCollectorEnhanced(config)

# =============================
# Extensions Sierra (live JSONL)
# =============================

async def _maybe_create_sierra_tail(collector: DataCollectorEnhanced, charts: Optional[List[int]] = None) -> Optional[SierraTail]:
    if not _SIERRA_AVAILABLE:
        logger.warning("SierraTail indisponible - _SIERRA_AVAILABLE=False")
        return None
    charts = charts or DEFAULT_CHARTS
    tail = SierraTail(charts=charts)
    await tail.start()
    return tail

async def _maybe_create_unified_writer(collector: DataCollectorEnhanced) -> Optional[UnifiedWriter]:
    if not _SIERRA_AVAILABLE:
        return None
    writer = await create_unified_writer()
    return writer

# Attache dynamiquement des m√©thodes sur la classe sans casser l'API existante
def _attach_sierra_methods():
    async def start_sierra_pipeline(self: DataCollectorEnhanced, charts: Optional[List[int]] = None, write_unified: bool = True):
        if not _SIERRA_AVAILABLE:
            logger.warning("Sierra pipeline non disponible (modules manquants)")
            return
        if self._sierra_running:
            return
        self.sierra_tail = await _maybe_create_sierra_tail(self, charts)
        if write_unified:
            self.unified_writer = await _maybe_create_unified_writer(self)
        self._sierra_running = True

        async def _loop():
            if self.sierra_tail is None:
                return
            async for ev in self.sierra_tail.events():
                try:
                    # Mettre √† jour VIX cache si graph 8
                    if ev.graph == 8 and ev.event_type in ("vix", "vix_diag"):
                        v = ev.raw_data.get('vix') or ev.raw_data.get('value')
                        if v is not None:
                            self._vix_cache['last_value'] = float(v)
                            self._vix_cache['last_ts'] = ev.ingest_ts.isoformat()

                    # Feeder MenthorQ si graph 10
                    if ev.graph == 10 and ev.event_type and ev.event_type.startswith("menthorq_"):
                        try:
                            # Lazy import pour √©viter d√©pendances dures
                            if self._menthorq_processor is None:
                                from features.menthorq_processor import MenthorQProcessor  # type: ignore
                                self._menthorq_processor = MenthorQProcessor()
                            line = json.dumps(ev.raw_data, ensure_ascii=False)
                            if hasattr(self._menthorq_processor, 'process_menthorq_line'):
                                self._menthorq_processor.process_menthorq_line(line)
                            elif hasattr(self._menthorq_processor, 'process_line'):
                                self._menthorq_processor.process_line(line)  # fallback
                        except Exception as me:
                            logger.warning(f"MenthorQ feed erreur: {me}")

                    # Router vers unified file
                    if self.unified_writer is not None:
                        try:
                            await self.unified_writer.route(ev)
                        except Exception as we:
                            logger.warning(f"UnifiedWriter erreur: {we}")

                    # Callbacks abonn√©s
                    if self._on_event_callbacks:
                        payload = dict(ev.raw_data)
                        payload['graph'] = ev.graph
                        payload['ingest_ts'] = ev.ingest_ts.isoformat()
                        for cb in list(self._on_event_callbacks):
                            try:
                                cb(payload)
                            except Exception as ce:
                                logger.warning(f"Callback erreur: {ce}")
                except Exception as e:
                    logger.error(f"Erreur boucle Sierra: {e}")

        self._sierra_task = asyncio.create_task(_loop())
        logger.info("Sierra pipeline d√©marr√©")

    async def stop_sierra_pipeline(self: DataCollectorEnhanced):
        if not self._sierra_running:
            return
        self._sierra_running = False
        try:
            if self.sierra_tail is not None:
                await self.sierra_tail.stop()
        except Exception:
            pass
        try:
            if self.unified_writer is not None:
                await self.unified_writer.close()
        except Exception:
            pass
        if self._sierra_task is not None:
            try:
                self._sierra_task.cancel()
            except Exception:
                pass
        logger.info("Sierra pipeline arr√™t√©")

    def register_event_callback(self: DataCollectorEnhanced, callback: Callable[[Dict[str, Any]], None]) -> None:
        """Permet au moteur de s'abonner aux √©v√©nements march√© unifi√©s."""
        self._on_event_callbacks.append(callback)

    def get_vix_cache(self: DataCollectorEnhanced) -> Dict[str, Any]:
        return dict(self._vix_cache)

    # Bind
    setattr(DataCollectorEnhanced, 'start_sierra_pipeline', start_sierra_pipeline)
    setattr(DataCollectorEnhanced, 'stop_sierra_pipeline', stop_sierra_pipeline)
    setattr(DataCollectorEnhanced, 'register_event_callback', register_event_callback)
    setattr(DataCollectorEnhanced, 'get_vix_cache', get_vix_cache)

_attach_sierra_methods()
