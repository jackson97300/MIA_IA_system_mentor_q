#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TEST COMPREHENSIF MENTHORQ FIRST METHOD
======================================

Test complet de la m√©thode MenthorQ First avec une batterie de donn√©es
de test couvrant tous les sc√©narios possibles.
"""

import sys
import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any

# Ajout du chemin du projet
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from test_data.menthorq_first_test_data import (
    MenthorQFirstTestData, TestData, TestScenario,
    get_test_data_by_scenario, get_test_data_by_expected_signal
)

def test_menthorq_first_comprehensive():
    """Test complet de la m√©thode MenthorQ First"""
    
    print("üéØ TEST COMPREHENSIF MENTHORQ FIRST METHOD")
    print("=" * 70)
    
    # === INITIALISATION ===
    try:
        from core.menthorq_first_method import MenthorQFirstMethod
        method = MenthorQFirstMethod()
        print("‚úÖ M√©thode MenthorQ First initialis√©e")
    except Exception as e:
        print(f"‚ùå Erreur initialisation: {e}")
        return False
    
    # === BATTERIE DE DONN√âES ===
    generator = MenthorQFirstTestData()
    all_scenarios = generator.get_all_test_scenarios()
    
    print(f"üìä Nombre de sc√©narios de test: {len(all_scenarios)}")
    print()
    
    # === R√âSULTATS ===
    results = {
        'total_tests': len(all_scenarios),
        'passed_tests': 0,
        'failed_tests': 0,
        'signal_accuracy': 0,
        'confidence_accuracy': 0,
        'scenario_results': []
    }
    
    # === EX√âCUTION DES TESTS ===
    for i, test_data in enumerate(all_scenarios, 1):
        print(f"üîç TEST {i:2d}/{len(all_scenarios)}: {test_data.scenario.value.upper()}")
        print(f"   Description: {test_data.description}")
        print(f"   Signal attendu: {test_data.expected_signal}")
        print(f"   Confiance attendue: {test_data.expected_confidence:.2f}")
        
        try:
            # Ex√©cution du test
            start_time = time.time()
            result = method.analyze_menthorq_first_opportunity(
                test_data.es_data, 
                test_data.nq_data
            )
            test_time = (time.time() - start_time) * 1000
            
            # Analyse des r√©sultats
            actual_signal = result.signal_type
            actual_confidence = result.confidence
            
            # V√©rification du signal
            signal_correct = actual_signal == test_data.expected_signal
            
            # V√©rification de la confiance (tol√©rance de ¬±0.1)
            confidence_tolerance = 0.1
            confidence_correct = abs(actual_confidence - test_data.expected_confidence) <= confidence_tolerance
            
            # Score global
            test_passed = signal_correct and confidence_correct
            
            if test_passed:
                results['passed_tests'] += 1
                status = "‚úÖ PASS√â"
            else:
                results['failed_tests'] += 1
                status = "‚ùå √âCHOU√â"
            
            # Mise √† jour des scores
            if signal_correct:
                results['signal_accuracy'] += 1
            if confidence_correct:
                results['confidence_accuracy'] += 1
            
            # Stockage des r√©sultats
            scenario_result = {
                'scenario': test_data.scenario.value,
                'expected_signal': test_data.expected_signal,
                'actual_signal': actual_signal,
                'expected_confidence': test_data.expected_confidence,
                'actual_confidence': actual_confidence,
                'signal_correct': signal_correct,
                'confidence_correct': confidence_correct,
                'test_passed': test_passed,
                'test_time_ms': test_time,
                'description': test_data.description
            }
            results['scenario_results'].append(scenario_result)
            
            # Affichage des r√©sultats
            print(f"   Signal obtenu: {actual_signal}")
            print(f"   Confiance obtenue: {actual_confidence:.3f}")
            print(f"   Temps: {test_time:.2f} ms")
            print(f"   R√©sultat: {status}")
            
            if not signal_correct:
                print(f"   ‚ö†Ô∏è Signal incorrect: attendu {test_data.expected_signal}, obtenu {actual_signal}")
            if not confidence_correct:
                print(f"   ‚ö†Ô∏è Confiance incorrecte: attendue {test_data.expected_confidence:.2f}, obtenue {actual_confidence:.3f}")
            
            print()
            
        except Exception as e:
            print(f"   ‚ùå Erreur lors du test: {e}")
            results['failed_tests'] += 1
            print()
    
    # === R√âSUM√â FINAL ===
    print("=" * 70)
    print("üìã R√âSUM√â FINAL")
    print("=" * 70)
    
    total_tests = results['total_tests']
    passed_tests = results['passed_tests']
    failed_tests = results['failed_tests']
    
    print(f"üìä Tests totaux: {total_tests}")
    print(f"‚úÖ Tests pass√©s: {passed_tests}")
    print(f"‚ùå Tests √©chou√©s: {failed_tests}")
    print(f"üìà Taux de r√©ussite: {(passed_tests/total_tests)*100:.1f}%")
    print()
    
    print(f"üéØ Pr√©cision des signaux: {(results['signal_accuracy']/total_tests)*100:.1f}%")
    print(f"üìä Pr√©cision de la confiance: {(results['confidence_accuracy']/total_tests)*100:.1f}%")
    print()
    
    # === ANALYSE PAR TYPE DE SIGNAL ===
    print("üìä ANALYSE PAR TYPE DE SIGNAL:")
    signal_types = ['LONG', 'SHORT', 'NO_SIGNAL']
    for signal_type in signal_types:
        scenarios = get_test_data_by_expected_signal(signal_type)
        if scenarios:
            passed_count = sum(1 for r in results['scenario_results'] 
                             if r['expected_signal'] == signal_type and r['test_passed'])
            total_count = len(scenarios)
            accuracy = (passed_count/total_count)*100 if total_count > 0 else 0
            print(f"   {signal_type:10}: {passed_count:2d}/{total_count:2d} ({accuracy:5.1f}%)")
    print()
    
    # === ANALYSE PAR SC√âNARIO ===
    print("üìä ANALYSE PAR SC√âNARIO:")
    for result in results['scenario_results']:
        status = "‚úÖ" if result['test_passed'] else "‚ùå"
        print(f"   {status} {result['scenario']:25} | {result['expected_signal']:10} | {result['actual_signal']:10} | {result['actual_confidence']:.3f}")
    print()
    
    # === RECOMMANDATIONS ===
    print("üí° RECOMMANDATIONS:")
    
    if results['passed_tests'] == total_tests:
        print("   üéâ TOUS LES TESTS SONT PASS√âS !")
        print("   ‚úÖ La m√©thode MenthorQ First est pr√™te pour la production")
    elif results['passed_tests'] >= total_tests * 0.8:
        print("   ‚úÖ La m√©thode fonctionne bien (‚â•80% de r√©ussite)")
        print("   üîß Quelques ajustements mineurs recommand√©s")
    elif results['passed_tests'] >= total_tests * 0.6:
        print("   ‚ö†Ô∏è La m√©thode fonctionne partiellement (‚â•60% de r√©ussite)")
        print("   üîß Des ajustements significatifs sont n√©cessaires")
    else:
        print("   ‚ùå La m√©thode a des probl√®mes majeurs (<60% de r√©ussite)")
        print("   üö® Une refonte est recommand√©e")
    
    # === EXPORT DES R√âSULTATS ===
    export_results(results)
    
    return results['passed_tests'] >= total_tests * 0.8

def export_results(results: Dict[str, Any]):
    """Exporte les r√©sultats vers un fichier JSON"""
    try:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"test_results/menthorq_first_test_results_{timestamp}.json"
        
        # Cr√©er le dossier si n√©cessaire
        os.makedirs("test_results", exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"üìÅ R√©sultats export√©s vers: {filename}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur export des r√©sultats: {e}")

def test_specific_scenarios():
    """Test de sc√©narios sp√©cifiques"""
    
    print("\nüéØ TEST DE SC√âNARIOS SP√âCIFIQUES")
    print("=" * 50)
    
    # Test du sc√©nario bullish breakout
    try:
        test_data = get_test_data_by_scenario(TestScenario.BULLISH_BREAKOUT)
        print(f"üìä Test du sc√©nario: {test_data.scenario.value}")
        print(f"   Description: {test_data.description}")
        print(f"   Signal attendu: {test_data.expected_signal}")
        print(f"   Confiance attendue: {test_data.expected_confidence:.2f}")
        
        from core.menthorq_first_method import MenthorQFirstMethod
        method = MenthorQFirstMethod()
        
        result = method.analyze_menthorq_first_opportunity(
            test_data.es_data, 
            test_data.nq_data
        )
        
        print(f"   Signal obtenu: {result.signal_type}")
        print(f"   Confiance obtenue: {result.confidence:.3f}")
        print(f"   Score MenthorQ: {result.menthorq_score:.3f}")
        print(f"   Score Orderflow: {result.orderflow_score:.3f}")
        print(f"   Score Structure: {result.structure_score:.3f}")
        print(f"   Score Final: {result.final_score:.3f}")
        
        if result.audit_data:
            print(f"   Audit Data: {len(result.audit_data)} √©l√©ments")
        
        print()
        
    except Exception as e:
        print(f"‚ùå Erreur test sc√©nario sp√©cifique: {e}")

def main():
    """Fonction principale"""
    
    print("üöÄ LANCEMENT DU TEST COMPREHENSIF MENTHORQ FIRST")
    print("=" * 70)
    
    # Test principal
    success = test_menthorq_first_comprehensive()
    
    # Test de sc√©narios sp√©cifiques
    test_specific_scenarios()
    
    print("=" * 70)
    if success:
        print("üéâ TEST COMPREHENSIF TERMIN√â AVEC SUCC√àS !")
    else:
        print("‚ö†Ô∏è TEST COMPREHENSIF TERMIN√â AVEC DES PROBL√àMES")
    print("=" * 70)
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
