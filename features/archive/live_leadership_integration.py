#!/usr/bin/env python3
"""
üîó LIVE LEADERSHIP INTEGRATION - MIA_IA_SYSTEM
Int√©gration temps r√©el du syst√®me de leadership avec les flux de march√©
- Connexion IBKR + Sierra en temps r√©el
- Injection du ConfluenceIntegrator dans le pipeline
- Monitoring des d√©cisions live
- Validation de la logique Fort/Faible
- Logging structur√© pour audit
"""

import sys
import time
import asyncio
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass
from collections import deque

# Ajouter le chemin du projet
sys.path.append(str(Path(__file__).parent.parent))

from core.logger import get_logger
from features.confluence_integrator import ConfluenceIntegrator, ConfluenceResult
from features.market_state_analyzer import MarketState
from features.leadership_engine import LeadershipResult

logger = get_logger(__name__)

@dataclass
class LiveMarketData:
    """Donn√©es de march√© en temps r√©el"""
    timestamp: datetime
    es_data: Dict[str, Any]  # Donn√©es ES depuis IBKR/Sierra
    nq_data: Dict[str, Any]  # Donn√©es NQ depuis IBKR/Sierra
    bias: str                # Biais actuel ('bullish', 'bearish', 'neutral')
    instrument: str          # Instrument cible ('ES', 'NQ')
    gamma_levels: Optional[List[float]] = None
    vwap: Optional[float] = None
    additional_signals: Optional[Dict[str, float]] = None

@dataclass
class LiveDecision:
    """D√©cision de trading en temps r√©el"""
    timestamp: datetime
    market_data: LiveMarketData
    confluence_result: ConfluenceResult
    execution_latency_ms: float
    decision_id: str

class LiveLeadershipIntegration:
    """Int√©gration temps r√©el du syst√®me de leadership"""
    
    def __init__(self, 
                 ibkr_connector=None,
                 sierra_connector=None,
                 decision_callback: Optional[Callable[[LiveDecision], None]] = None):
        """
        Initialise l'int√©gration temps r√©el
        
        Args:
            ibkr_connector: Connecteur IBKR (√† impl√©menter)
            sierra_connector: Connecteur Sierra (√† impl√©menter)
            decision_callback: Callback appel√© √† chaque d√©cision
        """
        self.ibkr_connector = ibkr_connector
        self.sierra_connector = sierra_connector
        self.decision_callback = decision_callback
        
        # PATCH: Int√©grateur avec calibration YAML
        self.integrator = ConfluenceIntegrator()
        
        # Monitoring temps r√©el
        self.decision_history = deque(maxlen=1000)
        self.start_time = datetime.now()
        self.decision_count = 0
        self.valid_decisions = 0
        self.rejected_decisions = 0
        
        # Configuration monitoring
        self.monitoring_interval = 60  # secondes
        self.last_monitoring = datetime.now()
        
        logger.info("üîó LiveLeadershipIntegration initialis√©")
        logger.info(f"  üìä Monitoring interval: {self.monitoring_interval}s")
        logger.info(f"  üìà Decision history size: {self.decision_history.maxlen}")
    
    async def start_live_integration(self, 
                                   symbols: List[str] = ['ES', 'NQ'],
                                   update_interval_ms: int = 1000):
        """
        D√©marre l'int√©gration temps r√©el
        
        Args:
            symbols: Symboles √† monitorer
            update_interval_ms: Intervalle de mise √† jour en ms
        """
        logger.info(f"üöÄ D√©marrage int√©gration temps r√©el")
        logger.info(f"  üìä Symboles: {symboles}")
        logger.info(f"  ‚è±Ô∏è Intervalle: {update_interval_ms}ms")
        
        try:
            # Connexion aux flux de donn√©es
            await self._connect_data_sources(symbols)
            
            # Boucle principale d'int√©gration
            cycle_count = 0
            logger.info("üîÑ D√©but de la boucle principale...")
            
            while True:
                start_time = time.time()
                cycle_count += 1
                
                logger.info(f"üîÑ Cycle {cycle_count} - R√©cup√©ration donn√©es...")
                
                # 1. R√©cup√©rer les donn√©es temps r√©el
                market_data = await self._fetch_live_market_data(symbols)
                
                if market_data:
                    logger.info(f"üìä Donn√©es re√ßues: {market_data.bias} {market_data.instrument}")
                    
                    # 2. Calculer la confluence avec leadership
                    decision = await self._process_market_data(market_data)
                    
                    # 3. Appliquer la d√©cision
                    if decision:
                        await self._apply_decision(decision)
                else:
                    logger.warning("‚ö†Ô∏è Aucune donn√©e de march√© re√ßue")
                
                # 4. Monitoring p√©riodique
                await self._periodic_monitoring()
                
                # 5. Contr√¥le de latence
                elapsed_ms = (time.time() - start_time) * 1000
                if elapsed_ms > update_interval_ms:
                    logger.warning(f"‚ö†Ô∏è Latence √©lev√©e: {elapsed_ms:.1f}ms > {update_interval_ms}ms")
                
                # 6. Attendre le prochain cycle
                sleep_time = max(0.001, (update_interval_ms - elapsed_ms) / 1000)
                logger.info(f"‚è±Ô∏è Attente {sleep_time:.3f}s avant prochain cycle")
                await asyncio.sleep(sleep_time)
                
        except KeyboardInterrupt:
            logger.info("üõë Arr√™t demand√© par l'utilisateur")
        except Exception as e:
            logger.error(f"‚ùå Erreur int√©gration temps r√©el: {e}")
            import traceback
            logger.error(f"üìã Traceback: {traceback.format_exc()}")
        finally:
            await self._cleanup()
    
    async def _connect_data_sources(self, symbols: List[str]):
        """Connecte aux sources de donn√©es temps r√©el"""
        logger.info("üîå Connexion aux sources de donn√©es...")
        
        # TODO: Impl√©menter la connexion IBKR
        if self.ibkr_connector:
            try:
                # await self.ibkr_connector.connect()
                logger.info("‚úÖ Connexion IBKR √©tablie")
            except Exception as e:
                logger.error(f"‚ùå Erreur connexion IBKR: {e}")
        
        # TODO: Impl√©menter la connexion Sierra
        if self.sierra_connector:
            try:
                # await self.sierra_connector.connect()
                logger.info("‚úÖ Connexion Sierra √©tablie")
            except Exception as e:
                logger.error(f"‚ùå Erreur connexion Sierra: {e}")
        
        logger.info("üîå Connexions √©tablies")
    
    async def _fetch_live_market_data(self, symbols: List[str]) -> Optional[LiveMarketData]:
        """R√©cup√®re les donn√©es de march√© temps r√©el"""
        try:
            # TODO: Remplacer par les vraies donn√©es IBKR/Sierra
            # Pour l'instant, simulation avec donn√©es de test
            now = datetime.now()
            
            # Simulation donn√©es ES
            es_data = {
                'close': 6397.5 + (now.second % 60) * 0.1,
                'volume': 1000 + (now.second % 30) * 10,
                'bid': 6397.0,
                'ask': 6398.0,
                'timestamp': now
            }
            
            # Simulation donn√©es NQ
            nq_data = {
                'close': 23246.0 + (now.second % 60) * 0.2,
                'volume': 800 + (now.second % 30) * 8,
                'bid': 23245.5,
                'ask': 23246.5,
                'timestamp': now
            }
            
            # Simulation biais et instrument (rotation pour test)
            bias_cycle = ['bullish', 'bearish', 'neutral']
            instrument_cycle = ['ES', 'NQ']
            
            bias = bias_cycle[(now.second // 20) % len(bias_cycle)]
            instrument = instrument_cycle[(now.second // 15) % len(instrument_cycle)]
            
            return LiveMarketData(
                timestamp=now,
                es_data=es_data,
                nq_data=nq_data,
                bias=bias,
                instrument=instrument,
                gamma_levels=[6400, 6450, 6500],
                vwap=6398.0,
                additional_signals={
                    'gamma_proximity': 0.7,
                    'volume_confirmation': 0.8,
                    'vwap_trend': 0.6,
                    'options_flow': 0.5,
                    'order_book_imbalance': 0.4
                }
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration donn√©es temps r√©el: {e}")
            return None
    
    async def _process_market_data(self, market_data: LiveMarketData) -> Optional[LiveDecision]:
        """Traite les donn√©es de march√© et g√©n√®re une d√©cision"""
        try:
            start_time = time.time()
            
            # Convertir les donn√©es en format attendu par l'int√©grateur
            processed_data = self._convert_to_integrator_format(market_data)
            
            # Calculer la confluence avec leadership
            confluence_result = self.integrator.calculate_confluence_with_leadership(processed_data)
            
            # Calculer la latence
            execution_latency_ms = (time.time() - start_time) * 1000
            
            # Cr√©er la d√©cision
            decision = LiveDecision(
                timestamp=market_data.timestamp,
                market_data=market_data,
                confluence_result=confluence_result,
                execution_latency_ms=execution_latency_ms,
                decision_id=f"DEC_{self.decision_count:06d}"
            )
            
            # Mettre √† jour les statistiques
            self.decision_count += 1
            if confluence_result.is_valid:
                self.valid_decisions += 1
            else:
                self.rejected_decisions += 1
            
            # Ajouter √† l'historique
            self.decision_history.append(decision)
            
            # Logging de la d√©cision
            self._log_live_decision(decision)
            
            return decision
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement donn√©es march√©: {e}")
            return None
    
    def _convert_to_integrator_format(self, market_data: LiveMarketData) -> Dict[str, Any]:
        """Convertit les donn√©es temps r√©el au format attendu par l'int√©grateur"""
        import pandas as pd
        
        # Cr√©er des DataFrames simul√©es (√† remplacer par vraies donn√©es)
        dates = pd.date_range(market_data.timestamp - timedelta(minutes=100), 
                             market_data.timestamp, freq='1min')
        
        # ES DataFrame
        es_df = pd.DataFrame({
            'close': [market_data.es_data['close'] - i*0.1 for i in range(len(dates))],
            'volume': [market_data.es_data['volume'] - i*5 for i in range(len(dates))],
            'buy_volume': [market_data.es_data['volume']*0.6 - i*3 for i in range(len(dates))],
            'sell_volume': [market_data.es_data['volume']*0.4 - i*2 for i in range(len(dates))]
        }, index=dates)
        
        # NQ DataFrame
        nq_df = pd.DataFrame({
            'close': [market_data.nq_data['close'] - i*0.2 for i in range(len(dates))],
            'volume': [market_data.nq_data['volume'] - i*4 for i in range(len(dates))],
            'buy_volume': [market_data.nq_data['volume']*0.6 - i*2.4 for i in range(len(dates))],
            'sell_volume': [market_data.nq_data['volume']*0.4 - i*1.6 for i in range(len(dates))]
        }, index=dates)
        
        return {
            'ES': es_df,
            'NQ': nq_df,
            'bias': market_data.bias,
            'symbol': market_data.instrument,
            'now': market_data.timestamp,
            'gamma_levels': market_data.gamma_levels,
            'vwap': market_data.vwap,
            **market_data.additional_signals
        }
    
    async def _apply_decision(self, decision: LiveDecision):
        """Applique la d√©cision de trading"""
        try:
            if decision.confluence_result.is_valid:
                logger.info(f"üéØ EX√âCUTION: {decision.decision_id}")
                logger.info(f"  üìä Score final: {decision.confluence_result.final_score:.3f}")
                logger.info(f"  üéØ Instrument: {decision.market_data.instrument}")
                logger.info(f"  üìà Biais: {decision.market_data.bias}")
                
                # TODO: Impl√©menter l'ex√©cution r√©elle
                # await self._execute_trade(decision)
                
            else:
                logger.info(f"‚ùå REJET: {decision.decision_id}")
                logger.info(f"  üìù Raison: {decision.confluence_result.reason}")
            
            # Appeler le callback si d√©fini
            if self.decision_callback:
                await self.decision_callback(decision)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur application d√©cision: {e}")
    
    def _log_live_decision(self, decision: LiveDecision):
        """Log une d√©cision temps r√©el"""
        try:
            result = decision.confluence_result
            market_data = decision.market_data
            
            status = "‚úÖ VALID" if result.is_valid else "‚ùå REJECT"
            
            logger.info(f"{status} | {decision.decision_id} | Latency: {decision.execution_latency_ms:.1f}ms")
            logger.info(f"  üìä Bias: {market_data.bias} | Instrument: {market_data.instrument}")
            logger.info(f"  üéØ Leader: {result.leadership_result.leader} | Force: {result.leadership_result.strength:.3f}")
            logger.info(f"  üîó Corr: {result.market_state.corr_15m:.3f} ({result.market_state.corr_regime})")
            logger.info(f"  üí∞ Final Score: {result.final_score:.3f} | Risk Mult: {result.risk_multiplier:.3f}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur logging d√©cision live: {e}")
    
    async def _periodic_monitoring(self):
        """Monitoring p√©riodique du syst√®me"""
        now = datetime.now()
        if (now - self.last_monitoring).total_seconds() >= self.monitoring_interval:
            self._log_monitoring_stats()
            self.last_monitoring = now
    
    def _log_monitoring_stats(self):
        """Log les statistiques de monitoring"""
        try:
            uptime = (datetime.now() - self.start_time).total_seconds()
            valid_rate = self.valid_decisions / max(self.decision_count, 1)
            reject_rate = self.rejected_decisions / max(self.decision_count, 1)
            
            # Statistiques de l'int√©grateur
            integrator_stats = self.integrator.get_statistics()
            
            logger.info("üìä MONITORING STATS:")
            logger.info(f"  ‚è±Ô∏è Uptime: {uptime:.0f}s")
            logger.info(f"  üìà Total decisions: {self.decision_count}")
            logger.info(f"  ‚úÖ Valid rate: {valid_rate:.1%}")
            logger.info(f"  ‚ùå Reject rate: {reject_rate:.1%}")
            logger.info(f"  üîó Leadership pass rate: {integrator_stats['leadership_stats']['pass_rate']:.1%}")
            logger.info(f"  ‚ö° Latency exceeded: {integrator_stats['latency_exceeded_rate']:.1%}")
            
            # Derni√®res d√©cisions
            if self.decision_history:
                recent_decisions = list(self.decision_history)[-5:]
                logger.info("üìú R√âCENTES D√âCISIONS:")
                for decision in recent_decisions:
                    status = "‚úÖ" if decision.confluence_result.is_valid else "‚ùå"
                    logger.info(f"  {status} {decision.decision_id}: {decision.confluence_result.final_score:.3f}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur monitoring stats: {e}")
    
    async def _cleanup(self):
        """Nettoyage √† la fin"""
        logger.info("üßπ Nettoyage int√©gration temps r√©el...")
        
        # TODO: Fermer les connexions
        if self.ibkr_connector:
            # await self.ibkr_connector.disconnect()
            pass
        
        if self.sierra_connector:
            # await self.sierra_connector.disconnect()
            pass
        
        logger.info("‚úÖ Nettoyage termin√©")
    
    def get_live_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques temps r√©el"""
        return {
            'uptime_seconds': (datetime.now() - self.start_time).total_seconds(),
            'decision_count': self.decision_count,
            'valid_decisions': self.valid_decisions,
            'rejected_decisions': self.rejected_decisions,
            'valid_rate': self.valid_decisions / max(self.decision_count, 1),
            'reject_rate': self.rejected_decisions / max(self.decision_count, 1),
            'integrator_stats': self.integrator.get_statistics(),
            'recent_decisions': list(self.decision_history)[-10:]
        }

async def test_live_integration():
    """Test de l'int√©gration temps r√©el"""
    logger.info("üßÆ TEST LIVE LEADERSHIP INTEGRATION")
    logger.info("=" * 50)
    
    # Initialiser l'int√©gration
    integration = LiveLeadershipIntegration()
    
    # Callback pour les d√©cisions
    async def decision_callback(decision: LiveDecision):
        logger.info(f"üîî CALLBACK: D√©cision {decision.decision_id} re√ßue")
    
    integration.decision_callback = decision_callback
    
    # D√©marrer l'int√©gration (simulation 30 secondes)
    logger.info("üöÄ D√©marrage simulation 30 secondes...")
    
    try:
        # Lancer l'int√©gration en arri√®re-plan
        task = asyncio.create_task(
            integration.start_live_integration(update_interval_ms=2000)
        )
        
        # Attendre 30 secondes
        await asyncio.sleep(30)
        
        # Annuler la t√¢che
        task.cancel()
        
    except asyncio.CancelledError:
        logger.info("‚úÖ Simulation termin√©e")
    
    # Statistiques finales
    stats = integration.get_live_statistics()
    logger.info("\nüìã STATISTIQUES FINALES:")
    logger.info(f"  ‚è±Ô∏è Uptime: {stats['uptime_seconds']:.0f}s")
    logger.info(f"  üìà Total decisions: {stats['decision_count']}")
    logger.info(f"  ‚úÖ Valid rate: {stats['valid_rate']:.1%}")
    logger.info(f"  ‚ùå Reject rate: {stats['reject_rate']:.1%}")

if __name__ == "__main__":
    asyncio.run(test_live_integration())
