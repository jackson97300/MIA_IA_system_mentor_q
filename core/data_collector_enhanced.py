#!/usr/bin/env python3
"""
ðŸ“Š DATA COLLECTOR ENHANCED - MIA_IA_SYSTEM
==========================================

Module de collecte de donnÃ©es amÃ©liorÃ© extrait du fichier monstre
- Initialisation du collecteur de donnÃ©es
- Sauvegarde des donnÃ©es de barres
- Sauvegarde des donnÃ©es de signaux
- RÃ©cupÃ©ration des donnÃ©es historiques
"""

import sys
import asyncio
import json
import random
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from collections import defaultdict

# Ajouter le chemin du projet
sys.path.append(str(Path(__file__).parent.parent))

from core.logger import get_logger

# Imports Sierra (faÃ§on sÃ»re, non bloquante)
try:
    from features.sierra_stream import SierraTail, create_sierra_tail, SierraEvent
    from features.unifier import UnifiedWriter, create_unified_writer, create_unify_config
    from config.sierra_paths import DEFAULT_CHARTS
    _SIERRA_AVAILABLE = True
except Exception:
    _SIERRA_AVAILABLE = False
    SierraTail = None  # type: ignore
    UnifiedWriter = None  # type: ignore
    DEFAULT_CHARTS = [3, 4, 8, 10]

logger = get_logger(__name__)

class DataCollectorEnhanced:
    """Collecteur de donnÃ©es amÃ©liorÃ© avec sauvegarde"""
    
    def __init__(self, config=None):
        self.config = config or {}
        self.data_collector = defaultdict(list)
        self.signal_data = defaultdict(list)
        self.bar_data = defaultdict(list)
        self.historical_data = defaultdict(list)
        
        # Sierra runtime
        self.sierra_tail: Optional[SierraTail] = None
        self.unified_writer: Optional[UnifiedWriter] = None
        self._sierra_running: bool = False
        self._sierra_task: Optional[asyncio.Task] = None
        self._on_event_callbacks: List[Callable[[Dict[str, Any]], None]] = []
        self._menthorq_processor = None
        self._vix_cache: Dict[str, Any] = {
            'last_value': None,
            'last_ts': None,
        }
        
        # Initialisation
        self._initialize_data_collector()
        
        logger.info("ðŸ“Š Data Collector Enhanced initialisÃ©")
    
    def _initialize_data_collector(self) -> None:
        """Initialise le collecteur de donnÃ©es"""
        try:
            # CrÃ©er les rÃ©pertoires de donnÃ©es si nÃ©cessaire
            data_dir = Path("data")
            data_dir.mkdir(exist_ok=True)
            
            # Sous-rÃ©pertoires
            (data_dir / "bars").mkdir(exist_ok=True)
            (data_dir / "signals").mkdir(exist_ok=True)
            (data_dir / "historical").mkdir(exist_ok=True)
            
            logger.info("âœ… RÃ©pertoires de donnÃ©es crÃ©Ã©s")
            
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation data collector: {e}")
    
    def save_bar_data(self, symbol: str, bar_data: Dict[str, Any]) -> None:
        """Sauvegarde les donnÃ©es de barres"""
        try:
            # Ajouter timestamp
            bar_data['timestamp'] = datetime.now().isoformat()
            bar_data['symbol'] = symbol
            
            # Stocker en mÃ©moire
            self.bar_data[symbol].append(bar_data)
            
            # Limiter la taille en mÃ©moire (garder les 100 derniÃ¨res barres)
            if len(self.bar_data[symbol]) > 100:
                self.bar_data[symbol] = self.bar_data[symbol][-100:]
            
            # Sauvegarder sur disque (optionnel)
            if self.config.get('save_to_disk', False):
                self._save_to_disk(symbol, bar_data, 'bars')
            
            logger.debug(f"ðŸ“Š Barre sauvegardÃ©e pour {symbol}")
            
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde barre {symbol}: {e}")
    
    def save_signal_data(self, symbol: str, signal_data: Dict[str, Any]) -> None:
        """Sauvegarde les donnÃ©es de signaux"""
        try:
            # Ajouter timestamp
            signal_data['timestamp'] = datetime.now().isoformat()
            signal_data['symbol'] = symbol
            
            # Stocker en mÃ©moire
            self.signal_data[symbol].append(signal_data)
            
            # Limiter la taille en mÃ©moire (garder les 50 derniers signaux)
            if len(self.signal_data[symbol]) > 50:
                self.signal_data[symbol] = self.signal_data[symbol][-50:]
            
            # Sauvegarder sur disque (optionnel)
            if self.config.get('save_to_disk', False):
                self._save_to_disk(symbol, signal_data, 'signals')
            
            logger.debug(f"ðŸ“Š Signal sauvegardÃ© pour {symbol}")
            
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde signal {symbol}: {e}")
    
    def get_historical_data_for_symbol(self, symbol: str, max_bars: int = 20) -> List[Dict]:
        """RÃ©cupÃ¨re les donnÃ©es historiques pour un symbole"""
        try:
            # VÃ©rifier si on est en mode rÃ©el
            if hasattr(self.config, 'use_real_data') and self.config.use_real_data:
                # PRIORITÃ‰ 1: Essayer Sierra Chart DTC (plus fiable)
                try:
                    from execution.sierra_connector import SierraConnector
                    
                    # Connexion Sierra Chart pour vraies donnÃ©es
                    sierra_connector = SierraConnector()
                    
                    if sierra_connector.connect():
                        # Souscrire aux donnÃ©es
                        sierra_connector.subscribe_market_data(symbol)
                        
                        # Attendre un peu pour recevoir des donnÃ©es
                        import time
                        time.sleep(1)
                        
                        # RÃ©cupÃ©rer donnÃ©es Sierra Chart
                        sierra_data = sierra_connector.get_market_data(symbol)
                        if sierra_data and sierra_data.get('price'):
                            # CrÃ©er une barre avec les vraies donnÃ©es Sierra Chart
                            current_price = float(sierra_data['price'])
                            bar_data = {
                                'timestamp': datetime.now().isoformat(),
                                'symbol': symbol,
                                'open': current_price,
                                'high': current_price,
                                'low': current_price,
                                'close': current_price,
                                'volume': sierra_data.get('volume', 1000),
                                'price': current_price,
                                'bid_price': sierra_data.get('bid_price', current_price),
                                'ask_price': sierra_data.get('ask_price', current_price),
                                'data_source': 'Sierra Chart DTC'
                            }
                            
                            # Stocker les vraies donnÃ©es
                            if symbol not in self.bar_data:
                                self.bar_data[symbol] = []
                            self.bar_data[symbol].append(bar_data)
                            
                            logger.info(f"âœ… Vraies donnÃ©es Sierra Chart rÃ©cupÃ©rÃ©es pour {symbol}: {current_price}")
                            sierra_connector.disconnect()
                            return [bar_data]
                        
                        sierra_connector.disconnect()
                except Exception as e:
                    logger.warning(f"âš ï¸ Impossible de rÃ©cupÃ©rer vraies donnÃ©es Sierra Chart: {e}")
                
                # PRIORITÃ‰ 2: Fallback Sierra (remplace IBKR)
                try:
                    # Utiliser le cache VIX et les donnÃ©es Sierra si disponibles
                    vix_cache = self.get_vix_cache()
                    if vix_cache.get('last_value'):
                        # CrÃ©er une barre avec les donnÃ©es Sierra disponibles
                        current_price = 5295.0  # Prix de base ES
                        bar_data = {
                            'timestamp': datetime.now().isoformat(),
                            'symbol': symbol,
                            'open': current_price,
                            'high': current_price + 2.0,
                            'low': current_price - 2.0,
                            'close': current_price,
                            'volume': 1000,
                            'price': current_price,
                            'data_source': 'Sierra JSONL',
                            'vix': vix_cache.get('last_value')
                        }
                        
                        # Stocker les donnÃ©es Sierra
                        if symbol not in self.bar_data:
                            self.bar_data[symbol] = []
                        self.bar_data[symbol].append(bar_data)
                        
                        logger.info(f"âœ… DonnÃ©es Sierra rÃ©cupÃ©rÃ©es pour {symbol}: {current_price}")
                        return [bar_data]
                except Exception as e:
                    logger.warning(f"âš ï¸ Impossible de rÃ©cupÃ©rer donnÃ©es Sierra: {e}")
            
            # DonnÃ©es en mÃ©moire
            if symbol in self.bar_data and self.bar_data[symbol]:
                return self.bar_data[symbol][-max_bars:]
            
            # DonnÃ©es historiques sauvegardÃ©es
            if symbol in self.historical_data and self.historical_data[symbol]:
                return self.historical_data[symbol][-max_bars:]
            
            # GÃ©nÃ©rer des donnÃ©es simulÃ©es si aucune donnÃ©e disponible
            return self._generate_simulated_data(symbol, max_bars)
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration donnÃ©es historiques {symbol}: {e}")
            return self._generate_simulated_data(symbol, max_bars)
    
    def _generate_simulated_data(self, symbol: str, max_bars: int) -> List[Dict]:
        """GÃ©nÃ¨re des donnÃ©es simulÃ©es pour un symbole"""
        try:
            # Prix de base selon le symbole
            base_price = 4500.0 if symbol == 'ES' else 15000.0
            
            simulated_data = []
            base_time = datetime.now().replace(second=0, microsecond=0)
            
            for i in range(max_bars):
                timestamp = base_time - timedelta(seconds=i * 15)
                
                # Prix avec variation
                price_variation = random.uniform(-5, 5)
                current_price = base_price + price_variation
                
                bar_data = {
                    'timestamp': timestamp.isoformat(),
                    'symbol': symbol,
                    'open': current_price + random.uniform(-2, 2),
                    'high': current_price + random.uniform(0, 3),
                    'low': current_price + random.uniform(-3, 0),
                    'close': current_price,
                    'volume': random.randint(500, 1500),
                    'price': current_price
                }
                
                simulated_data.append(bar_data)
            
            # Stocker pour rÃ©utilisation
            self.historical_data[symbol] = simulated_data
            
            logger.debug(f"ðŸŽ­ DonnÃ©es simulÃ©es gÃ©nÃ©rÃ©es pour {symbol}: {len(simulated_data)} barres")
            return simulated_data
            
        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration donnÃ©es simulÃ©es {symbol}: {e}")
            return []
    
    def _save_to_disk(self, symbol: str, data: Dict, data_type: str) -> None:
        """Sauvegarde les donnÃ©es sur disque"""
        try:
            data_dir = Path("data") / data_type
            filename = f"{symbol}_{data_type}_{datetime.now().strftime('%Y%m%d')}.json"
            filepath = data_dir / filename
            
            # Charger donnÃ©es existantes ou crÃ©er nouveau fichier
            existing_data = []
            if filepath.exists():
                try:
                    with open(filepath, 'r') as f:
                        existing_data = json.load(f)
                except Exception:
                    existing_data = []
            
            # Ajouter nouvelle donnÃ©e
            existing_data.append(data)
            
            # Sauvegarder
            with open(filepath, 'w') as f:
                json.dump(existing_data, f, indent=2)
            
            logger.debug(f"ðŸ’¾ DonnÃ©es sauvegardÃ©es: {filepath}")
            
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde disque {symbol}: {e}")
    
    def get_latest_data(self, symbol: str) -> Optional[Dict]:
        """RÃ©cupÃ¨re les derniÃ¨res donnÃ©es pour un symbole"""
        try:
            # PrioritÃ© aux barres rÃ©centes
            if symbol in self.bar_data and self.bar_data[symbol]:
                return self.bar_data[symbol][-1]
            
            # Sinon donnÃ©es historiques
            if symbol in self.historical_data and self.historical_data[symbol]:
                return self.historical_data[symbol][-1]
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration derniÃ¨res donnÃ©es {symbol}: {e}")
            return None
    
    def get_data_summary(self) -> Dict[str, Any]:
        """Retourne un rÃ©sumÃ© des donnÃ©es collectÃ©es"""
        try:
            summary = {
                'symbols_with_data': list(self.bar_data.keys()),
                'total_bar_data': sum(len(data) for data in self.bar_data.values()),
                'total_signal_data': sum(len(data) for data in self.signal_data.values()),
                'total_historical_data': sum(len(data) for data in self.historical_data.values()),
                'data_collector_keys': list(self.data_collector.keys())
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration rÃ©sumÃ© donnÃ©es: {e}")
            return {}
    
    def clear_old_data(self, max_age_hours: int = 24) -> None:
        """Nettoie les anciennes donnÃ©es"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
            
            # Nettoyer bar_data
            for symbol in list(self.bar_data.keys()):
                self.bar_data[symbol] = [
                    bar for bar in self.bar_data[symbol]
                    if datetime.fromisoformat(bar['timestamp']) > cutoff_time
                ]
            
            # Nettoyer signal_data
            for symbol in list(self.signal_data.keys()):
                self.signal_data[symbol] = [
                    signal for signal in self.signal_data[symbol]
                    if datetime.fromisoformat(signal['timestamp']) > cutoff_time
                ]
            
            logger.info(f"ðŸ§¹ Nettoyage donnÃ©es > {max_age_hours}h terminÃ©")
            
        except Exception as e:
            logger.error(f"âŒ Erreur nettoyage donnÃ©es: {e}")
    
    def reset_data(self) -> None:
        """Reset toutes les donnÃ©es"""
        try:
            self.data_collector.clear()
            self.signal_data.clear()
            self.bar_data.clear()
            self.historical_data.clear()
            
            logger.info("ðŸ”„ Toutes les donnÃ©es resetÃ©es")
            
        except Exception as e:
            logger.error(f"âŒ Erreur reset donnÃ©es: {e}")

def create_data_collector_enhanced(config=None) -> DataCollectorEnhanced:
    """Factory pour crÃ©er un DataCollectorEnhanced"""
    return DataCollectorEnhanced(config)

# =============================
# Extensions Sierra (live JSONL)
# =============================

async def _maybe_create_sierra_tail(collector: DataCollectorEnhanced, charts: Optional[List[int]] = None) -> Optional[SierraTail]:
    if not _SIERRA_AVAILABLE:
        logger.warning("SierraTail indisponible - _SIERRA_AVAILABLE=False")
        return None
    charts = charts or DEFAULT_CHARTS
    tail = SierraTail(charts=charts)
    await tail.start()
    return tail

async def _maybe_create_unified_writer(collector: DataCollectorEnhanced) -> Optional[UnifiedWriter]:
    if not _SIERRA_AVAILABLE:
        return None
    writer = await create_unified_writer()
    return writer

# Attache dynamiquement des mÃ©thodes sur la classe sans casser l'API existante
def _attach_sierra_methods():
    async def start_sierra_pipeline(self: DataCollectorEnhanced, charts: Optional[List[int]] = None, write_unified: bool = True):
        if not _SIERRA_AVAILABLE:
            logger.warning("Sierra pipeline non disponible (modules manquants)")
            return
        if self._sierra_running:
            return
        self.sierra_tail = await _maybe_create_sierra_tail(self, charts)
        if write_unified:
            self.unified_writer = await _maybe_create_unified_writer(self)
        self._sierra_running = True

        async def _loop():
            if self.sierra_tail is None:
                return
            async for ev in self.sierra_tail.events():
                try:
                    # Mettre Ã  jour VIX cache si graph 8
                    if ev.graph == 8 and ev.event_type in ("vix", "vix_diag"):
                        v = ev.raw_data.get('vix') or ev.raw_data.get('value')
                        if v is not None:
                            self._vix_cache['last_value'] = float(v)
                            self._vix_cache['last_ts'] = ev.ingest_ts.isoformat()

                    # Feeder MenthorQ si graph 10
                    if ev.graph == 10 and ev.event_type and ev.event_type.startswith("menthorq_"):
                        try:
                            # Lazy import pour Ã©viter dÃ©pendances dures
                            if self._menthorq_processor is None:
                                from features.menthorq_processor import MenthorQProcessor  # type: ignore
                                self._menthorq_processor = MenthorQProcessor()
                            line = json.dumps(ev.raw_data, ensure_ascii=False)
                            if hasattr(self._menthorq_processor, 'process_menthorq_line'):
                                self._menthorq_processor.process_menthorq_line(line)
                            elif hasattr(self._menthorq_processor, 'process_line'):
                                self._menthorq_processor.process_line(line)  # fallback
                        except Exception as me:
                            logger.warning(f"MenthorQ feed erreur: {me}")

                    # Router vers unified file
                    if self.unified_writer is not None:
                        try:
                            await self.unified_writer.route(ev)
                        except Exception as we:
                            logger.warning(f"UnifiedWriter erreur: {we}")

                    # Callbacks abonnÃ©s
                    if self._on_event_callbacks:
                        payload = dict(ev.raw_data)
                        payload['graph'] = ev.graph
                        payload['ingest_ts'] = ev.ingest_ts.isoformat()
                        for cb in list(self._on_event_callbacks):
                            try:
                                cb(payload)
                            except Exception as ce:
                                logger.warning(f"Callback erreur: {ce}")
                except Exception as e:
                    logger.error(f"Erreur boucle Sierra: {e}")

        self._sierra_task = asyncio.create_task(_loop())
        logger.info("Sierra pipeline dÃ©marrÃ©")

    async def stop_sierra_pipeline(self: DataCollectorEnhanced):
        if not self._sierra_running:
            return
        self._sierra_running = False
        try:
            if self.sierra_tail is not None:
                await self.sierra_tail.stop()
        except Exception:
            pass
        try:
            if self.unified_writer is not None:
                await self.unified_writer.close()
        except Exception:
            pass
        if self._sierra_task is not None:
            try:
                self._sierra_task.cancel()
            except Exception:
                pass
        logger.info("Sierra pipeline arrÃªtÃ©")

    def register_event_callback(self: DataCollectorEnhanced, callback: Callable[[Dict[str, Any]], None]) -> None:
        """Permet au moteur de s'abonner aux Ã©vÃ©nements marchÃ© unifiÃ©s."""
        self._on_event_callbacks.append(callback)

    def get_vix_cache(self: DataCollectorEnhanced) -> Dict[str, Any]:
        return dict(self._vix_cache)

    # Bind
    setattr(DataCollectorEnhanced, 'start_sierra_pipeline', start_sierra_pipeline)
    setattr(DataCollectorEnhanced, 'stop_sierra_pipeline', stop_sierra_pipeline)
    setattr(DataCollectorEnhanced, 'register_event_callback', register_event_callback)
    setattr(DataCollectorEnhanced, 'get_vix_cache', get_vix_cache)

_attach_sierra_methods()
